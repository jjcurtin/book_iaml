[
  {
    "objectID": "003_regression.html#overview-of-unit",
    "href": "003_regression.html#overview-of-unit",
    "title": "3  Introduction to Regression Models",
    "section": "3.1 Overview of Unit",
    "text": "3.1 Overview of Unit\n\n3.1.1 Learning Objectives\n\nUse of root mean square error (RMSE) in training and validation sets for model performance evaluation\nThe General Linear Model as a machine learning model\n\nExtensions to categorical variables (Dummy coding features)\nExtensions to interactive and non-linear effects of features\n\nK Nearest Neighbor (KNN)\n\nHyperparameter \\(k\\)\nScaling predictors\nExtensions to categorical variables\n\n\n\n\n\n3.1.2 Readings\n\nJames et al. (2023) Chapter 3, pp 59 - 109\n\n\n\n3.1.3 Lecture Videos\n\nLecture 1: Overview ~ 13 mins\nLecture 2: The Simple Linear Model, Part 1 ~ 16 mins\nLecture 3: The Simple Linear Model, Part 2 ~ 12 mins\nLecture 4: Extension to Multiple Predictors ~ 15 mins\nLecture 5: Extension to Categorical Predictors ~ 30 mins\nLecture 6: Extension to Interactions and Non-Linear Effects\nLecture 7: Introduction to KNN\nLecture 8: Distance and Scaling in KNN\nLecture 9: KNN with Ames\nDiscussijn\n\n\n\n\n3.1.4 Application Assignment and Quiz\n\nclean data: train; validate; test\ndata dictionary\nlm qmd\nknn qmd\nsolution: lm; knn\n\nPost questions to the Slack channel for application assignments.\nSubmit the application assignment here and complete the unit quiz by 8 pm on Wednesday, February 7th\n\nOur goal in this unit is to build a machine learning regression model that can accurately (we hope) predict the sale_price for future sales of houses (in Iowa? more generally?)\nTo begin this project we need to:\n\nSet up conflicts policies\nWe will hide this in future units\n\n\noptions(conflicts.policy = \"depends.ok\")\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\n\nℹ SHA-1 hash of file is \"175d942e14f108d74912bfb2593b77637328ecb1\"\n\ntidymodels_conflictRules()\n\n\n\nLoad the packages we will need. I am shifting here to only loading tidymodels and tidyverse because the other functions we need are only called occassionally (so we will call them by namespace to see how that “feels”.)\n\n\nlibrary(tidyverse) # for general data wrangling\nlibrary(tidymodels) # for modeling\n\n\n\nsource additional class functions libraries\nWe will hide this in future units\n\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true\")\n\nℹ SHA-1 hash of file is \"c045eee2655a18dc85e715b78182f176327358a7\"\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_plots.R?raw=true\")\n\nℹ SHA-1 hash of file is \"def6ce26ed7b2493931fde811adff9287ee8d874\"\n\n\n\nset display options\nWe will hide this in future units\n\n\ntheme_set(theme_classic())\noptions(tibble.width = Inf)\n\n\nhandle paths\n\n\npath_data <- \"./data\"\n\n\n\nSet up function to class ames data (copied with one improvement from last unit)\n\n\nclass_ames <- function(df){\n  df |>\n    mutate(across(where(is.character), factor)) |> \n    mutate(overall_qual = factor(overall_qual, levels = 1:10), \n           garage_qual = suppressWarnings(fct_relevel(garage_qual, # <1> \n                                                      c(\"no_garage\", \"po\", \"fa\", \n                                                    \"ta\", \"gd\", \"ex\"))))\n}\n\n\nWarnings should be considered errors until investigated. Once investigated, they can be ignored. To explicitly ignore, use suppressWarnings()\n\n\n\nOpen the cleaned training set\n\n\ndata_trn <- \n  read_csv(here::here(path_data, \"ames_clean_class_trn.csv\"), \n           col_types = cols()) |>  \n  class_ames() |> \n  glimpse()\n\nRows: 1,465\nColumns: 10\n$ sale_price   <dbl> 105000, 126000, 115000, 120000, 99500, 112000, 122000, 12…\n$ gr_liv_area  <dbl> 896, 882, 864, 836, 918, 1902, 900, 1225, 1728, 858, 1306…\n$ lot_area     <dbl> 11622, 8400, 10500, 2280, 7892, 8930, 9819, 9320, 13260, …\n$ year_built   <dbl> 1961, 1970, 1971, 1975, 1979, 1978, 1967, 1959, 1962, 195…\n$ overall_qual <fct> 5, 4, 4, 7, 6, 6, 5, 4, 5, 5, 3, 5, 4, 5, 3, 5, 2, 6, 5, …\n$ garage_cars  <dbl> 1, 2, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 2, 2, 1, …\n$ garage_qual  <fct> ta, ta, no_garage, ta, ta, ta, ta, no_garage, no_garage, …\n$ ms_zoning    <fct> res_high, res_low, res_low, res_low, res_low, res_med, re…\n$ lot_config   <fct> inside, corner, fr2, fr2, inside, inside, inside, inside,…\n$ bldg_type    <fct> one_fam, one_fam, one_fam, town_inside, town_end, duplex,…\n\n\n\n\nOpen the cleaned validation set\n\n\ndata_val <- read_csv(here::here(path_data, \"ames_clean_class_val.csv\"),\n                     col_types = cols()) |> \n  class_ames() |> \n  glimpse()\n\nRows: 490\nColumns: 10\n$ sale_price   <dbl> 215000, 189900, 189000, 171500, 212000, 164000, 394432, 1…\n$ gr_liv_area  <dbl> 1656, 1629, 1804, 1341, 1502, 1752, 1856, 1004, 1092, 106…\n$ lot_area     <dbl> 31770, 13830, 7500, 10176, 6820, 12134, 11394, 11241, 168…\n$ year_built   <dbl> 1960, 1997, 1999, 1990, 1985, 1988, 2010, 1970, 1971, 197…\n$ overall_qual <fct> 6, 5, 7, 7, 8, 8, 9, 6, 5, 6, 7, 9, 8, 8, 7, 8, 6, 5, 5, …\n$ garage_cars  <dbl> 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 3, 2, 3, 1, 1, 2, …\n$ garage_qual  <fct> ta, ta, ta, ta, ta, ta, ta, ta, ta, ta, ta, ta, ta, ta, t…\n$ ms_zoning    <fct> res_low, res_low, res_low, res_low, res_low, res_low, res…\n$ lot_config   <fct> corner, inside, inside, inside, corner, inside, corner, c…\n$ bldg_type    <fct> one_fam, one_fam, one_fam, one_fam, town_end, one_fam, on…\n\n\nNOTE: Remember, I have held back an additional test set that we will use only once to evaluate the final model that we each develop in this unit.\n\nWe will also make a dataframe to track validation error across the models we fit\n\nerror_val <- tibble(model = character(), rmse_val = numeric()) |> \n  glimpse()\n\nRows: 0\nColumns: 2\n$ model    <chr> \n$ rmse_val <dbl> \n\n\n\nWe will fit regression models with various model configurations.\nThese configurations will differ with respect to statistical algorithm:\n\nA General Linear Model (lm) - a parametric approach\nK Nearest Neighbor (KNN) - a non-parametric approach\n\nThese configurations will differ with respect to the features\n\nSingle feature (i.e., simple regression)\nVarious sets of multiple features that vary by:\n\nRaw predictors used\nTransformations applied to those predictors as part of feature engineering\nInclusion (or not) of interactions among features\n\nThe KNN model configurations will also differ with respect to its hyperparameter- \\(k\\)\n\n\nTo build models that will work well in new data (e.g., the data that I have held back from you so far):\n\nWe have split the remaining data into a training and validation set for our own use during model building\nWe will fit models in train\nWe will evaluate them in validation\n\nRemember that we:\n\nUsed a 75/25 stratified (on sale_price) split of the data at the end of cleaning EDA to create training and validation sets\nAre only using a subset of the available predictors. The same ones I used for the EDA unit\n\nYou will work with all of my predictors and all the predictors you used for your EDA when you do the application assignment for this unit\n\nPause for a moment to answer this question:\n\n\n\n\n\n\nQuestion: Why do we need independent validation data to select the best model configuration? In other words, why cant we just fit and evaluate all of the models in our one training set?\n\n\n\n\n\n\n\nShow Answer\nThese models will all overfit the dataset within which they are fit to some degree.   \nIn other words, they will predict both systematic variance (the DGP) and some noise in \nthe training set.  However, they will differ in how much they overfit the training set.   \nAs the models get more flexible they will have the potential to overfit to a greater degree.\nModels with a larger number of features (e.g., more predictors, features based on interactions\nas well as raw predictors) will overfit to a greater degree.  All other things equal, the\nnon-parametric KNN will also be more flexible than the general linear model so it may \noverfit to a greater degree as well if the true DGP is linear on the features.  \nTherefore, just because a model fits the training set well does not mean it will work \nwell in new data because the noise will be different in every new dataset.  \nThis overfitting will be removed from our performance estimate if we calculate it \nwith new data (the validation set).\n\n\n\n\n\n\nLet’s take a quick look at the available raw predictors in the training set\n\ndata_trn |> skim_all()\n\n\nData summary\n\n\nName\ndata_trn\n\n\nNumber of rows\n1465\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n5\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nn_unique\ntop_counts\n\n\n\n\noverall_qual\n0\n1\n10\n5: 424, 6: 350, 7: 304, 8: 176\n\n\ngarage_qual\n0\n1\n5\nta: 1312, no_: 81, fa: 57, gd: 13\n\n\nms_zoning\n0\n1\n7\nres: 1157, res: 217, flo: 66, com: 13\n\n\nlot_config\n0\n1\n5\nins: 1095, cor: 248, cul: 81, fr2: 39\n\n\nbldg_type\n0\n1\n5\none: 1216, tow: 108, dup: 63, tow: 46\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\nsale_price\n0\n1\n180696.15\n78836.41\n12789\n129500\n160000\n213500\n745000\n1.64\n4.60\n\n\ngr_liv_area\n0\n1\n1506.84\n511.44\n438\n1128\n1450\n1759\n5642\n1.43\n5.19\n\n\nlot_area\n0\n1\n10144.16\n8177.55\n1476\n7500\n9375\n11362\n164660\n11.20\n182.91\n\n\nyear_built\n0\n1\n1971.35\n29.65\n1880\n1953\n1972\n2000\n2010\n-0.54\n-0.62\n\n\ngarage_cars\n1\n1\n1.78\n0.76\n0\n1\n2\n2\n4\n-0.26\n0.10\n\n\n\n\n\n\nRemember from our modeling EDA that we have some issues to address as part of our feature engineering:\n\nMissing values\nPossible transformation of sale_price\nPossible transformation of other numeric predictors\nWe will need to use some feature engineering techniques to handle categorical variables\nWe may need to consider interactions among features\n\nAll of this will be accomplished with a recipe\nBut first, let’s discuss/review our first statistical algorithm"
  },
  {
    "objectID": "003_regression.html#the-simple-general-linear-model-lm",
    "href": "003_regression.html#the-simple-general-linear-model-lm",
    "title": "3  Introduction to Regression Models",
    "section": "3.2 The Simple (General) Linear Model (LM)",
    "text": "3.2 The Simple (General) Linear Model (LM)\nWe will start with only a quick review of the use of the simple (one feature) linear model (LM) as a machine learning model because you should be very familiar with this statistical model at this point\n\n\\(Y = \\beta_0 + \\beta_1*X_1 + \\epsilon\\)\n\nApplied to our regression problem, we might fit a model such as:\n\n\\(sale\\_price = \\beta_0 + \\beta_1*gr\\_liv\\_area + \\epsilon\\)\n\nThe (general) linear model is a parametric model. We need to estimate two parameters using our training set\n\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\nYou already know how to do this using lm() in base R. However, we will use the tidymodels modeling approach.\n\nWe use tidymodels because:\n\nIt provides a consistent interface to many (and growing numbers) of statistical algorithms\nIt provides very strong and easy feature engineering routines (e.g., missing data, scaling, transformations, near-zero variance, collinearity) via recipes\nIt simplifies model performance evaluation using resampling approaches (that you don’t know yet!)\nIt supports numerous performance metrics\nIt is tightly integrated within the tidyverse\nIt is under active development and support\nYou can see documentation for all of the packages at the tidymodels website. It is worth a quick review now to get a sense of what is available\n\n\nTo fit a model with a specific configuration, we need to:\n\nSet up a feature engineering recipe\nUse the recipe to make a feature matrix\n\nprep() it with training data\nbake() it with data you want to use to calculate feature matrix\n\nSelect and define the statistical algorithm\nFit the algorithm in the feature matrix in our training set\n\nThese steps are accomplished with functions from the recipes and parsnip packages.\n\nWe will start with a simple model configuration\n\nGeneral linear model (lm)\nOne feature (raw gr_liv_area)\nFit in training data\n\n\nSet up a VERY SIMPLE feature engineering recipe\n\nInclude outcome on the left size of ~\nInclude raw predictors (not yet features) on the right side of ~.\n\nIndicate the training data\n\n\nrec <- \n  recipe(sale_price ~ gr_liv_area, data = data_trn) \n\n\nWe can see a summary of it to verify it is doing what you expect by calling\n\nrec\nsummary(rec)\n\n\n\nWe can then prep the recipe and bake the data to make our feature matrix from the training dataset\n\nAgain, remember we always prep a recipe with training data but use the prepped recipe to bake any data\nIn this instance we will prep with data_trn and then bake data_trn so that we have features from our training set to train/fit the model.\n\n\nrec_prep <- rec |> \n  prep(training = data_trn)\n\n\n\nAnd now we can bake the training data to make a feature matrix\n\n\nfeat_trn <- rec_prep |> \n  bake(new_data = data_trn)\n\n\nYou should always review the feature matrix to make sure it looks as you expect\n\nincludes outcome (sale_price)\nincludes expected feature (gr_liv_area)\nSample size is as expected\nNo missing data\n\n\nfeat_trn |> skim_all()\n\n\nData summary\n\n\nName\nfeat_trn\n\n\nNumber of rows\n1465\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n1506.84\n511.44\n438\n1128\n1450\n1759\n5642\n1.43\n5.19\n\n\nsale_price\n0\n1\n180696.15\n78836.41\n12789\n129500\n160000\n213500\n745000\n1.64\n4.60\n\n\n\n\n\n\nNow let’s consider the statistical algorithm\n\ntidymodels breaks this apart into two pieces for clarity\nFirst, you specify the broad category of algorithm\n\ne.g., linear_reg(), nearest_neighbor(), logistic_reg()\n\nNext, you set_mode() to indicate if if the model is for regression or classification broadly\n\nNot needed if the engine can only be used for one mode (e.g., 'linear_reg() is only for regression.\n\nThen you select a function from a specific R package (or base R) that will implement the algorithm\n\ntidymodels calls this setting the engine\ne.g., lm, kknn, glm, glmnet\n\n\n\nYou can see the available engines (and modes: regression vs. classification) for the broad classes of algorithms\nWe will work with many of these algorithms later in the course\n\nshow_engines(\"linear_reg\")\n\n# A tibble: 7 × 2\n  engine mode      \n  <chr>  <chr>     \n1 lm     regression\n2 glm    regression\n3 glmnet regression\n4 stan   regression\n5 spark  regression\n6 keras  regression\n7 brulee regression\n\nshow_engines(\"nearest_neighbor\")\n\n# A tibble: 2 × 2\n  engine mode          \n  <chr>  <chr>         \n1 kknn   classification\n2 kknn   regression    \n\nshow_engines(\"logistic_reg\")\n\n# A tibble: 7 × 2\n  engine    mode          \n  <chr>     <chr>         \n1 glm       classification\n2 glmnet    classification\n3 LiblineaR classification\n4 spark     classification\n5 keras     classification\n6 stan      classification\n7 brulee    classification\n\nshow_engines(\"decision_tree\")\n\n# A tibble: 5 × 2\n  engine mode          \n  <chr>  <chr>         \n1 rpart  classification\n2 rpart  regression    \n3 C5.0   classification\n4 spark  classification\n5 spark  regression    \n\nshow_engines(\"rand_forest\")\n\n# A tibble: 6 × 2\n  engine       mode          \n  <chr>        <chr>         \n1 ranger       classification\n2 ranger       regression    \n3 randomForest classification\n4 randomForest regression    \n5 spark        classification\n6 spark        regression    \n\nshow_engines(\"mlp\")\n\n# A tibble: 6 × 2\n  engine mode          \n  <chr>  <chr>         \n1 keras  classification\n2 keras  regression    \n3 nnet   classification\n4 nnet   regression    \n5 brulee classification\n6 brulee regression    \n\n\n\nYou can load even more engines from the discrim package. We will use some of these later too. You need to load the package to use these engines.\n\nlibrary(discrim, exclude = \"smoothness\") # needed for these engines\n\nWarning: package 'discrim' was built under R version 4.2.3\n\nshow_engines(\"discrim_linear\") \n\n# A tibble: 4 × 2\n  engine        mode          \n  <chr>         <chr>         \n1 MASS          classification\n2 mda           classification\n3 sda           classification\n4 sparsediscrim classification\n\nshow_engines(\"discrim_regularized\") \n\n# A tibble: 1 × 2\n  engine mode          \n  <chr>  <chr>         \n1 klaR   classification\n\nshow_engines(\"naive_Bayes\")\n\n# A tibble: 2 × 2\n  engine     mode          \n  <chr>      <chr>         \n1 klaR       classification\n2 naivebayes classification\n\n\n\nYou can also better understand how the engine will be called using translate()\nNot useful here but will be with more complicated algorithms\n\nlinear_reg() |> \n  set_engine(\"lm\") |> \n  translate()\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\nModel fit template:\nstats::lm(formula = missing_arg(), data = missing_arg(), weights = missing_arg())\n\n\n\nLet’s combine our feature matrix with an algorithm to fit a model in our training set using only raw gr_liv_area as a feature\nNote the specification of\n\nThe category of algorithm\nThe engine (no need to set mode of engine b/c lm are only for the regression mode)\nThe use of the . to indicate all features in the matrix.\n\nnot that useful here because there is only one feature: gr_liv_area\nwill be useful when we have many features in the matrix\n\nWe use the the feature matrix (rather than raw data) from the training set to fit the model.\n\n\nfit_lm_1 <- \n  linear_reg() |> # <1> \n  set_engine(\"lm\") |> # <2> \n  fit(sale_price ~ ., data = feat_trn) # <3>\n\n\ncategory of algorithm\nengine\nuse of . for all features and use of feature matrix from training set\n\n\nWe can get the parameter estimates, standard errors, and statistical tests for each \\(\\beta\\) = 0 for this model using tidy() from the broom package (loaded as part of the tidyverse)\n\nfit_lm_1 |>  tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)   16561.   4537.        3.65 2.72e-  4\n2 gr_liv_area     109.      2.85     38.2  4.78e-222\n\n\n\nThere are a variety of ways to pull out the estimates for each feature (and intercept)\nOption 1: Pull all estimates from the tidy object\n\nfit_lm_1 |> \n  tidy() |> \n  pull(estimate)\n\n[1] 16560.9991   108.9268\n\n\n\nOption 2: Extract a single estimate using $ and row number. Be careful that order of features won’t change! This assumes the feature coefficient for the relevant feature is always the second coefficient.\n\ntidy(fit_lm_1)$estimate[[2]]\n\n[1] 108.9268\n\n\n\nOption 3: Filter tidy df to the relevant row (using term ==) and pull the estimate. Safer!\n\nfit_lm_1 |> \n  tidy() |> \n  filter(term == \"gr_liv_area\") |> \n  pull(estimate)\n\n[1] 108.9268\n\n\n\nOption 4: Write a function if we plan to do this a lot. We include this function in the fun_ml.R script in our repo. Better still (safe and code efficient)!\n\nget_estimate <- function(the_fit, the_term){\n  the_fit |> \n    tidy() |> \n    filter(term == the_term) |> \n    pull(estimate)\n}\n\nand then use this function\n\nget_estimate(fit_lm_1, \"gr_liv_area\")\n\n[1] 108.9268\n\nget_estimate(fit_lm_1, \"(Intercept)\")\n\n[1] 16561\n\n\n\nRegardless of the method, we now have a simple parametric model for sale_price\n\\(\\hat{sale\\_price} = 1.6561\\times 10^{4} + 108.9 * gr\\_liv\\_area\\)\n\nWe can get the predicted values for sale_price (i.e., \\(\\hat{sale\\_price}\\)) in our validation set using predict()\nHowever, we first need to make a feature matrix for our validation set\n\nWe use the same recipe that we previously prepped with training data (data_trn)\nBut now we bake the validation data, data_val\n\n\nfeat_val <- rec_prep |> \n  bake(new_data = data_val)\n\n\nAs always, we should skim these new features\n\nSample size matches what we expect for validation set\nNo missing data\nIncludes expected outcome and features\n\n\nfeat_val |> skim_all()\n\n\nData summary\n\n\nName\nfeat_val\n\n\nNumber of rows\n490\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n1493.0\n483.78\n480\n1143.5\n1436\n1729.5\n3608\n0.92\n1.16\n\n\nsale_price\n0\n1\n178512.8\n75493.59\n35311\n129125.0\n160000\n213000.0\n556581\n1.42\n2.97\n\n\n\n\n\n\nNow we can get predictions using our model with validation features\npredict() returns a dataframe with one column named .pred and one row for every observation in dataframe (e.g., validation feature set)\n\npredict(fit_lm_1, feat_val)\n\n# A tibble: 490 × 1\n     .pred\n     <dbl>\n 1 196944.\n 2 194003.\n 3 213065.\n 4 162632.\n 5 180169.\n 6 207401.\n 7 218729.\n 8 125923.\n 9 135509.\n10 133004.\n# … with 480 more rows\n\n\n\nWe can visualize how well this model performs in the validation set by plotting predicted sale_price (\\(\\hat{sale\\_price}\\)) vs. sale_price (ground truth in machine learning terminology) for these data\nWe might do this a lot so let’s write a function. We have also included this function in fun_ml.R\n\nplot_truth <- function(truth, estimate) {\n  ggplot(mapping = aes(x = truth, y = estimate)) + \n    geom_abline(lty = 2, color = \"red\") + \n    geom_point(alpha = 0.5) + \n    labs(y = \"predicted outcome\", x = \"outcome\") +\n    coord_obs_pred()   # scale axes uniformly (from tune package)\n}\n\n\n\nplot_truth(truth = feat_val$sale_price, \n           estimate = predict(fit_lm_1, feat_val)$.pred)\n\n\n\n\nPerfect performance would have all the points right on the dotted line (same value for actual and predicted outcome)\n\nOur model doesn’t do that well yet. Not surprising\nPattern also has some indication of fanning of residuals AND some non-linearity with higher outcome scores that suggests need for a power transformation of outcome (e.g., log)\nThis is consistent with our earlier modeling EDA\nPerhaps not that bad here b/c both sale_price and gr_liv_area were positively skewed\nWe will need consider this eventually\n\n\nWe can quantify model performance by selecting a performance metric\n\nThe yardstick package within the tidymodels framework supports calculation of many performance metrics for regression and classification models\nSee the list of all currently available metrics\n\nRoot mean square error (RMSE) is a common performance metric for regression models\n\nYou focused on a related metric, sum of squared error (SSE), in PSY 610/710\nRMSE simply divides SSE by N (to get mean squared error; MSE) and then takes the square root to return the metric to the original units for the outcome variable\nIt is easy to calculate using rmse_vec() from the yardstick package\n\n\nrmse_vec(truth = feat_val$sale_price, \n         estimate = predict(fit_lm_1, feat_val)$.pred)\n\n[1] 51375.08\n\n\n\nLet’s record how well this model performed in validation so we can compare it to subsequent models\n\nerror_val <- bind_rows(error_val, \n                       tibble(model = \"simple linear model\", \n                              rmse_val = rmse_vec(truth = feat_val$sale_price, \n                                                  estimate = predict(fit_lm_1,\n                                                                     feat_val)$.pred)))\nerror_val\n\n# A tibble: 1 × 2\n  model               rmse_val\n  <chr>                  <dbl>\n1 simple linear model   51375.\n\n\nNOTE: I will continue to bind RMSE to this dataframe for newer models but plan to hide this code chuck to avoid distractions. You can reuse this code repeatedly to track your own models if you like. (Perhaps we should write a function??)\n\nFor explanatory purposes, we might want to visualize the relationship between a feature and the outcome (in addition to examining the parameter estimates and the associated statistical tests)\n\nHere is a plot of \\(\\hat{sale\\_price}\\) by gr_liv_area superimposed over a scatterplot of the raw data from the validation set\n\n\nfeat_val |> \n  ggplot(aes(x = gr_liv_area)) +\n    geom_point(aes(y = sale_price), color = \"gray\") +\n    geom_line(aes(y = predict(fit_lm_1, data_val)$.pred), \n              linewidth = 1.25, color = \"blue\") + \n    ggtitle(\"Validation Set\")\n\n\n\n\n\nAs expected, there is a moderately strong positive relationship between gr_liv_area and sale_price.\n\nWe can also again see the heteroscadasticity in the errors that might be corrected by a power transformation of sale_price (or gr_liv_area)"
  },
  {
    "objectID": "003_regression.html#extension-of-lm-to-multiple-predictors",
    "href": "003_regression.html#extension-of-lm-to-multiple-predictors",
    "title": "3  Introduction to Regression Models",
    "section": "3.3 Extension of LM to Multiple Predictors",
    "text": "3.3 Extension of LM to Multiple Predictors\nWe can improve model performance by moving from simple linear model to a linear model with multiple features derived from multiple predictors\nWe have many other numeric variables available to use, even in this pared down version of the dataset.\n\ndata_trn |>  names()\n\n [1] \"sale_price\"   \"gr_liv_area\"  \"lot_area\"     \"year_built\"   \"overall_qual\"\n [6] \"garage_cars\"  \"garage_qual\"  \"ms_zoning\"    \"lot_config\"   \"bldg_type\"   \n\n\nLet’s expand our model to also include lot_area, year_built, and garage_cars\nAgain, we need:\n\nA feature engineering recipe\nTraining (and eventually validation) feature matrices\nAn algorithm to fit in training feature matrix\n\n\nWith the addition of new predictors, we now have a feature engineering task\n\nWe have missing data on garage_cars in the training set\nWe need to decide how we will handle it\n\nA simple solution is to do median imputation - substitute the median of the non-missing scores for any missing score.\n\nThis is fast and easy to understand\nIt works OK (but there are certainly better options that we will consider later in the course)\n\nsee other options in Step Functions - Imputation section on tidymodels website\n\nThere is only one missing value so it likely doesn’t matter much anyway\n\n\nLet’s add this to our recipe. All of the defaults are appropriate but you should see ?step_impute_median() to review them\n\nrec <- \n  recipe(sale_price ~ gr_liv_area + lot_area + year_built + garage_cars, # <1>\n         data = data_trn) |> \n  step_impute_median(garage_cars)\n\n\nNotice we now list four predictors for our recipe using + between them\n\n\nNow we need to\n\nFirst prep recipe\n\n\nrec_prep <- rec |> \n  prep(data_trn)  # <1>\n\n\nI am going to stop using training = at this point. Remember, we prep recipes with training data.\n\n\n\nNext, bake the training data with prepped recipe to get training features\n\n\nfeat_trn <- rec_prep |> \n  bake(data_trn) # <1>\n\n\nI am going to stop using new_data = but remember, we can bake any dataset to make features for that dataset.\n\n\n\nAnd take a quick look at the features\n\nSample size is correct\n4 features and the outcome variable\nAll features are numeric\nNo missing data for garage_qual\n\n\n\nfeat_trn |> skim_all()\n\n\nData summary\n\n\nName\nfeat_trn\n\n\nNumber of rows\n1465\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n1506.84\n511.44\n438\n1128\n1450\n1759\n5642\n1.43\n5.19\n\n\nlot_area\n0\n1\n10144.16\n8177.55\n1476\n7500\n9375\n11362\n164660\n11.20\n182.91\n\n\nyear_built\n0\n1\n1971.35\n29.65\n1880\n1953\n1972\n2000\n2010\n-0.54\n-0.62\n\n\ngarage_cars\n0\n1\n1.78\n0.76\n0\n1\n2\n2\n4\n-0.26\n0.10\n\n\nsale_price\n0\n1\n180696.15\n78836.41\n12789\n129500\n160000\n213500\n745000\n1.64\n4.60\n\n\n\n\n\n\n\nAnd finally, bake the validation data with the same prepped recipe to get validation features\n\n\nfeat_val <- rec_prep |> \n  bake(data_val) # <1>\n\n\nNotice that here we are now baking data_val\n\n\n\nAnd take a quick look\n\nCorrect sample size (N = 490)\n4 features and outcome\nAll numeric\nNo missing data\n\n\n\nfeat_val |> skim_all()\n\n\nData summary\n\n\nName\nfeat_val\n\n\nNumber of rows\n490\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n1493.00\n483.78\n480\n1143.5\n1436.0\n1729.50\n3608\n0.92\n1.16\n\n\nlot_area\n0\n1\n10462.08\n10422.55\n1680\n7500.0\n9563.5\n11780.75\n215245\n15.64\n301.66\n\n\nyear_built\n0\n1\n1971.08\n30.96\n1875\n1954.0\n1975.0\n2000.00\n2010\n-0.66\n-0.41\n\n\ngarage_cars\n0\n1\n1.74\n0.76\n0\n1.0\n2.0\n2.00\n4\n-0.24\n0.22\n\n\nsale_price\n0\n1\n178512.82\n75493.59\n35311\n129125.0\n160000.0\n213000.00\n556581\n1.42\n2.97\n\n\n\n\n\n\nNow let’s combine our algorithm and training features to fit this model configuration with 4 features\n\nfit_lm_4 <- \n  linear_reg() |> \n  set_engine(\"lm\") |> \n  fit(sale_price ~ ., data = feat_trn) # <1>\n\n\nthe . is a bit more useful now\n\n\nThis yields these parameter estimates (which as we know from 610/710 were selected to minimize SSE in the training set):\n\nfit_lm_4 |> tidy()\n\n# A tibble: 5 × 5\n  term            estimate std.error statistic   p.value\n  <chr>              <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept) -1665041.    89370.       -18.6  1.14e- 69\n2 gr_liv_area       76.8       2.62      29.3  3.56e-149\n3 lot_area           0.514     0.146      3.51 4.60e-  4\n4 year_built       854.       46.2       18.5  7.66e- 69\n5 garage_cars    22901.     1964.        11.7  4.09e- 30\n\n\n\nHere is our parametric model\n\n\\(\\hat{sale\\_price} = -1.6650409\\times 10^{6} + 76.8 * gr\\_liv\\_area + 0.5 * lot\\_area + 854.3 * year\\_built + 2.29008\\times 10^{4} * garage\\_cars\\)\n\nCompared with our previous simple regression model:\n\n\\(\\hat{sale\\_price} = 1.6561\\times 10^{4} + 108.9 * gr\\_liv\\_area\\)\n\n\nOf course, these four features are correlated both with sale_price but also with each other\nLet’s look at correlations in the training set.\n\nfeat_trn |> \n  cor() |> \n  corrplot::corrplot.mixed()\n\n\n\n\n\n\n\n\n\n\n\nQuestion: What are the implications of the correlations among many of these predictors?\n\n\n\n\n\n\n\nShow Answer\nThe multiple regression model coefficients represent unique effects, controlling for \nall other variables in the model.  You can see how the unique effect of `gr_liv_area` \nis smaller than its overall effect from the simple regression.   This also means \nthat the overall predictive strength of the model will not be a sum of the effects \nof each predictor considered in isolation - it will likely be less.  Also, if the \ncorrelations are high, problems with multicollinearity will emerge.  This will yield \nlarge standard errors which means that the models will start to have more variance when \nfit in different training datasets!  We will soon learn about other regularized \nversions of the GLM that do not have these issues with correlated predictors.\n\n\n\n\n\n\nHow well does this more complex model perform in validation? Let’s compare the previous and current visualizations of \\(sale\\_price\\) vs. \\(\\hat{sale\\_price}\\)\n\nLooks like the errors are smaller (closer to the diagonal line that would represent prefect prediction)\nClear signs of non-linearity are now present as well. Time for more Modeling EDA!!\n\n\nplot_1 <- plot_truth(truth = feat_val$sale_price, \n                     estimate = predict(fit_lm_1, feat_val)$.pred)\n\nplot_4 <- plot_truth(truth = feat_val$sale_price, \n                     estimate = predict(fit_lm_4, feat_val)$.pred)\n\ncowplot::plot_grid(plot_1, plot_4, \n          labels = list(\"1 feature\", \"4 features\"), hjust = -1.5)\n\n\n\n\nCoding sidebar: Notice the use of plot_grid() from the cowplot package to make side by side plots. This also required returning the individual plots as objects (just assign to a object name, e.g., plot_1)\n\nLet’s compare model performance for the two models using RMSE in the validation set\n\nThe one feature simple linear model\n\n\nrmse_vec(feat_val$sale_price, \n         predict(fit_lm_1, feat_val)$.pred)\n\n[1] 51375.08\n\n\n\nThe four feature linear model. A clear improvement!\n\n\nrmse_vec(feat_val$sale_price, \n         predict(fit_lm_4, feat_val)$.pred)\n\n[1] 39903.25\n\n\n\n\nLet’s bind the new performance metric to our results table\n\n\n\n# A tibble: 2 × 2\n  model                  rmse_val\n  <chr>                     <dbl>\n1 simple linear model      51375.\n2 4 feature linear model   39903.\n\n\n\nGiven the non-linearity suggested by the truth vs. estimate plots, we might wonder if we could improve the fit if we transformed our features to be closer to normal\n\nThere are a number of recipe functions that do transformations (see Step Functions - Individual Transformations)\nWe will apply step_YeoJohnson(), which is similar to a Box-Cox transformation but can be more broadly applied because the scores don’t need to be strictly positive\n\n\nLet’s do it all again, now with transformed features!\n\nDefine the feature engineering recipe\n\n\nrec <- \n  recipe(sale_price ~ gr_liv_area + lot_area + year_built + garage_cars, \n         data = data_trn) |> \n  step_impute_median(garage_cars) |> \n  step_YeoJohnson(lot_area, gr_liv_area, year_built, garage_cars)\n\n\n\nPrep the recipe with training set\n\n\nrec_prep <- rec |> \n  prep(data_trn)\n\n\nUse prepped recipe to bake the training set into features\nNotice the features are now less skewed (but sale_price is still skewed)\n\n\nfeat_trn <- rec_prep |> \n  bake(data_trn)\n\nfeat_trn |> skim_all()\n\n\nData summary\n\n\nName\nfeat_trn\n\n\nNumber of rows\n1465\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n5.22\n0.16\n4.60\n5.11\n5.23\n5.33\n5.86\n0.00\n0.12\n\n\nlot_area\n0\n1\n14.10\n1.14\n10.32\n13.69\n14.20\n14.64\n21.65\n0.08\n5.46\n\n\nyear_built\n0\n1\n1971.35\n29.65\n1880.00\n1953.00\n1972.00\n2000.00\n2010.00\n-0.54\n-0.62\n\n\ngarage_cars\n0\n1\n2.12\n0.98\n0.00\n1.11\n2.37\n2.37\n5.23\n-0.03\n0.04\n\n\nsale_price\n0\n1\n180696.15\n78836.41\n12789.00\n129500.00\n160000.00\n213500.00\n745000.00\n1.64\n4.60\n\n\n\n\n\n\n\nUse same prepped recipe to bake the validation set into features\nAgain, features are less skewed\n\n\nfeat_val <- rec_prep |> \n  bake(data_val)\n\nfeat_val |> skim_all()\n\n\nData summary\n\n\nName\nfeat_val\n\n\nNumber of rows\n490\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n5.22\n0.16\n4.65\n5.11\n5.23\n5.32\n5.66\n-0.17\n0.19\n\n\nlot_area\n0\n1\n14.14\n1.17\n10.57\n13.69\n14.24\n14.72\n22.44\n0.11\n6.12\n\n\nyear_built\n0\n1\n1971.08\n30.96\n1875.00\n1954.00\n1975.00\n2000.00\n2010.00\n-0.66\n-0.41\n\n\ngarage_cars\n0\n1\n2.06\n0.96\n0.00\n1.11\n2.37\n2.37\n5.23\n0.01\n0.24\n\n\nsale_price\n0\n1\n178512.82\n75493.59\n35311.00\n129125.00\n160000.00\n213000.00\n556581.00\n1.42\n2.97\n\n\n\n\n\n\n\nFit model\n\n\nfit_lm_4yj <- \n  linear_reg() |> \n  set_engine(\"lm\") |> \n  fit(sale_price ~ ., data = feat_trn)\n\n\n\nView truth vs. estimate plot\n\n\nplot_truth(truth = feat_val$sale_price,\n           estimate = predict(fit_lm_4yj, feat_val)$.pred)\n\n\n\n\n\n\nand look at the error\n\n\n\n# A tibble: 3 × 2\n  model                          rmse_val\n  <chr>                             <dbl>\n1 simple linear model              51375.\n2 4 feature linear model           39903.\n3 4 feature linear model with YJ   41660.\n\n\n\nThat didn’t help at all. Error still high and still non-linearity in plot.\n\n\nWe may need to consider\n\na transformation of sale_price (We will leave that to you for the application assignment if you are daring!)\nor a different algorithm that can handle non-linear relationships better"
  },
  {
    "objectID": "003_regression.html#extensions-to-interactive-models-and-non-linear-models",
    "href": "003_regression.html#extensions-to-interactive-models-and-non-linear-models",
    "title": "3  Introduction to Regression Models",
    "section": "3.5 Extensions to Interactive Models and Non-linear Models",
    "text": "3.5 Extensions to Interactive Models and Non-linear Models\n\n3.5.1 Interactions\nThere may be interactive effects among our predictors\n\nSome statistical algorithms (e.g., KNN) can naturally accommodate interactive effects without any feature engineering\nLinear models cannot\nNothing to fear, tidymodels makes it easy to feature engineer interactions\n[BUT - as we will learn, we generally think that if you expect lots of interactions, the linear model may not be the best model to use]\n\n\nFor example, it may be that the relationship between year_built and sale_price depends on overall_qual.\n\nOld houses are expensive if they are in good condition\nbut old houses are very cheap if they are in poor condition\n\n\nIn the tidymodels framework\n\nCoding interactions is done by feature engineering, not by formula (Note that formula does not change below in recipe)\nThis seems appropriate to us as we are making new features to represent interactions\nWe still use an R formula like interface to specify the interaction term features that will be created\nsee more details on the tidymodels website\n\n\nrec <- \n  recipe(sale_price ~  ~ gr_liv_area + lot_area + year_built + garage_cars + \n           ms_zoning + overall_qual, data = data_trn) |> \n  step_impute_median(garage_cars) |> \n  step_mutate(ms_zoning = fct_collapse(ms_zoning,\n                                 \"residential\" = c(\"res_high\", \"res_med\", \"res_low\"),\n                                 \"commercial\" = c(\"agri\", \"commer\", \"indus\"),\n                                 \"floating\" = \"float\"),\n              overall_qual = as.numeric(overall_qual)) |>\n  step_dummy(ms_zoning) |> \n  step_interact(~ overall_qual:year_built)\n\n\nLet’s prep, bake, fit, and evaluate!\n\nrec_prep <- rec |> \n  prep(data_trn)\n\nfeat_trn <- rec_prep |> \n  bake(data_trn)\n\nfeat_val <- rec_prep |> \n  bake(data_val)\n\n\n\nNote the new interaction term (we just skim feat_trn here)\nNamed using “x” to specify the interaction\n\n\nfeat_trn |> skim_all()\n\n\nData summary\n\n\nName\nfeat_trn\n\n\nNumber of rows\n1465\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n9\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n1506.84\n511.44\n438\n1128\n1450\n1759\n5642\n1.43\n5.19\n\n\nlot_area\n0\n1\n10144.16\n8177.55\n1476\n7500\n9375\n11362\n164660\n11.20\n182.91\n\n\nyear_built\n0\n1\n1971.35\n29.65\n1880\n1953\n1972\n2000\n2010\n-0.54\n-0.62\n\n\ngarage_cars\n0\n1\n1.78\n0.76\n0\n1\n2\n2\n4\n-0.26\n0.10\n\n\noverall_qual\n0\n1\n6.08\n1.41\n1\n5\n6\n7\n10\n0.20\n-0.03\n\n\nsale_price\n0\n1\n180696.15\n78836.41\n12789\n129500\n160000\n213500\n745000\n1.64\n4.60\n\n\nms_zoning_floating\n0\n1\n0.05\n0.21\n0\n0\n0\n0\n1\n4.38\n17.22\n\n\nms_zoning_residential\n0\n1\n0.94\n0.23\n0\n1\n1\n1\n1\n-3.86\n12.90\n\n\noverall_qual_x_year_built\n0\n1\n12015.69\n2907.93\n1951\n9800\n11808\n14021\n20090\n0.24\n-0.11\n\n\n\n\n\n\n\nfit model\n\n\nfit_lm_8 <- \n  linear_reg() |> \n  set_engine(\"lm\") |> \n  fit(sale_price ~., \n      data = feat_trn)\n\n\n\nplot\n\n\nplot_truth(truth = feat_val$sale_price, \n           estimate = predict(fit_lm_8, feat_val)$.pred)\n\n\n\n\n\n\ncalculate held out error\n\n\n\n# A tibble: 6 × 2\n  model                                rmse_val\n  <chr>                                   <dbl>\n1 simple linear model                    51375.\n2 4 feature linear model                 39903.\n3 4 feature linear model with YJ         41660.\n4 6 feature linear model w/ms_zoning     39846.\n5 7 feature linear model                 34080.\n6 8 feature linear model w/interaction   32720.\n\n\n\nThat helped!\n\n\nYou can also feature engineer interactions with nominal (and ordinal predictors treated as nominal) predictors\n\nThe nominal predictors should first be converted to dummy code features\nYou will indicate the interactions using the variable names that will be assigned to these dummy code features\nUse starts_with() or matches() to make it easy if there are many features associated with a categorical predictor\nCan use “~ .^2” to include all two way interactions (be careful if you have dummy coded features!)\n\n\nLet’s code an interaction between ms_zoning & year_built.\n\nOld homes are cool\nOld commercial spaces are never cool\nMaybe this is why the main effect of ms_zoning wasn’t useful\n\n\nrec <- \n  recipe(sale_price ~  ~ gr_liv_area + lot_area + year_built + garage_cars + \n           ms_zoning + overall_qual, data = data_trn) |> \n  step_impute_median(garage_cars) |> \n  step_mutate(ms_zoning = fct_collapse(ms_zoning,\n                                 \"residential\" = c(\"res_high\", \"res_med\", \"res_low\"),\n                                 \"commercial\" = c(\"agri\", \"commer\", \"indus\"),\n                                 \"floating\" = \"float\"),\n              overall_qual = as.numeric(overall_qual)) |>\n  step_dummy(ms_zoning) |> \n  step_interact(~ overall_qual:year_built) |> \n  step_interact(~ starts_with(\"ms_zoning_\"):year_built)  \n\n\n\nprep, bake\n\n\nrec_prep <- rec |> \n  prep(data_trn)\n\nfeat_trn <- rec_prep |> \n  bake(data_trn)\n\nfeat_val <- rec_prep |> \n  bake(data_val)\n\n\n\nYup, we have two new interaction features as expected\n\n\nfeat_trn |> skim_all()\n\n\nData summary\n\n\nName\nfeat_trn\n\n\nNumber of rows\n1465\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n1506.84\n511.44\n438\n1128\n1450\n1759\n5642\n1.43\n5.19\n\n\nlot_area\n0\n1\n10144.16\n8177.55\n1476\n7500\n9375\n11362\n164660\n11.20\n182.91\n\n\nyear_built\n0\n1\n1971.35\n29.65\n1880\n1953\n1972\n2000\n2010\n-0.54\n-0.62\n\n\ngarage_cars\n0\n1\n1.78\n0.76\n0\n1\n2\n2\n4\n-0.26\n0.10\n\n\noverall_qual\n0\n1\n6.08\n1.41\n1\n5\n6\n7\n10\n0.20\n-0.03\n\n\nsale_price\n0\n1\n180696.15\n78836.41\n12789\n129500\n160000\n213500\n745000\n1.64\n4.60\n\n\nms_zoning_floating\n0\n1\n0.05\n0.21\n0\n0\n0\n0\n1\n4.38\n17.22\n\n\nms_zoning_residential\n0\n1\n0.94\n0.23\n0\n1\n1\n1\n1\n-3.86\n12.90\n\n\noverall_qual_x_year_built\n0\n1\n12015.69\n2907.93\n1951\n9800\n11808\n14021\n20090\n0.24\n-0.11\n\n\nms_zoning_floating_x_year_built\n0\n1\n90.29\n415.84\n0\n0\n0\n0\n2009\n4.38\n17.22\n\n\nms_zoning_residential_x_year_built\n0\n1\n1860.03\n453.95\n0\n1948\n1968\n1997\n2010\n-3.83\n12.78\n\n\n\n\n\n\n\nFit model\n\n\nfit_lm_10 <- \n  linear_reg() |> \n  set_engine(\"lm\") |> \n  fit(sale_price ~ ., data = feat_trn)\n\n\n\nPlot\n\n\nplot_truth(truth = feat_val$sale_price, \n           estimate = predict(fit_lm_10, feat_val)$.pred)\n\n\n\n\n\n\nQuantify held out error\n\n\nerror_val <- error_val |> \n  bind_rows(tibble(model = \"10 feature linear model w/interactions\", \n                   rmse_val = rmse_vec(feat_val$sale_price,\n                                       predict(fit_lm_10,\n                                               feat_val)$.pred)))\n\nerror_val\n\n# A tibble: 7 × 2\n  model                                  rmse_val\n  <chr>                                     <dbl>\n1 simple linear model                      51375.\n2 4 feature linear model                   39903.\n3 4 feature linear model with YJ           41660.\n4 6 feature linear model w/ms_zoning       39846.\n5 7 feature linear model                   34080.\n6 8 feature linear model w/interaction     32720.\n7 10 feature linear model w/interactions   32708.\n\n\n\nNot really any better\nShouldn’t just include all interactions without reason\n\nEither you have done EDA to support them or\nYou have substantive interest in them (explanatory question)\nIf you want all interactions, use a statistical algorithm that supports those relationships without feature engineering (e.g., KNN, random forest and other decision trees)\n\n\n\n\n\n3.5.2 Non-linear Models\nWe may also want to model non-linear effects of our predictors\n\nSome non-parametric models can accommodate non-linear effects without feature engineering (e.g., KNN, Random Forest).\nNon-linear effects can be accommodated in a linear model with feature engineering\n\nTransformations of Y or X. See Step Functions - Individual Transformations on tidymodels website\nOrdinal predictors can be coded with dummy variables\nNumeric predictors can be split at threshold\nPolynomial contrasts for numeric or ordinal predictors (see step_poly())\n\nWe will continue to explore these options throughout the course"
  },
  {
    "objectID": "003_regression.html#knn-regression",
    "href": "003_regression.html#knn-regression",
    "title": "3  Introduction to Regression Models",
    "section": "3.6 KNN Regression",
    "text": "3.6 KNN Regression\nK Nearest Neighbor\n\nIs a non-parametric regression and classification statistical algorithm\n\nIt does not yield specific parameter estimates for features/predictors (or statistical tests for those parameter estimates)\nThere are still ways to use it to address explanatory questions (visualizations, model comparisons, feature importance)\n\nVery simple but also powerful (listed commonly among top 10 algorithms)\n\nBy powerful, it is quite flexible and can accommodate many varied DGPs without the need for much feature engineering with its predictors\nMay not need most transformations of X or Y\nMay not need to model interactions\nStill need to handle missing data, outliers, and categorical predictors\n\n\n\nK Nearest Neighbor\n\nAlgorithm “memorizes” the training set (lazy learning)\n\nLazy learning is most useful for large, continuously changing datasets with few attributes (features) that are commonly queried (e.g., online recommendation systems)\n\nPrediction for any new observation is based on \\(k\\) most similar observations from the dataset\n\n\\(k\\) provides direct control over the bias-variance trade-off for this algorithm\n\n\n\nTo better understand KNN let’s simulate training data for three different DGPs (linear - y, polynomial - y2, and step - y3)\n\n\n\n\nLet’s start with a simple example where the DGP for Y is linear on one predictor (X)\nDGP: \\(y = rnorm(150, x, 10)\\)\nThis figure displays:\n\nDGP\nPrediction line from a simple linear model\nRed lines to represent three new observations (X = 10, 50, 90) we want to make predictions for via a standard KNN\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion: What would 5-NN predictions look like for each of these three new values of X in the figure above?\n\n\n\n\n\n\n\nShow Answer\nFor x = 10, find the five observations that have X values closest to 10.  Average the \nY values for those 5 observations and that is your predicted Y associated with \nthat new value of X.  Repeat to make predictions for Y for any other value of X,\ne.g., 50, 90, or any other value\n\n\n\n\n\n\nKNN can easily accommodate non-linear relationships between numeric predictors and outcomes without any feature engineering for predictors\nIn fact, it can flexibly handle any shape of relationship\nDGP: \\(y2 = rnorm(150, x^4 / 800000, 8)\\)\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\nDGP: \\(y3 = if\\_else(x < 40, rnorm(150, 25, 10), rnorm(150, 75, 10))\\)\n\n\n\n\n\n\n\n3.6.1 The hyperparameter k\nKNN is our first example of a statistical algorithm that includes a hyperparameter, in this case \\(k\\)\n\nAlgorithm hyperparameters differ from parameters in that they cannot be estimated while fitting the algorithm to the training set\nThey must be set in advance\nk = 5 is the default for kknn(), the engine from the kknn package that we will use to fit a KNN within tidymodels.\n\n\\(kknn()\\) weights observations (neighbors) based on distance.\n\nAn option exists for unweighted as well but not likely used much (default is optimal weighting, use it!).\n\n\n\nUsing the polynomial DGP above, let’s look at a 5-NN yields\n\nNote the new category of algorithm, new engine, and the need to set a mode (because KNN can be used for regression and classification)\nWe can look in the package documentation to better understand what is being done (?kknn::train.kknn).\n\n\nnearest_neighbor() |>   \n  set_engine(\"kknn\") |>   \n  set_mode(\"regression\") |> \n  translate()\n\nK-Nearest Neighbor Model Specification (regression)\n\nComputational engine: kknn \n\nModel fit template:\nkknn::train.kknn(formula = missing_arg(), data = missing_arg(), \n    ks = min_rows(5, data, 5))\n\n\n\n\nSet up simple feature engineering recipe and get training features (nothing happening but let’s follow normal routine anyway)\n\n\nrec <- \n  recipe(y2 ~ x, data = data_trn_demo)\n\nrec_prep <- rec |> \n  prep(data_trn_demo)\n\nfeat_trn_demo <- rec_prep |> \n  bake(data_trn_demo)\n\n\n\nFit 5NN\n\n\nfit_5nn_demo <- \n  nearest_neighbor() |>   \n  set_engine(\"kknn\") |>   \n  set_mode(\"regression\") |> \n  fit(y2 ~ ., data = feat_trn_demo)\n\n\n\nGet a validation set (a new sample using same polynomial DGP)\n\n\ndata_val_demo <- tibble(x = runif(200, 1, 100),\n               y = rnorm(200, x, 10),\n               y_dgp = rnorm(200, x ,0),\n               y2 = rnorm(200, x^4 / 800000, 8),\n               y2_dgp = rnorm(200, x^4 / 800000 ,0),\n               y3 = if_else(x < 40, rnorm(200, 25, 10),  rnorm(200, 75, 10)),\n               y3_dgp = if_else(x < 40, rnorm(200, 25, 0),  rnorm(200, 75, 0)))\n\nfeat_val_demo <- rec_prep |> \n  bake(data_val_demo)\n\n\n\nDisplay 5NN predictions in validation\n\nKNN (with k = 5) does a pretty good job of representing the shape of the DGP (low bias)\nKNN displays some (but minimal) evidence of overfitting\nSimple linear model does not perform well (clear/high bias)\n\n\n\n\n\n\n\n\nLet’s pause and consider our conceptual understanding of the impact of \\(k\\) on the bias-variance trade-off\n\n\n\n\n\n\nQuestion: How will the size of k influence model performance (e.g., bias, overfitting/variance)?\n\n\n\n\n\n\n\nShow Answer\nSmaller values of $k$ will tend to increase overfitting (and therefore variance \nacross training samples) but decrease bias.  Larger values of k will tend to decrease\noverfitting but increase bias.  We need to find the Goldilocks \"sweet spot\"\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion: How will k = 1 perform in training and validation sets?\n\n\n\n\n\n\n\nShow Answer\nk = 1 will perfectly fit the training set.  Therefore it is very dependent on the training \nset (high variance).  It will fit both the DGP and the noise in the training set.  \nClearly it will likely not do as well in validation (it will be overfit to training).  \nk needs to be larger if there is more noise (to average over more cases).  k needs \nto be smaller if the relationships are complex. (More on choosing k by resampling in \nunit 5.\n\n\n\n\n\n\nk = 1\n\nFit new model\nRecipe and features have not changed\n\n\nfit_1nn_demo <- \n  nearest_neighbor(neighbors = 1) |>  # <1> \n  set_engine(\"kknn\") |>   \n  set_mode(\"regression\") |> \n  fit(y2 ~ ., data = feat_trn_demo)\n\n\nSet k with neighbors =\n\n\nV_ isualize prediction models in Train and Validation\n\n\n\n\n\n\nCalculate RMSE in validation for two KNN models\nk = 1\n\nrmse_vec(feat_val_demo$y2, \n         predict(fit_1nn_demo, feat_val_demo)$.pred)\n\n[1] 10.91586\n\n\nk = 5\n\nrmse_vec(feat_val_demo$y2, \n         predict(fit_5nn_demo, feat_val_demo)$.pred)\n\n[1] 8.387035\n\n\n\nWhat if we go the other way and increase \\(k\\) to 75\n\nfit_75nn_demo <- \n  nearest_neighbor(neighbors = 75) |>   \n  set_engine(\"kknn\") |>   \n  set_mode(\"regression\") |> \n  fit(y2 ~ ., data = feat_trn_demo)\n\n\nVisualize prediction models in Train and Validation\n\n#|echo: false\nplot_train <- feat_trn_demo |> \n  bind_cols(data_trn_demo |> select(y, y2_dgp)) |> # add in other outcomes for fig\n  ggplot(aes(x = x, y = y2)) +\n    geom_line(aes(x = x, y = y2_dgp, color = \"blue\"), linewidth = 1.5) +\n    geom_line(aes(x = x, y = predict(fit_5nn_demo, feat_trn_demo)$.pred, \n                  color = \"red\"), linewidth = 1.5) +\n    geom_line(aes(x = x, y = predict(fit_1nn_demo, feat_trn_demo)$.pred, \n                  color = \"green\"), linewidth = 1.5) +\n    geom_line(aes(x = x, y = predict(fit_75nn_demo, feat_trn_demo)$.pred, \n                  color = \"yellow\"), linewidth = 1.5) +\n    geom_point(aes(y = y2), color = \"black\") +\n    scale_color_identity(name = \"Model\",\n                       breaks = c(\"blue\", \"red\", \"green\", \"yellow\"),\n                       labels = c(\"DGP\", \"k = 5\", \"k = 1\", \"k = 75\"),\n                       guide = \"legend\")\n\nplot_val <- feat_val_demo |> \n  bind_cols(data_val_demo |> select(y, y2_dgp)) |> # add in other outcomes for fig\n  ggplot(aes(x = x, y = y2)) +\n    geom_line(aes(x = x, y = y2_dgp, color = \"blue\"), linewidth = 1.5) +\n    geom_line(aes(x = x, y = predict(fit_5nn_demo, feat_val_demo)$.pred, \n                  color = \"red\"), linewidth = 1.5) +\n    geom_line(aes(x = x, y = predict(fit_1nn_demo, feat_val_demo)$.pred, \n                  color = \"green\"), linewidth = 1.5) +\n    geom_line(aes(x = x, y = predict(fit_75nn_demo, feat_val_demo)$.pred, \n                  color = \"yellow\"), linewidth = 1.5) +\n    geom_point(aes(y = y2), color = \"black\") +\n     scale_color_identity(name = \"Model\",\n                       breaks = c(\"blue\", \"red\", \"green\", \"yellow\"),\n                       labels = c(\"DGP\", \"k = 5\", \"k = 1\", \"k = 75\"),\n                       guide = \"legend\")\n\ncowplot::plot_grid(plot_train, plot_val, \n                   labels = list(\"Training Set\", \"Validation Set\"), \n                   ncol = 2, nrow = 1, hjust = -1)\n\n\n\n\n\nCalculate RMSE in validation for three KNN models\nThis is the bias-variance trade-off in action\n\nk = 1 - high variance\n\n\nrmse_vec(feat_val_demo$y2, \n         predict(fit_1nn_demo, feat_val_demo)$.pred)\n\n[1] 10.91586\n\n\n\nk = 5 - just right (well better at least)\n\n\nrmse_vec(feat_val_demo$y2, \n         predict(fit_5nn_demo, feat_val_demo)$.pred)\n\n[1] 8.387035\n\n\n\nk = 75 - high bias\n\n\nrmse_vec(feat_val_demo$y2, \n         predict(fit_75nn_demo, feat_val_demo)$.pred)\n\n[1] 15.34998"
  },
  {
    "objectID": "003_regression.html#discussion",
    "href": "003_regression.html#discussion",
    "title": "3  Introduction to Regression Models",
    "section": "3.9 Discussion",
    "text": "3.9 Discussion\n\nAnnouncements\n\n\nReprex\n\nRead new appendix\nWe now expect reprex for help on application assignments\nWill review in lab next week\n\nHomework is basically same for unit 4\n\nNew dataset - titanic\nDo EDA but we don’t need to see it\nFit KNN and RDA models (will learn about LDA, QDA and RDA in unit)\nSubmit predictions. Free lunch!\nWill know about first free lunch by next Thursday\n\nCourse feedback in quiz as trial\n\n\nQuestions\n\n\nWhat are two broad sources of error?\nWhat are two broad sources of reducible error?\nWhy do we need independent validation data to select the best model configuration?\nWhat factors make the need for a validation set even greater?\nWhat is RMSE? Connect it to metric you already know? How is it being used in lm (two ways)?; in knn (one way)?\nHow does bias and variance manifest when you look at your performance metric (RMSE) in training and validation sets?\nWill the addition of new predictors/features to a (lm?) model always reduce RMSE in train? in validation? Connect to concepts of bias and variance\n\n\nk\n\n\nWhat is it and how does it get used when making predictions?\nWhat is the impact of k on bias and variance/overfitting?\nk=1 - performance in train? in val?\n\n\nInteraction in KNN - Consider bias first (but also variance) in this example\n\n\nSimulate data\nFit models for lm and knn with and without interaction\nTook some shortcuts (no recipe, predict back into train)\n\n\nn <- 200\nset.seed(5433)\n\nd <- tibble(x1 = runif(n, 0,100), # uniform\n               x2 = rep(c(0,1), n/2), # dichotomous\n               x1_x2 = x1*x2, # interaction\n               y = rnorm(n, 0 + 1*x1 + 10*x2 + 10* x1_x2, 20)) #DGP + noise\n\nfit_lm <- \n  linear_reg() |>   \n  set_engine(\"lm\") |>   \n  fit(y ~ x1 + x2, data = d)\n\nfit_lm_int <- \n  linear_reg() |>   \n  set_engine(\"lm\") |>   \n  fit(y ~ x1 + x2 + x1_x2, data = d)\n\nfit_knn <- \n  nearest_neighbor(neighbors = 20) |>   \n  set_engine(\"kknn\") |>   \n  set_mode(\"regression\") |> \n  fit(y ~ x1 + x2, data = d)\n\nfit_knn_int <- \n  nearest_neighbor(neighbors = 20) |>   \n  set_engine(\"kknn\") |>   \n  set_mode(\"regression\") |> \n  fit(y ~ x1 + x2 + x1_x2, data = d)\n\nd <- d |> \n  mutate(pred_lm = predict(fit_lm, d)$.pred,\n         pred_lm_int = predict(fit_lm_int, d)$.pred,\n         pred_knn = predict(fit_knn, d)$.pred,\n         pred_knn_int = predict(fit_knn_int, d)$.pred)\n\n\nPredictions from linear model with and without interaction\n\n\nd |> \n  ggplot(aes(x = x1, group = factor(x2), color = factor(x2))) +\n    geom_line(aes(y = pred_lm)) +\n    geom_point(aes(y = y)) +\n    ggtitle(\"lm without interaction\") +\n    ylab(\"y\") +\n    scale_color_discrete(name = \"x2\")\n\n\n\nd |> \n  ggplot(aes(x = x1, group = factor(x2), color = factor(x2))) +\n    geom_line(aes(y = pred_lm_int)) +\n    geom_point(aes(y = y)) +\n    ggtitle(\"lm with interaction\") +\n    ylab(\"y\") +\n    scale_color_discrete(name = \"x2\")\n\n\n\n\n\nPredictions from linear model with and without interaction\n\n\nd |> \n  ggplot(aes(x = x1, group = factor(x2), color = factor(x2))) +\n    geom_line(aes(y = pred_knn)) +\n    geom_point(aes(y = y)) +\n    ggtitle(\"KNN without interaction\") +\n    ylab(\"y\") +\n    scale_color_discrete(name = \"x2\")\n\n\n\nd |> \n  ggplot(aes(x = x1, group = factor(x2), color = factor(x2))) +\n    geom_line(aes(y = pred_knn_int)) +\n    geom_point(aes(y = y)) +\n    ggtitle(\"KNN with interaction\") +\n    ylab(\"y\") +\n    scale_color_discrete(name = \"x2\")\n\n\n\n\n\nWhat are implications of this for when to use flexible algorithm like knn vs. lm?\n\nif data are high dimensional?\nroutine use?\n\n\n\nTransformations of numeric predictors\n\n\nUse of plot_truth() [predicted vs. observed]\nResiduals do not have mean of 0 for every \\(\\hat{y}\\)\n\nConsequence: biased parameter estimates. Linear is bad DGP\nAlso bad test of questions RE the predictor (underestimate? misinform)\n\nNon-normal residuals\n\nConsequence: lm parameter estimates still unbiased (for linear DGP) but more “efficient” solutions exist\nBad for prediction b/c higher variance than other solutions\nMay suggest omission of variables\n\nHeteroscasticity\n\nConsequence: Inefficient and inaccurate standard errors.\nStatistical tests wrong\nPoor prediction for some (where larger variance of resituals) \\(\\hat{y}\\)\nhigher variance overall than other solutions - bad again for prediction\n\nTransformation of outcome?\n\nmetric\nback to raw predictions\n\n\n\nKNN (black box) for explanatory purposes\n\n\nVisualizations (think of interaction plot above) make clear the effect\nWill learn more (better visualizations, variable importance, model comparisons) in later unit\n\n\nExploration\n\n\n“I feel that I can come up with models that decrease the RMSE, but I don’t have good priors on whether adding any particular variable or observation will result in an improved model. I still feel a little weird just adding and dropping variables into a KNN and seeing what gets the validation RMSE the lowest (even though because we’re using validation techniques it’s a fine technique)”\n\nExploration is learning. This is research. If you knew the answer you wouldn’t be doing the study\nDomain knowledge is still VERY important\nSome algorithms (LASSO, glmnet) will help with feature selection\nstaying organized\n\nScript structure\nGood documentation - RMD as analysis notebook\n\nSome overfitting to validation will occur? Consequence? Solutions?\n\n\n\nLM vs. KNN better with predictors or overall\n\n\n“Why do some features seem to improve performance more in linear models or only in KNNs?”\n“What are some contexts where KNN doesn’t work well? In other words, what are the advantages/disadvantages of using KNN?”\n\nAlways comes down to bias vs. variance\nFlexibility and N are key moderators of these two key factors.\n\nk? - impact on bias, variance?\n\n\n\n“In GLM, why correlation/collinearity among predictors will cause larger variance? Is it because of overfitting?”\n“Curse of dimensionality” - Bias vs. variance\n\n\nMissing features produce biased models.\nUnnecessary features or even many features relative to N produce variance\nDoes your available N in your algorithm support the features you need to have low bias.\n\nMostly an empirical question - can’t really tell otherwise outside of simulated data. Validation set is critical!\nFlexible models often need more N holding predictors constant\nRegularization (unit 6) will work well when lots of predictors\n\n\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2023. An Introduction to Statistical Learning: With Applications in R. 2nd ed. Springer Texts in Statistics. New York: Springer-Verlag."
  },
  {
    "objectID": "003_regression.html#footnotes",
    "href": "003_regression.html#footnotes",
    "title": "3  Introduction to Regression Models",
    "section": "",
    "text": "As you know, the estimation procedure in linear models is OLS. Parameter estimates are derived to minimize the SSE in the data set in which they are derived. For this reason, adding a predictor will never increase RMSE in the training set and it will usually lower it even when it is not part of the DGP. However, this is not true in validation. A predictor will only meaningfully lower RMSE in validation if it is part of the DGP. Also, a bad predictor could even increase RMSE in validation due to overfitting.↩︎\nFor x = 10, find the five observations that have X values closest to 10. Average the Y values for those 5 observations and that is your prediction (\\(\\hat{Y}\\)) associated with that new value of X. Repeat to make predictions for \\(\\hat{Y}\\) for any other value of X, e.g., 50, 90, or any other value↩︎\nSmaller values of \\(k\\) will tend to increase overfitting (and therefore variance across training samples) but decrease bias. Larger values of k will tend to decrease overfitting but increase bias. We need to find the Goldilocks “sweet spot”↩︎\n\\(k\\) = 1 will perfectly fit the training set. Therefore it is very dependent on the training set (high variance). It will fit both the DGP and the noise in the training set. Clearly it will likely not do as well in validation (it will be overfit to training). \\(k\\) needs to be larger if there is more noise (to average over more cases). \\(k\\) needs to be smaller if the relationships are complex. (More on choosing \\(k\\) by resampling in unit 5.↩︎"
  },
  {
    "objectID": "003_regression.html#extension-to-categorical-predictors",
    "href": "003_regression.html#extension-to-categorical-predictors",
    "title": "3  Introduction to Regression Models",
    "section": "3.4 Extension to Categorical Predictors",
    "text": "3.4 Extension to Categorical Predictors\nMany important predictors in our models may be categorical (nominal and some ordinal predictors)\n\nSome statistical algorithms (e.g., random forest) can accept even nominal predictors as features without any further feature engineering\nBut many cannot. Linear models cannot.\nThe type of feature engineering may differ for nominal vs. ordinal categorical predictors\nFor nominal categorical predictors:\n\nWe need to learn a common approach to transform them to numeric features - dummy coding. We will learn the concept in general AND how to accomplish within a feature engineering recipe.\n\nFor ordinal predictors:\n\nWe can treat them like numeric predictors\nWe can treat them like nominal categorical predictors\n\nSee article on Categorical Predictors on the tidymodels website for more details\n\n\n\n3.4.1 Dummy Coding\nFor many algorithms, we will need to use feature engineering to convert a categorical predictor to numeric features. One common technique is to use dummy coding. When dummy coding a predictor, we transform the original categorical predictor with m levels into m-1 dummy coded features.\nTo better understand how and why we do this, lets consider a version of ms_zoning in the Ames dataset.\n\ndata_trn |> \n  pull(ms_zoning) |> \n  table()\n\n\n    agri   commer    float    indus res_high  res_low  res_med \n       2       13       66        1        9     1157      217 \n\n\nWe will recode ms_zoning to have only 3 levels to make our example simple (though dummy codes can be used for predictors with any number of levels)\n\ndata_dummy <- data_trn |> \n  select(sale_price, ms_zoning)  |> # <1>\n  mutate(ms_zoning3 = fct_collapse(ms_zoning, # <2>\n                                 \"residential\" = c(\"res_high\", \"res_med\",\n                                                   \"res_low\"),\n                                 \"commercial\" = c(\"agri\", \"commer\", \"indus\"),\n                                 \"floating\" = \"float\")) |> # <3>\n  select(-ms_zoning) # <4>\n\n\nMake a df (dataframe) with only sale_price and ms_zoning\nfct_collapse() from the forcats package is our preferred way to collapse levels of a factor. See fct_recode() for more generic recoding of levels.\nWe could have left this line out and float would have stayed as a level named float\nRemove original ms_zoning predictor\n\n\nTake a look at the new predictor\n\ndata_dummy |> \n  pull(ms_zoning3) |> \n  table() \n\n\n commercial    floating residential \n         16          66        1383 \n\n\n\n\n\n\n\n\n\nQuestion: Why can’t we simply recode each level with a different consecutive value (e.g., commercial = 1, floating =2 , residential = 3)?\n\n\n\n\n\n\n\nShow Answer\nThere is no meaningful way to order the numbers that we assign to the levels of \nthis unordered categorical predictor.  The shape and strength of the relationship\nbetween it and sale_price will completely change based on arbitrary ordering of \nthe levels.\n\n\n\n\n\n\nImagine fitting a straight line to predict sale_price from ms_zoning3 using these three different ways to arbitrarily assign numbers to levels.\n\ndata_dummy |> \n  mutate(ms_zoning3 = case_when(ms_zoning3 == \"residential\" ~ 1,\n                                ms_zoning3 == \"commercial\" ~ 2,\n                                ms_zoning3 == \"floating\" ~ 3)) |> \n  ggplot(aes(x = ms_zoning3, y = sale_price)) +\n    geom_bar(stat=\"summary\", fun = \"mean\")\n\n\n\n\n\ndata_dummy |> \n  mutate(ms_zoning3 = case_when(ms_zoning3 == \"residential\" ~ 2,\n                                ms_zoning3 == \"commercial\" ~ 1,\n                                ms_zoning3 == \"floating\" ~ 3)) |> \n  ggplot(aes(x = ms_zoning3, y = sale_price)) +\n    geom_bar(stat=\"summary\", fun = \"mean\")\n\n\n\n\n\ndata_dummy |> \n  mutate(ms_zoning3 = case_when(ms_zoning3 == \"residential\" ~ 3,\n                                ms_zoning3 == \"commercial\" ~ 1,\n                                ms_zoning3 == \"floating\" ~ 2)) |> \n  ggplot(aes(x = ms_zoning3, y = sale_price)) +\n    geom_bar(stat=\"summary\", fun = \"mean\")\n\n\n\n\n\nDummy coding resolves this issue.\n\nWhen using dummy codes, we transform (i.e., feature engineer) our original m-level categorical predictor to m-1 dummy features.\nEach of these m-1 features represents a contrast between a specific level of the categorical variable and a reference level\nThe full set of m-1 features represents the overall effect of the categorical predictor variable.\nWe assign values of 0 or 1 to each observation on each feature in a meaningful pattern (see below)\n\n\nFor example, with our three-level predictor: ms_zoning3\n\nWe need 2 dummmy features (d1, d2) to represent this 3-level categorical predictor\nDummy feature 1 is coded 1 for residential and 0 for all other levels\nDummy feature 2 is coded 1 for floating and 0 for all other levels\n\nHere is this coding scheme displayed in a table\n\n\n# A tibble: 3 × 3\n  ms_zoning3     d1    d2\n  <chr>       <dbl> <dbl>\n1 commercial      0     0\n2 residential     1     0\n3 floating        0     1\n\n\n\nWith this coding:\n\nCommercial properties are coded 0 for both d1 and d2.\n\nThis means that commercial properties will become the reference level against which both residential and floating village are compared.\nBecause we are focused on prediction, the choice of reference level is mostly arbitrary. For explanatory goals, you might consider which level is best suited to be the reference.\nThere is much deeper coverage of dummy and other contrast coding in 610/710\n\n\nWe can add these two features manually to the data frame and view a handful of observations to make this coding scheme more concrete\n\n\n# A tibble: 8 × 4\n  sale_price ms_zoning3     d1    d2\n       <dbl> <fct>       <dbl> <dbl>\n1     105000 residential     1     0\n2     126000 residential     1     0\n3      13100 commercial      0     0\n4     115000 residential     1     0\n5     149500 floating        0     1\n6      40000 commercial      0     0\n7     120000 residential     1     0\n8     151000 floating        0     1\n\n\n\nIf we now fit a model where we predict sale_price from these two dummy coded features, each feature would represent the contrast of the mean sale_price for the level coded 1 vs. the mean sale_price for the level that is coded 0 for all features (i.e., commercial)\n\nd1 is the contrast of mean sale_price for residential vs. commercial\nd2 is the contrast of mean sale_price for floating vs. commercial\nThe combined effect of these two features represents the overall effect of ms_zoning3 on sale_price\n\n\nLets do this quickly in base R using lm() as you have done previously in 610.\n\nm <- lm(sale_price ~ d1 + d2, data = data_dummy) \n\nm |> summary()\n\n\nCall:\nlm(formula = sale_price ~ d1 + d2, data = data_dummy)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-166952  -50241  -20241   31254  565259 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    81523      19409   4.200 2.83e-05 ***\nd1             98219      19521   5.031 5.47e-07 ***\nd2            143223      21635   6.620 5.03e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 77640 on 1462 degrees of freedom\nMultiple R-squared:  0.03151,   Adjusted R-squared:  0.03018 \nF-statistic: 23.78 on 2 and 1462 DF,  p-value: 6.858e-11\n\n\n\nThe mean sale price of residential properties is 9.8219^{4} dollars higher than commercial properties.\nThe mean sale price of floating villages is 1.43223^{5} dollars higher than commercial properties.\n\n\nTo understand this conceptually, it is easiest to visualize the linear model that would predict sale_price with these two dichotomous features.\n\nThere are only three columns of sale_price because the only possible values for d1 and d2 (which are both dichotomous) are\n\n0,0 (commercial)\n1,0 (residential)\n0,1 (floating village)\n\nThis regression with two features yields a prediction plane (displayed)\nThe left/right tilt of the plane will be the parameter estimate for d1 and it is the contrast of residential vs. commercial\nThe front/back tilt of the plane will be the parameter estimate for d2 and it is the contrast of floating village vs. commercial\n\n\n\n\n\n\n\nStatistical sidebar:\n\nAny full rank (# levels - 1) set of features regardless of coding system predicts exactly the same (e.g., dummy, helmert, contrast coding)\nPreference among coding systems is simply to get single df contrasts of theoretical importance (i.e., for explanation rather than prediction)\nFinal (mth) dummy feature is not included b/c its is completely redundant (perfectly multicollinear) with other dummy features. This would also prevent a linear model from fitting (‘dummy variable trap’).\nHowever, some statistical algorithms do not have problems with perfect multicollinearity (e.g., LASSO, ridge regression).\n\nFor these algorithms, you will sometimes see modified version of dummy coding called one-hot coding.\n\nThis approach uses one additional dummy coded feature for the final category.\n\nWe won’t spend time on this but you should be familiar with the term b/c it is often confused with dummy coding.\n\n\n\nCoding Sidebar\nWhen creating dummy coded features from factors that have levels with infrequent observations, you may occasionally end up with novel levels in your validation or test sets that were not present in your training set.\n\nThis will cause you issues.\n\nThese issues are mostly resolved if you make sure to explicitly list all possible levels for a factor when classing that factor in the training data, even if the level doesn’t exist in the training data.\n\nWe provide more detail on this issue in an appendix.\n\n\n\n\n3.4.2 Nominal Predictors\nNow that we understand how to use dummy coding to feature engineer nominal predictors, let’s consider some potentially important ones that are available to us.\nWe can discuss if any look promising.\n\nLets return first to ms_zoning\n\ndata_trn |> \n  plot_categorical(\"ms_zoning\", \"sale_price\") |> \n  cowplot::plot_grid(plotlist = _, ncol = 2)\n\nWarning: Groups with fewer than two data points have been dropped.\n\n\n\n\n\nWe might:\n\nRepresent it with 6 dummy features (because there are 7 raw levels) but many of the categories are very low n - won’t account for much variance?\nCombine all the commercial categories (agri, commer, indus), which would take care of most of the low n groups. They also all tend to have the lower prices.\nCombine all the residential to get a better feature to variance accounted ratio. They all tend to have similar prices on average and res_high is also pretty low n. \n\nData dictionary entry: Identifies the general zoning classification of the sale.\n\nagri: Agriculture\ncommer: Commercial\nfloat: Floating Village Residential\nindus: Industrial\nres_high: Residential High Density\nres_med: Residential Medium Density\nres_low: Residential Low Density\n\n\nlot_config\n\ndata_trn |> \n  plot_categorical(\"lot_config\", \"sale_price\") |> \n  cowplot::plot_grid(plotlist = _, ncol = 2)\n\n\n\n\nWe see that:\n\nMost are inside lots, some of the lot categories are low n\nMedian sale_price is not very different between configurations\nNot very promising but could help some (particularly given the large sample size)\n\nData dictionary entry: Lot configuration\n\ninside: Inside lot\ncorner: Corner lot\nculdsac: Cul-de-sac\nfr2: Frontage on 2 sides of property\nfr3: Frontage on 3 sides of property\n\n\nbldg_type\n\ndata_trn |> \n  plot_categorical(\"bldg_type\", \"sale_price\") |> \n  cowplot::plot_grid(plotlist = _, ncol = 2)\n\n\n\n\nWe see that:\n\nMost of the houses are in one category - one_fam\nThere is not much difference in median sale_price among categories\nNot very promising\n\nData dictionary entry: Type of dwelling\n\none_fam: Single-family Detached\n\ntwo_fam: Two-family Conversion; originally built as one-family dwelling\nduplex: Duplex\ntown_end: Townhouse End Unit\ntown_inside: Townhouse Inside Unit\n\n\nLet’s do some feature engineering with ms_zoning. We can now do this formally in a recipe so that it can be used in our modeling workflow.\n\nFirst, if you noticed earlier, there are some levels for ms_zoning that are pretty infrequent. Lets make sure both data_trn and data_val have all levels set for this factor.\n\n\ndata_trn |> pull(ms_zoning) |> levels()\n\n[1] \"agri\"     \"commer\"   \"float\"    \"indus\"    \"res_high\" \"res_low\"  \"res_med\" \n\ndata_val |> pull(ms_zoning) |> levels()\n\n[1] \"commer\"   \"float\"    \"indus\"    \"res_high\" \"res_low\"  \"res_med\" \n\n\n\nAs expected, we are missing a level (agri) in data_val. Lets fix that here\n\n\ndata_val <- data_val |> \n  mutate(ms_zoning = factor(ms_zoning, \n                            levels = c(\"agri\", \"commer\", \"float\", \"indus\", \n                                       \"res_high\", \"res_low\", \"res_med\")))\n\n[Note: Ideally, you would go back to cleaning EDA and add this level to the full dataset and then re-split into training, validation and test. This is a sloppy shortcut!]\n\nWith that fixed, let’s proceed:\n\nWe will collapse categories down to three levels (commercial, residential, floating village) as before but now using step_mutate() combined with fct_collapse() to do this inside of our recipe.\n\nWe will convert to dummy features using step_dummy(). The first level of the factor will be set to the reference level when we call step_dummy().\nstep_dummy() is a poor choice for function name. It actually uses whatever contrast coding we have set up in R. However, the default is are dummy coded contrasts (R calls this treatment contrasts). See ?contrasts and options(\"contrasts\") for more info.\n\n\nrec <- \n  recipe(sale_price ~ gr_liv_area + lot_area + year_built + garage_cars + ms_zoning, \n         data = data_trn) |> \n  step_impute_median(garage_cars) |> \n  step_mutate(ms_zoning = fct_collapse(ms_zoning,\n                                 \"residential\" = c(\"res_high\", \"res_med\", \"res_low\"),\n                                 \"commercial\" = c(\"agri\", \"commer\", \"indus\"),\n                                 \"floating\" = \"float\")) |>\n  step_dummy(ms_zoning)\n\n\nCoding Sidebar\nYou should also read more about some other step_() functions that you might use for categorical predictors: - step_other() to combine all low frequency categories into a single “other” category. - step_unknown() to assign missing values their own category - You can use selector functions. For example, you could make dummy variables out of all of your factors in one step using step_dummy(all_nominal_predictors()).\nSee the Step Functions - Dummy Variables and Encoding section on the tidymodels website for additional useful functions.\nWe have also described these in the section on factor steps in Appendix 1\n\nLet’s see if the addition of ms_zoning helped\n\nNotice the addition of the dummy coded features to the feature matrix\nNotice the removal of the factor ms_zoning\n\n\nrec_prep <- rec |> \n  prep(data_trn)\n\nfeat_trn <- rec_prep |> \n  bake(data_trn)\n\nfeat_val <- rec_prep |> \n  bake(data_val)\n\n\n\nskim\n\n\nfeat_trn |> skim_all()\n\n\nData summary\n\n\nName\nfeat_trn\n\n\nNumber of rows\n1465\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n1506.84\n511.44\n438\n1128\n1450\n1759\n5642\n1.43\n5.19\n\n\nlot_area\n0\n1\n10144.16\n8177.55\n1476\n7500\n9375\n11362\n164660\n11.20\n182.91\n\n\nyear_built\n0\n1\n1971.35\n29.65\n1880\n1953\n1972\n2000\n2010\n-0.54\n-0.62\n\n\ngarage_cars\n0\n1\n1.78\n0.76\n0\n1\n2\n2\n4\n-0.26\n0.10\n\n\nsale_price\n0\n1\n180696.15\n78836.41\n12789\n129500\n160000\n213500\n745000\n1.64\n4.60\n\n\nms_zoning_floating\n0\n1\n0.05\n0.21\n0\n0\n0\n0\n1\n4.38\n17.22\n\n\nms_zoning_residential\n0\n1\n0.94\n0.23\n0\n1\n1\n1\n1\n-3.86\n12.90\n\n\n\n\nfeat_val |> skim_all()\n\n\nData summary\n\n\nName\nfeat_val\n\n\nNumber of rows\n490\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n1493.00\n483.78\n480\n1143.5\n1436.0\n1729.50\n3608\n0.92\n1.16\n\n\nlot_area\n0\n1\n10462.08\n10422.55\n1680\n7500.0\n9563.5\n11780.75\n215245\n15.64\n301.66\n\n\nyear_built\n0\n1\n1971.08\n30.96\n1875\n1954.0\n1975.0\n2000.00\n2010\n-0.66\n-0.41\n\n\ngarage_cars\n0\n1\n1.74\n0.76\n0\n1.0\n2.0\n2.00\n4\n-0.24\n0.22\n\n\nsale_price\n0\n1\n178512.82\n75493.59\n35311\n129125.0\n160000.0\n213000.00\n556581\n1.42\n2.97\n\n\nms_zoning_floating\n0\n1\n0.05\n0.22\n0\n0.0\n0.0\n0.00\n1\n4.07\n14.58\n\n\nms_zoning_residential\n0\n1\n0.93\n0.25\n0\n1.0\n1.0\n1.00\n1\n-3.51\n10.33\n\n\n\n\n\n\n\nNow lets fit a model with these features\n\n\nfit_lm_6 <- \n  linear_reg() |> \n  set_engine(\"lm\") |> \n  fit(sale_price ~ ., data = feat_trn)\n\n\n\nplot it\n\n\nplot_truth(truth = feat_val$sale_price, \n           estimate = predict(fit_lm_6, feat_val)$.pred)\n\n\n\n\n\n\nAnd evaluate it\n\n\n\n# A tibble: 4 × 2\n  model                              rmse_val\n  <chr>                                 <dbl>\n1 simple linear model                  51375.\n2 4 feature linear model               39903.\n3 4 feature linear model with YJ       41660.\n4 6 feature linear model w/ms_zoning   39846.\n\n\n\nRemoving Yeo Johnson transformation but adding dummy coded ms_zoning may have helped a little\n\n\n\n\n\n\n\n\nQuestion: Will the addition of new predictors/features to a model always reduce RMSE in train? in validation?\n\n\n\n\n\n\n\nShow Answer\nAs you know, the estimation procedure in linear models is OLS.  Parameter estimates\nare derived to minimize the SSE in the data set in which they are derived.  For this\nreason, adding a predictor will never increase RMSE in the training set and it will\nusually lower it even when it is not part of the DGP.   However, this is not true in\nvalidation.  A predictor will only meaningfully lower RMSE in validation if it is\npart of the DGP.  Also, a bad predictor could even increase RMSE in validation due to\noverfitting.\n\n\n\n\n\n\n\n\n3.4.3 Ordinal Predictors\nWe have two paths to pursue for ordinal predictors\n\nWe can treat them like nominal predictors (e.g., dummy code)\nWe can treat them like numeric predictors (either raw or with an added transformation if needed)\n\n\nLet’s consider overall_qual\n\ndata_trn |> \n  plot_categorical(\"overall_qual\", \"sale_price\") |> \n  cowplot::plot_grid(plotlist = _, ncol = 2)\n\n\n\n\nObservations:\n\nLow frequency for low and to some degree high quality response options. If dummy coding, may want to collapse some (1-2)\nThere is a monotonic relationship (mostly linear) with sale_price. Treat as numeric?\nNot skewed so doesn’t likely need to be transformed if treated as numeric\nNumeric will take one feature vs. many (9?) features for dummy codes.\n\nDummy codes are more flexible but we may not need this flexibility (and unnecessary flexibility increases overfitting)\n\n\nLet’s add overall_qual to our model as numeric\nRemember that this predictor was ordinal so we paid special attention to the order of the levels when we classed this factor. Lets confirm they are in order\n\ndata_trn |> pull(overall_qual) |> levels()\n\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"\n\n\n\nTo convert overall_qual to numeric (with levels in the specified order), we can use another simple mutate inside our recipe.\n\nrec <- \n  recipe(sale_price ~  ~ gr_liv_area + lot_area + year_built + garage_cars + \n           ms_zoning + overall_qual, data = data_trn) |> \n  step_impute_median(garage_cars) |> \n  step_mutate(ms_zoning = fct_collapse(ms_zoning,\n                                 \"residential\" = c(\"res_high\", \"res_med\", \"res_low\"),\n                                 \"commercial\" = c(\"agri\", \"commer\", \"indus\"),\n                                 \"floating\" = \"float\"),\n              overall_qual = as.numeric(overall_qual)) |>\n  step_dummy(ms_zoning)\n\nCoding Sidebar\nThere is a step function called step_ordinalscore() but it requires that the factor is classed as an ordered factor. It is also more complicated than needed in our opinion. Just use as.numeric()\n\nLet’s evaluate this model\n\nMaking features\nSkipping the skim to save space (we promised we checked it previously!)\n\n\nrec_prep <- rec |> \n  prep(data_trn)\n\nfeat_trn <- rec_prep |> \n  bake(data_trn)\n\nfeat_val <- rec_prep |> \n  bake(data_val)\n\n\n\nFitting model\n\n\nfit_lm_7 <- \n  linear_reg() |> \n  set_engine(\"lm\") |> \n  fit(sale_price ~ ., data = feat_trn)\n\n\n\nPlotting results\n\n\nplot_truth(truth = feat_val$sale_price, \n                                 estimate = predict(fit_lm_7, feat_val)$.pred)\n\n\n\n\n\n\nQuantifying held out error\n\n\n\n# A tibble: 5 × 2\n  model                              rmse_val\n  <chr>                                 <dbl>\n1 simple linear model                  51375.\n2 4 feature linear model               39903.\n3 4 feature linear model with YJ       41660.\n4 6 feature linear model w/ms_zoning   39846.\n5 7 feature linear model               34080.\n\n\n\nThat helped!"
  },
  {
    "objectID": "002_exploratory_data_analysis.html#overview-of-unit",
    "href": "002_exploratory_data_analysis.html#overview-of-unit",
    "title": "2  Exploratory Data Analysis",
    "section": "2.1 Overview of Unit",
    "text": "2.1 Overview of Unit\n\n2.1.1 Learning Objectives\n\nStages of Analysis\nBest practices for data storage, variable classing, data dictionaries\nProblems and solutions regarding data leakage\nKey goals and techniques cleaning EDA\n\nTidying names and response labels\nAppropriate visualizations based on variable class\nSummary statistics based on variable class\n\nProper splitting for training/validation and test sets\nKey goals and techniques modeling EDA\n\nAppropriate visualizations based on variable class\nSummary statistics based on variable class\n\nIntroductory use of recipes for feature engineering\n\n\n\n\n2.1.2 Readings\n[NOTE: These are short chapters. You are reading to understand the framework of visualizing data in R. Don’t feel like you have to memorize the details. These are reference materials that you can turn back to when you need to write code!]\n\nWickham, Çetinkaya-Rundel, and Grolemund (2023) Chapter 1, Data Visualization\nWickham, Çetinkaya-Rundel, and Grolemund (2023) Chapter 9, Layers\nWickham, Çetinkaya-Rundel, and Grolemund (2023) Chapter 10, Exploratory Data Analysis\n\n\n\n2.1.3 Lecture Videos\n\nLecture 1: Stages of Data Analysis and Model Development ~ 10 mins\nLecture 2: Best Practices and Other Recommendations ~ 27 mins\nLecture 3: EDA for Data Cleaning ~ 41 mins\nLecture 4: EDA for Modeling - Univariate ~ 24 mins\nLecture 5: EDA for Modeling - Bivariate ~ 20 mins\nLecture 6: Working with Recipes ~ 13 mins\n\n\nDiscussion\n\nPost questions or discuss readings or lectures in Slack\n\n\n\n2.1.4 Application Assignment\n\ndata\ndata dictionary\ncleaning EDA: qmd\nmodeling EDA: qmd\nsolutions: cleaning EDA; modeling EDA\n\nNote: the qmd files may not be viewable but can be downloaded through your browser (e.g., right-click to save)\nSubmit the application assignment by 8 pm on Wednesday, January 31st\n\n\n2.1.5 Quiz\nSubmit the unit quiz by 8 pm on Wednesday, January 31st"
  },
  {
    "objectID": "002_exploratory_data_analysis.html#overview-of-exploratory-data-analysis",
    "href": "002_exploratory_data_analysis.html#overview-of-exploratory-data-analysis",
    "title": "2  Exploratory Data Analysis",
    "section": "2.2 Overview of Exploratory Data Analysis",
    "text": "2.2 Overview of Exploratory Data Analysis\n\n2.2.1 Stages of Data Analysis and Model Development\nThese are the main stages of data analysis for machine learning and the data that are used\n\nEDA: Cleaning (full dataset)\nEDA: Split data into training, validation and test set(s)\nEDA: Modeling (training sets)\nModel Building: Feature engineering (training sets)\nModel Building: Fit many models configurations (training set)\nModel Building: Evaluate many models configurations (validation sets)\nFinal Model Evaluation: Select final/best model configuration (validation sets)\nFinal Model Evaluation: Fit best model configuration (use both training and validation sets)\nFinal Model Evaluation: Evaluate final model configuration (test sets)\nFinal Model Evaluation: Fit best model configuration to ALL data (training, validation, and test sets) if you plan to use it for applications.\n\n\nThe earlier stages are highly iterative:\n\nYou may iterate some through EDA stages 1-3 if you find further errors to clean in stage 3 [But make sure you resplit into the same sets]\nYou will iterate many times though stages 3-6 as you learn more about your data both through EDA for modeling and evaluating actual models in validation\n\nYou will NOT iterate back to earlier stages after you select a final model configuration\n\nStages 7 - 10 are performed ONLY ONCE\nOnly one model configuration is selected and re-fit and only that model is brought into test for evaluation\nAny more than this is essentially equivalent to p-hacking in traditional analyses\nStep 10 only happens if you plan to use the model in some application"
  },
  {
    "objectID": "002_exploratory_data_analysis.html#best-practices-and-other-recommendations",
    "href": "002_exploratory_data_analysis.html#best-practices-and-other-recommendations",
    "title": "2  Exploratory Data Analysis",
    "section": "2.3 Best Practices and Other Recommendations",
    "text": "2.3 Best Practices and Other Recommendations\n\n2.3.1 Data file formats\nWe generally store data as CSV [comma-separated value] files\n\nEasy to view directly in a text editor\nEasy to share because others can use/import into any data analysis platform\nWorks with version control (e.g. git, svn)\nuse read_csv() and write_csv()\n\nExceptions include:\n\nWe may consider binary (.rds) format for very big files because read/write can be slow for csv files.\n\nBinary file format provides a very modest additional protection for sensitive data (which we also don’t share)\nuse read_rds() and write_rds()\n\nSee chapter 7 - Data Import in Wickham, Çetinkaya-Rundel, and Grolemund (2023) for more details and advanced techniques for importing data using read_csv()\n\n\n\n2.3.2 Classing Variables\nWe store and class variables in R based on their data type (level of measurement).\n\nSee Wikipedia definitions for levels of measurement for a bit more precision that we will provide here.\n\nCoarsely, there are four levels:\n\nnominal: qualitative categories, no inherent order (e.g., marital status, sex, car color)\nordinal: qualitative categories (sometimes uses number), inherent order but not equidistant spacing (e.g., Likert scale; education level)\ninterval and ratio (generally treated the same in social sciences): quantitative scores, ordered, equidistant spacing. Ratio has true 0. (e.g., temperature in Celsius vs. Kelvin scales)\n\nWe generally refer to nominal and ordinal variables as categorical and interval/ratio as quantitative or numeric\n\nFor nominal variables\n\nWe store (in csv files) these variables as character class with descriptive text labels for the levels\n\nEasier to share/document\nReduces errors\n\nWe class these variables in R as factors when we load them (using read_csv())\nIn some cases, we should pay attention to the order of the levels of the variable. e.g.,\n\nFor a dichotomous outcome variable, the positive/event level of dichotomous factor outcome should be first level of the factor\nThe order of levels may also matter for factor predictors (e.g., step_dummy() uses first level as reference).\n\n\n\nFor ordinal variables:\n\nWe store (in csv files) these variables as character class with descriptive text labels for the levels\n\nEasier to share/document\nReduces errors\n\nWe class these variables in R as factors (just like nominal variables)\n\nIt is easier to do EDA with these variables classes as factors\nWe use standard factors (not ordered)\n\nConfirm that the order of the levels is set up correctly. This is very important for ordinal variables.\nDuring feature engineering stage, we can then either\n\nTreat as a nominal variable and create features using step_dummy()\nTreat as an interval variable using step_ordinalscore()\n\n\nSimilar EDA approaches are used with both nominal and ordinal variable\nOrdinal variables may show non-linear relations b/c they may not be evenly spaced. In these instances, we can use feature engineering approaches that are also used for nominal variables\n\nFor interval and ratio variables:\n\nWe store these variables as numeric\nWe class these variables as numeric (either integer or double - let R decide) during the read and clean stage (They are typically already in this class when read in)\n\nSimilar EDA approaches are used with both interval and ratio variables\nSimilar feature engineering approaches are used with both\n\n\n\n2.3.3 Data Dictionaries\nYou should always make a data dictionary for use with your data files.\n\nIdeally, these are created during the planning phase of your study, prior to the start of data collection\nStill useful if created at the start of data analysis\n\nData dictionaries:\n\nhelp you keep track of your variables and their characteristics (e.g., valid ranges, valid responses)\ncan be used by you to check your data during EDA\ncan be provided to others when you share your data (data are not generally useful to others without a data dictionary)\n\nWe will see a variety of data dictionaries throughout the course. Many are not great as you will learn.\n\n\n\n2.3.4 The Ames Housing Prices Dataset\nWe will use the Ames Housing Prices dataset as a running example this unit (and some future units and application assignments as well)\n\nYou can read more about the original dataset created by Dean DeCock\nThe data set contains data from home sales of individual residential property in Ames, Iowa from 2006 to 2010\nThe original data set includes 2930 observations of sales price and a large number of explanatory variables (23 nominal, 23 ordinal, 14 discrete, and 20 continuous)\nThis is the original data dictionary\nThe challenge with this dataset is to build the best possible prediction model for the sale price of the homes.\n\n\n\n\n2.3.5 Packages and Conflicts\nFirst, lets set up our environment with functions from important packages. I strongly recommend reviewing our recommendations for best practices regarding managing function conflicts now. It will save you a lot of headaches in the future.\n\nWe set a conflicts policy that will produce errors if we have unanticipated conflicts.\nWe source a library of functions that we use for common tasks in machine learning.\n\nThis includes a function (tidymodels_conflictRules()) that sets conflict rules to allow us to attach tidymodels functions without conflicts with tidyverse functions.\n\nYou can review that function to see what it does (search for that function name at the link)\n\nThen we use that function\n\n\noptions(conflicts.policy = \"depends.ok\")\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\ntidymodels_conflictRules()\n\n\nNext we load packages for functions that we will use regularly. There are five things to note RE best practices\n\nIf we will use a lot of functions from a package (e.g., tidyverse, tidymodels), we attach the full package\nIf we will use only several functions from a package (but plan to use them repeatedly), we use the include.only parameter to just attach those functions.\nAt times, if we plan to use a single function from a package only 1-2x times, we may not even attach that function at all. Instead, we just call it using its namespace (i.e. packagename::functionname)\nIf a package has a function that conflicts with our primary packages and we don’t plan to use that function, we load the package but exclude the function. If we really needed it, we can call it with its namespace as per option 3 above.\nPay attention to conflicts that were allowed to make sure you understand and accept them. (I left the package messages and warnings in the book this time to see them. I will hide them to avoid cluttering book in later units but you should always review them.)\n\n\n1library(janitor, include.only = \"clean_names\")\n2library(cowplot, include.only = \"plot_grid\")\n3library(kableExtra, exclude = \"group_rows\")\nlibrary(tidyverse) \n4library(tidymodels)\n\n\n1\n\nAs an alternative, we could have skipped loading the package and instead called the function as janitor::clean_names()\n\n2\n\nSame is true for cowplot package\n\n3\n\nWhen loading kableExtra (which we use often), you will always need to exclude groups_rows() to prevent a conflict with dplyr package in the tidyverse\n\n4\n\nLoading tidymodels will produce conflicts unless you source and call my function tidymodels_conflictRules() (see above)\n\n\n\n\n\n\n\n2.3.6 Source and Other Environment Settings\nWe will also source (from github) two other libraries of functions that we use commonly for exploratory data analyses. You should review these function scripts (fun_eda.R; fun_plots.R to see the code for these functions.\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true\")\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_plots.R?raw=true\")\n\n\nFinally, we tune our environment a bit more by setting plot themes and print options that we prefer\n\ntheme_set(theme_classic())\noptions(tibble.width = Inf, tibble.print_max = Inf)\n\nAnd we set a relative path to our data. This assumes you are using an RStudio project with the path to the data relative to that project file. I’ve provided more detail elsewhere on best practices for managing files and paths.\n\npath_data &lt;- \"data\"\n\n\n\n\n2.3.7 Read and Glimpse Dataframe\nLets read in the data and glimpse the subset of observations we will work with in Units 2-3 and the first two application assignments.\n\n1data_all &lt;- read_csv(here::here(path_data, \"ames_raw_class.csv\"),\n2                     col_types = cols()) |&gt;\n3  glimpse()\n\n\n1\n\nFirst we read data using a relative path and the here::here() function. This is a replacement for file.path() that works better for both interactive use and rendering in Quarto when using projects.\n\n2\n\nWe use col_types = cols() to let R guess the correct class for each column. This suppresses messages that aren’t important at this point prior to EDA.\n\n3\n\nIt is good practice to always glimpse() data after you read it.\n\n\n\n\nRows: 1,955\nColumns: 81\n$ PID               &lt;chr&gt; \"0526301100\", \"0526350040\", \"0526351010\", \"052710501…\n$ `MS SubClass`     &lt;chr&gt; \"020\", \"020\", \"020\", \"060\", \"120\", \"120\", \"120\", \"06…\n$ `MS Zoning`       &lt;chr&gt; \"RL\", \"RH\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\"…\n$ `Lot Frontage`    &lt;dbl&gt; 141, 80, 81, 74, 41, 43, 39, 60, 75, 63, 85, NA, 47,…\n$ `Lot Area`        &lt;dbl&gt; 31770, 11622, 14267, 13830, 4920, 5005, 5389, 7500, …\n$ Street            &lt;chr&gt; \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pav…\n$ Alley             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ `Lot Shape`       &lt;chr&gt; \"IR1\", \"Reg\", \"IR1\", \"IR1\", \"Reg\", \"IR1\", \"IR1\", \"Re…\n$ `Land Contour`    &lt;chr&gt; \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"HLS\", \"Lvl\", \"Lv…\n$ Utilities         &lt;chr&gt; \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"A…\n$ `Lot Config`      &lt;chr&gt; \"Corner\", \"Inside\", \"Corner\", \"Inside\", \"Inside\", \"I…\n$ `Land Slope`      &lt;chr&gt; \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gt…\n$ Neighborhood      &lt;chr&gt; \"NAmes\", \"NAmes\", \"NAmes\", \"Gilbert\", \"StoneBr\", \"St…\n$ `Condition 1`     &lt;chr&gt; \"Norm\", \"Feedr\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"No…\n$ `Condition 2`     &lt;chr&gt; \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Nor…\n$ `Bldg Type`       &lt;chr&gt; \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"TwnhsE\", \"TwnhsE\", …\n$ `House Style`     &lt;chr&gt; \"1Story\", \"1Story\", \"1Story\", \"2Story\", \"1Story\", \"1…\n$ `Overall Qual`    &lt;dbl&gt; 6, 5, 6, 5, 8, 8, 8, 7, 6, 6, 7, 8, 8, 8, 9, 4, 6, 6…\n$ `Overall Cond`    &lt;dbl&gt; 5, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 2, 5, 6, 6…\n$ `Year Built`      &lt;dbl&gt; 1960, 1961, 1958, 1997, 2001, 1992, 1995, 1999, 1993…\n$ `Year Remod/Add`  &lt;dbl&gt; 1960, 1961, 1958, 1998, 2001, 1992, 1996, 1999, 1994…\n$ `Roof Style`      &lt;chr&gt; \"Hip\", \"Gable\", \"Hip\", \"Gable\", \"Gable\", \"Gable\", \"G…\n$ `Roof Matl`       &lt;chr&gt; \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg…\n$ `Exterior 1st`    &lt;chr&gt; \"BrkFace\", \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"CemntBd…\n$ `Exterior 2nd`    &lt;chr&gt; \"Plywood\", \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"CmentBd…\n$ `Mas Vnr Type`    &lt;chr&gt; \"Stone\", \"None\", \"BrkFace\", \"None\", \"None\", \"None\", …\n$ `Mas Vnr Area`    &lt;dbl&gt; 112, 0, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 603, 0, 350,…\n$ `Exter Qual`      &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"Gd\", \"Gd\", \"Gd\", \"TA\", \"TA\"…\n$ `Exter Cond`      &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\"…\n$ Foundation        &lt;chr&gt; \"CBlock\", \"CBlock\", \"CBlock\", \"PConc\", \"PConc\", \"PCo…\n$ `Bsmt Qual`       &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"Gd\", \"Gd\", \"Gd\", \"Gd\", \"TA\", \"Gd\"…\n$ `Bsmt Cond`       &lt;chr&gt; \"Gd\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\"…\n$ `Bsmt Exposure`   &lt;chr&gt; \"Gd\", \"No\", \"No\", \"No\", \"Mn\", \"No\", \"No\", \"No\", \"No\"…\n$ `BsmtFin Type 1`  &lt;chr&gt; \"BLQ\", \"Rec\", \"ALQ\", \"GLQ\", \"GLQ\", \"ALQ\", \"GLQ\", \"Un…\n$ `BsmtFin SF 1`    &lt;dbl&gt; 639, 468, 923, 791, 616, 263, 1180, 0, 0, 0, 637, 36…\n$ `BsmtFin Type 2`  &lt;chr&gt; \"Unf\", \"LwQ\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Un…\n$ `BsmtFin SF 2`    &lt;dbl&gt; 0, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1120, 0, 0, 0, 0,…\n$ `Bsmt Unf SF`     &lt;dbl&gt; 441, 270, 406, 137, 722, 1017, 415, 994, 763, 789, 6…\n$ `Total Bsmt SF`   &lt;dbl&gt; 1080, 882, 1329, 928, 1338, 1280, 1595, 994, 763, 78…\n$ Heating           &lt;chr&gt; \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"Gas…\n$ `Heating QC`      &lt;chr&gt; \"Fa\", \"TA\", \"TA\", \"Gd\", \"Ex\", \"Ex\", \"Ex\", \"Gd\", \"Gd\"…\n$ `Central Air`     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y…\n$ Electrical        &lt;chr&gt; \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\"…\n$ `1st Flr SF`      &lt;dbl&gt; 1656, 896, 1329, 928, 1338, 1280, 1616, 1028, 763, 7…\n$ `2nd Flr SF`      &lt;dbl&gt; 0, 0, 0, 701, 0, 0, 0, 776, 892, 676, 0, 0, 1589, 67…\n$ `Low Qual Fin SF` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ `Gr Liv Area`     &lt;dbl&gt; 1656, 896, 1329, 1629, 1338, 1280, 1616, 1804, 1655,…\n$ `Bsmt Full Bath`  &lt;dbl&gt; 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0…\n$ `Bsmt Half Bath`  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ `Full Bath`       &lt;dbl&gt; 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 2, 1, 1, 2, 2…\n$ `Half Bath`       &lt;dbl&gt; 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0…\n$ `Bedroom AbvGr`   &lt;dbl&gt; 3, 2, 3, 3, 2, 2, 2, 3, 3, 3, 2, 1, 4, 4, 1, 2, 3, 3…\n$ `Kitchen AbvGr`   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ `Kitchen Qual`    &lt;chr&gt; \"TA\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Gd\", \"Gd\", \"TA\"…\n$ `TotRms AbvGrd`   &lt;dbl&gt; 7, 5, 6, 6, 6, 5, 5, 7, 7, 7, 5, 4, 12, 8, 8, 4, 7, …\n$ Functional        &lt;chr&gt; \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Ty…\n$ Fireplaces        &lt;dbl&gt; 2, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1…\n$ `Fireplace Qu`    &lt;chr&gt; \"Gd\", NA, NA, \"TA\", NA, NA, \"TA\", \"TA\", \"TA\", \"Gd\", …\n$ `Garage Type`     &lt;chr&gt; \"Attchd\", \"Attchd\", \"Attchd\", \"Attchd\", \"Attchd\", \"A…\n$ `Garage Yr Blt`   &lt;dbl&gt; 1960, 1961, 1958, 1997, 2001, 1992, 1995, 1999, 1993…\n$ `Garage Finish`   &lt;chr&gt; \"Fin\", \"Unf\", \"Unf\", \"Fin\", \"Fin\", \"RFn\", \"RFn\", \"Fi…\n$ `Garage Cars`     &lt;dbl&gt; 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2…\n$ `Garage Area`     &lt;dbl&gt; 528, 730, 312, 482, 582, 506, 608, 442, 440, 393, 50…\n$ `Garage Qual`     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\"…\n$ `Garage Cond`     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\"…\n$ `Paved Drive`     &lt;chr&gt; \"P\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y…\n$ `Wood Deck SF`    &lt;dbl&gt; 210, 140, 393, 212, 0, 0, 237, 140, 157, 0, 192, 0, …\n$ `Open Porch SF`   &lt;dbl&gt; 62, 0, 36, 34, 0, 82, 152, 60, 84, 75, 0, 54, 36, 12…\n$ `Enclosed Porch`  &lt;dbl&gt; 0, 0, 0, 0, 170, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `3Ssn Porch`      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ `Screen Porch`    &lt;dbl&gt; 0, 120, 0, 0, 0, 144, 0, 0, 0, 0, 0, 140, 210, 0, 0,…\n$ `Pool Area`       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ `Pool QC`         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Fence             &lt;chr&gt; NA, \"MnPrv\", NA, \"MnPrv\", NA, NA, NA, NA, NA, NA, NA…\n$ `Misc Feature`    &lt;chr&gt; NA, NA, \"Gar2\", NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ `Misc Val`        &lt;dbl&gt; 0, 0, 12500, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ `Mo Sold`         &lt;dbl&gt; 5, 6, 6, 3, 4, 1, 3, 6, 4, 5, 2, 6, 6, 6, 6, 6, 2, 1…\n$ `Yr Sold`         &lt;dbl&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010…\n$ `Sale Type`       &lt;chr&gt; \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\"…\n$ `Sale Condition`  &lt;chr&gt; \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"N…\n$ SalePrice         &lt;dbl&gt; 215000, 105000, 172000, 189900, 213500, 191500, 2365…\n\n\n\nDataset Notes:\n\nDataset has N = 1955 rather than 2930.\n\nI have held out remaining observations to serve as a test set for a friendly competition in Unit 3\nI will judge your models’ performance with this test set at that time!\nMore on the importance of held out test sets as we progress through the course\n\nThis full dataset has 81 variables. For the lecture examples in units 2-3 we will only use a subset of the predictors\nYou will use different predictors in the next two application assignments\n\n\nHere we select the variables we will use for lecture\n\ndata_all &lt;- data_all |&gt; \n  select(SalePrice,\n         `Gr Liv Area`, \n         `Lot Area`, \n         `Year Built`, \n         `Overall Qual`, \n         `Garage Cars`,\n         `Garage Qual`,\n         `MS Zoning`,\n         `Lot Config` ,\n1         `Bldg Type`) |&gt;\n  glimpse()\n\n\n1\n\nNotice that the dataset used non-standard variable names that include spaces. We need to use back-ticks around the variable names to allow us reference those variables. We will fix this during the cleaning process and you should never use spaces in variable names when setting up your own data!!!\n\n\n\n\nRows: 1,955\nColumns: 10\n$ SalePrice      &lt;dbl&gt; 215000, 105000, 172000, 189900, 213500, 191500, 236500,…\n$ `Gr Liv Area`  &lt;dbl&gt; 1656, 896, 1329, 1629, 1338, 1280, 1616, 1804, 1655, 14…\n$ `Lot Area`     &lt;dbl&gt; 31770, 11622, 14267, 13830, 4920, 5005, 5389, 7500, 100…\n$ `Year Built`   &lt;dbl&gt; 1960, 1961, 1958, 1997, 2001, 1992, 1995, 1999, 1993, 1…\n$ `Overall Qual` &lt;dbl&gt; 6, 5, 6, 5, 8, 8, 8, 7, 6, 6, 7, 8, 8, 8, 9, 4, 6, 6, 7…\n$ `Garage Cars`  &lt;dbl&gt; 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2…\n$ `Garage Qual`  &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"…\n$ `MS Zoning`    &lt;chr&gt; \"RL\", \"RH\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"…\n$ `Lot Config`   &lt;chr&gt; \"Corner\", \"Inside\", \"Corner\", \"Inside\", \"Inside\", \"Insi…\n$ `Bldg Type`    &lt;chr&gt; \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"TwnhsE\", \"TwnhsE\", \"Tw…"
  },
  {
    "objectID": "002_exploratory_data_analysis.html#exploratory-data-analysis-for-data-cleaning",
    "href": "002_exploratory_data_analysis.html#exploratory-data-analysis-for-data-cleaning",
    "title": "2  Exploratory Data Analysis",
    "section": "2.4 Exploratory Data Analysis for Data Cleaning",
    "text": "2.4 Exploratory Data Analysis for Data Cleaning\nEDA could be done using either tidyverse packages and functions or tidymodels (mostly using the recipes package.)\n\nWe prefer to use the richer set of functions available in the tidyverse (and dplyr and purrr packages in particular).\nWe will reserve the use of recipes for feature engineering only when we are building features for models that we will fit in our training sets and evaluation in our validation and test sets.\n\n\n\n2.4.1 Data Leakage Issues\nData leakage refers to a mistake made by the developer of a machine learning model in which they accidentally share information between their training set and held-out validation or test sets\n\nTraining sets are used to fit models with different configurations\nValidation sets are used to select the best model among those with different configurations (not needed if you only have one configuration)\nTest sets are used to evaluate a best model\nWhen splitting data-sets into training, validation and test sets, the goal is to ensure that no data (or information more broadly) are shared between the three sets\n\nNo data or information from test should influence either fitting or selecting models\nTest should only be used once to evaluate a best/final model\nTrain and validation set also must be segregated (although validation sets may be used to evaluate many model configurations)\nInformation necessary for transformations and other feature engineering (e.g., means/sds for centering/scaling, procedures for missing data imputation) must all be based only on training data.\nData leakage is common if you are not careful.\n\n\nIn particular, if we begin to use test data or information about test during model fitting\n\nWe risk overfitting\nThis is essentially the equivalent of p-hacking in traditional analyses\nOur estimate of model performance will be too optimistic, which could have harmful real-world consequences.\n\n\n\n\n2.4.2 Tidy variable names\nUse snake case for variable names\n\nclean_names() from janitor package is useful for this.\nMay need to do further correction of variable names using rename()\nSee more details about tidy names for objects (e.g., variables, dfs, functions) per Tidy Style Guide\n\n\ndata_all &lt;- data_all |&gt; \n  clean_names(\"snake\")\n\ndata_all |&gt; names()\n\n [1] \"sale_price\"   \"gr_liv_area\"  \"lot_area\"     \"year_built\"   \"overall_qual\"\n [6] \"garage_cars\"  \"garage_qual\"  \"ms_zoning\"    \"lot_config\"   \"bldg_type\"   \n\n\n\n\n\n2.4.3 Explore variable classes\nAt this point, we should class all of our variables as either numeric or factor\n\nInterval and ratio variables use numeric classes (dbl or int)\nNominal and ordinal variable use factor class\nUseful for variable selection later (e.g., where(is.numeric), where(is.factor))\n\nSubsequent cleaning steps are clearer if we have this established/confirmed now\n\nWe have a number of nominal or ordinal variables that are classed as character.\nWe have one ordinal variable (overall_qual) that is classed as numeric (because the levels were coded with numbers rather than text)\n\nread_csv() thought was numeric by the levels are coded using numbers\nThe data dictionary indicates that valid values range from 1 - 10.\n\n\ndata_all |&gt; glimpse()\n\nRows: 1,955\nColumns: 10\n$ sale_price   &lt;dbl&gt; 215000, 105000, 172000, 189900, 213500, 191500, 236500, 1…\n$ gr_liv_area  &lt;dbl&gt; 1656, 896, 1329, 1629, 1338, 1280, 1616, 1804, 1655, 1465…\n$ lot_area     &lt;dbl&gt; 31770, 11622, 14267, 13830, 4920, 5005, 5389, 7500, 10000…\n$ year_built   &lt;dbl&gt; 1960, 1961, 1958, 1997, 2001, 1992, 1995, 1999, 1993, 199…\n$ overall_qual &lt;dbl&gt; 6, 5, 6, 5, 8, 8, 8, 7, 6, 6, 7, 8, 8, 8, 9, 4, 6, 6, 7, …\n$ garage_cars  &lt;dbl&gt; 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, …\n$ garage_qual  &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA…\n$ ms_zoning    &lt;chr&gt; \"RL\", \"RH\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL…\n$ lot_config   &lt;chr&gt; \"Corner\", \"Inside\", \"Corner\", \"Inside\", \"Inside\", \"Inside…\n$ bldg_type    &lt;chr&gt; \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"TwnhsE\", \"TwnhsE\", \"Twnh…\n\n\n\nWe can the recode overall_qual first and set its levels\nWe can recode all the character variables to factor in one step. Most are nominal. We will handle the order for garage_qual later.\n\n1oq_levels &lt;- 1:10\n\ndata_all &lt;-  data_all |&gt; \n  mutate(overall_qual = factor(overall_qual, \n2                               levels = oq_levels)) |&gt;\n3  mutate(across(where(is.character), factor)) |&gt;\n  glimpse()\n\n\n1\n\nIt is always best to explicitly set the levels of an ordinal factor in the order you prefer. It is not necessary here because overall_qual was numeric and therefore sorts in the expected order. However, if it had been numbers stored as characters, it could sort incorrectly (e.g., 1, 10, 2, 3, …). And obviously if the orders levels were names, the order would have to be specified.\n\n2\n\nWe indicate the levels here.\n\n3\n\nWe use a mutate to re-class all character data to factors. I prefer factor() to forcats::fct() because factor orders the levels alphabetically. Be aware that this could change if your code is used in a region of the world where this sorting is different. I still prefer this to the alternative (in fct()) that orders by the order the levels are found in your data.\n\n\n\n\nRows: 1,955\nColumns: 10\n$ sale_price   &lt;dbl&gt; 215000, 105000, 172000, 189900, 213500, 191500, 236500, 1…\n$ gr_liv_area  &lt;dbl&gt; 1656, 896, 1329, 1629, 1338, 1280, 1616, 1804, 1655, 1465…\n$ lot_area     &lt;dbl&gt; 31770, 11622, 14267, 13830, 4920, 5005, 5389, 7500, 10000…\n$ year_built   &lt;dbl&gt; 1960, 1961, 1958, 1997, 2001, 1992, 1995, 1999, 1993, 199…\n$ overall_qual &lt;fct&gt; 6, 5, 6, 5, 8, 8, 8, 7, 6, 6, 7, 8, 8, 8, 9, 4, 6, 6, 7, …\n$ garage_cars  &lt;dbl&gt; 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, …\n$ garage_qual  &lt;fct&gt; TA, TA, TA, TA, TA, TA, TA, TA, TA, TA, TA, TA, TA, TA, T…\n$ ms_zoning    &lt;fct&gt; RL, RH, RL, RL, RL, RL, RL, RL, RL, RL, RL, RL, RL, RL, R…\n$ lot_config   &lt;fct&gt; Corner, Inside, Corner, Inside, Inside, Inside, Inside, I…\n$ bldg_type    &lt;fct&gt; 1Fam, 1Fam, 1Fam, 1Fam, TwnhsE, TwnhsE, TwnhsE, 1Fam, 1Fa…\n\n\n\n\n\n2.4.4 Skimming the data\nskim() from the skimr package is a wonderful and customizable function for summary statistics\n\nIt is highly customizable so we can write our own versions for our own needs\nWe use different versions for cleaning and modeling EDA\nFor cleaning EDA, we just remove some stats that we don’t want to see at this time\nWe can get many of the summary stats for cleaning in one call\nWe have a custom skim defined in the fun_eda.R function library that we use regularly. Here is the code but you can use the function directly if you sourced fun_eda.R (as we did above)\n\n\nskim_some &lt;- skim_with(numeric = sfl(mean = NULL, sd = NULL, p25 = NULL, p50 = NULL, p75 = NULL, hist = NULL))\n\n\nHere is what we get with our new skim_some() function\n\nWe will refer to this again for each characteristic we want to review for instructional purposes\nWe can already see that we can use skim_some() to confirm that we only have numeric and factor classes\n\n\ndata_all |&gt; \n  skim_some()\n\n\n\n\nData summary\n\n\n\n\nName\n\n\ndata_all\n\n\n\n\nNumber of rows\n\n\n1955\n\n\n\n\nNumber of columns\n\n\n10\n\n\n\n\n_______________________\n\n\n\n\n\n\nColumn type frequency:\n\n\n\n\n\n\nfactor\n\n\n5\n\n\n\n\nnumeric\n\n\n5\n\n\n\n\n________________________\n\n\n\n\n\n\nGroup variables\n\n\nNone\n\n\n\n\n\nVariable type: factor\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nordered\n\n\nn_unique\n\n\ntop_counts\n\n\n\n\n\n\noverall_qual\n\n\n0\n\n\n1.00\n\n\nFALSE\n\n\n10\n\n\n5: 556, 6: 487, 7: 403, 8: 233\n\n\n\n\ngarage_qual\n\n\n109\n\n\n0.94\n\n\nFALSE\n\n\n5\n\n\nTA: 1745, Fa: 79, Gd: 16, Po: 4\n\n\n\n\nms_zoning\n\n\n0\n\n\n1.00\n\n\nFALSE\n\n\n7\n\n\nRL: 1530, RM: 297, FV: 91, C (: 19\n\n\n\n\nlot_config\n\n\n0\n\n\n1.00\n\n\nFALSE\n\n\n5\n\n\nIns: 1454, Cor: 328, Cul: 114, FR2: 55\n\n\n\n\nbldg_type\n\n\n0\n\n\n1.00\n\n\nFALSE\n\n\n5\n\n\n1Fa: 1631, Twn: 145, Dup: 77, Twn: 64\n\n\n\n\n\nVariable type: numeric\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\np0\n\n\np100\n\n\n\n\n\n\nsale_price\n\n\n0\n\n\n1\n\n\n12789\n\n\n745000\n\n\n\n\ngr_liv_area\n\n\n0\n\n\n1\n\n\n438\n\n\n5642\n\n\n\n\nlot_area\n\n\n0\n\n\n1\n\n\n1476\n\n\n215245\n\n\n\n\nyear_built\n\n\n0\n\n\n1\n\n\n1875\n\n\n2010\n\n\n\n\ngarage_cars\n\n\n1\n\n\n1\n\n\n0\n\n\n4\n\n\n\n\n\n\n\n\nCoding sidebar 1:\n\nWrite functions whenever you will repeat code often. You can now reuse skim_some()\nskim_with() is an example of a function factory - a function that is used to create a new function\n\npartial() and compose() are two other function factories we will use at times\nMore details on function factories is available in Advanced R\n\n\n\nCoding sidebar 2:\n\nGather useful functions together in a script that you can reuse.\nAll of the reusable functions in this and later units are available to you in one of my public github repositories.\nYou can load these functions into your workspace directly from github using devtools::source_url(). For example: devtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_modeling.R?raw=true\")\nYou should start to gather your favorite custom functions together in your own script(s).\n\nYou can save your own scripts in a local file and load them into your workspace using source() or you can make your own github repo so you can begin to share your code with others!\n\n\n\n\n2.4.5 Missing Data - All variables\nskim_some() provides us with missing data counts and complete data proportions for each variable\n\ndata_all |&gt; \n  skim_some() |&gt; \n1  select(skim_variable, n_missing, complete_rate)\n\n\n1\n\nskim_some() returns a dataframe so you can select only the subset of columns to focus its output on what you want. Or just print it all!\n\n\n\n\n# A tibble: 10 × 3\n   skim_variable n_missing complete_rate\n   &lt;chr&gt;             &lt;int&gt;         &lt;dbl&gt;\n 1 overall_qual          0         1    \n 2 garage_qual         109         0.944\n 3 ms_zoning             0         1    \n 4 lot_config            0         1    \n 5 bldg_type             0         1    \n 6 sale_price            0         1    \n 7 gr_liv_area           0         1    \n 8 lot_area              0         1    \n 9 year_built            0         1    \n10 garage_cars           1         0.999\n\n\n\nYou likely should view the full observation for missing values\nWe will show you a few methods to do this in your rendered output\n\nprint() will print only 20 rows and the number of columns that will display for width of page\n\nSet options() if you will do a lot of printing and want full dataframe printed\n\nUse kbl() from kableExtra package for formatted tables (two methods below)\n\nDon’t forget that you can also use View() interactively in R Studio\n\nOption 1 (Simple): Use print() with options()\n\n1options(tibble.width = Inf, tibble.print_max = Inf)\n\ndata_all |&gt; filter(is.na(garage_cars)) |&gt; \n  print()\n\n\n1\n\nThis sets print to print all rows and columns. Note that we set these options at the start of the unit b.c. we like to see our full tibbles. If we want only a subset of the first (or last) rows, we use head() or tail()\n\n\n\n\n# A tibble: 1 × 10\n  sale_price gr_liv_area lot_area year_built overall_qual garage_cars\n       &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;fct&gt;              &lt;dbl&gt;\n1     150909        1828     9060       1923 5                     NA\n  garage_qual ms_zoning lot_config bldg_type\n  &lt;fct&gt;       &lt;fct&gt;     &lt;fct&gt;      &lt;fct&gt;    \n1 &lt;NA&gt;        RM        Inside     1Fam     \n\n\n\nHere are some more advanced options using kbl() for the df with many rows\n\nkable() tables from knitr package and kableExtra extensions (including kbl()) are very useful during EDA and also final publication quality tables\nuse library(kableExtra)\nsee vignettes for kableExtra\n\nOption 2 (more advanced): Use a function for kables that we created. Code is displayed here but the function is available to you if you source fun_eda.R from Github\n\n# Might want to use height = \"100%\" if only printing a few rows\n1print_kbl &lt;- function(data, height = \"500px\") {\n  data |&gt; \n    kbl(align = \"r\") |&gt; \n    kable_styling(bootstrap_options = c(\"striped\", \"condensed\")) |&gt; \n2    scroll_box(height = height, width = \"100%\")\n}\n\n\n1\n\nDefaults to a output box of height = “500px”. Can set to other values if preferred.\n\n2\n\nMight want to use height = \"100%\" if only printing a few rows.\n\n\n\n\n\nLet’s use this function to see its output\n\ndata_all |&gt; filter(is.na(garage_qual)) |&gt; \n  print_kbl()\n\n\n\n\n\nsale_price\ngr_liv_area\nlot_area\nyear_built\noverall_qual\ngarage_cars\ngarage_qual\nms_zoning\nlot_config\nbldg_type\n\n\n\n\n115000\n864\n10500\n1971\n4\n0\nNA\nRL\nFR2\n1Fam\n\n\n128950\n1225\n9320\n1959\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n84900\n1728\n13260\n1962\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n116500\n858\n7207\n1958\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n76500\n1306\n5350\n1940\n3\n0\nNA\nRL\nInside\n1Fam\n\n\n76500\n2256\n9045\n1910\n5\n0\nNA\nRM\nInside\n2fmCon\n\n\n159900\n1560\n12900\n1912\n6\n0\nNA\nRM\nInside\n1Fam\n\n\n55000\n1092\n5600\n1930\n4\n0\nNA\nRM\nInside\n2fmCon\n\n\n93369\n1884\n6449\n1907\n4\n0\nNA\nC (all)\nInside\n1Fam\n\n\n94000\n1020\n6342\n1875\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n136000\n1832\n10773\n1967\n4\n0\nNA\nRL\nInside\nDuplex\n\n\n100000\n1664\n9825\n1965\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n90000\n960\n6410\n1958\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n100000\n1666\n9839\n1931\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n139000\n1824\n9400\n1971\n6\n0\nNA\nRL\nCorner\nDuplex\n\n\n76000\n1092\n1476\n1970\n4\n0\nNA\nRM\nInside\nTwnhs\n\n\n75500\n630\n1491\n1972\n4\n0\nNA\nRM\nInside\nTwnhsE\n\n\n88250\n1092\n1900\n1970\n4\n0\nNA\nRM\nInside\nTwnhsE\n\n\n136000\n1792\n9000\n1974\n5\n0\nNA\nRL\nFR2\nDuplex\n\n\n142000\n1114\n13072\n2004\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n82500\n708\n5330\n1940\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n129000\n1464\n9900\n1910\n5\n0\nNA\nRM\nCorner\n1Fam\n\n\n94550\n1701\n7627\n1920\n4\n0\nNA\nRM\nCorner\n2fmCon\n\n\n103000\n1447\n10134\n1910\n5\n0\nNA\nRM\nInside\n1Fam\n\n\n37900\n968\n5925\n1910\n3\n0\nNA\nRM\nInside\n1Fam\n\n\n113000\n1452\n4456\n1920\n4\n0\nNA\nRM\nInside\n2fmCon\n\n\n58500\n816\n3300\n1910\n4\n0\nNA\nC (all)\nInside\n1Fam\n\n\n34900\n720\n7879\n1920\n4\n0\nNA\nC (all)\nInside\n1Fam\n\n\n60000\n800\n6120\n1936\n2\n0\nNA\nRM\nInside\n1Fam\n\n\n62500\n2128\n3000\n1922\n5\n0\nNA\nRM\nInside\nDuplex\n\n\n97500\n1864\n5852\n1902\n7\n0\nNA\nRM\nCorner\n2fmCon\n\n\n70000\n892\n5160\n1923\n4\n0\nNA\nRM\nInside\n1Fam\n\n\n179000\n1200\n10800\n1987\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n179000\n1200\n10800\n1987\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n61000\n904\n10020\n1922\n1\n0\nNA\nRL\nInside\n1Fam\n\n\n118000\n698\n9405\n1947\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n99900\n864\n4060\n1922\n5\n0\nNA\nRL\nCorner\n1Fam\n\n\n119900\n1678\n10926\n1959\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n112000\n833\n8780\n1985\n5\n0\nNA\nRL\nCorner\n1Fam\n\n\n141000\n1080\n7500\n2004\n7\n0\nNA\nRL\nInside\n1Fam\n\n\n106250\n1294\n10800\n1900\n4\n0\nNA\nRL\nInside\n2fmCon\n\n\n130000\n1800\n8513\n1961\n5\n0\nNA\nRL\nCorner\nDuplex\n\n\n120000\n1027\n5400\n1920\n7\n0\nNA\nRM\nInside\n1Fam\n\n\n95000\n1080\n5914\n1890\n5\n0\nNA\nRM\nInside\n1Fam\n\n\n65000\n1588\n12205\n1949\n3\n0\nNA\nRM\nInside\n1Fam\n\n\n129400\n1540\n6000\n1905\n5\n0\nNA\nRM\nCorner\n1Fam\n\n\n160000\n1984\n8094\n1910\n6\n1\nNA\nRM\nInside\n2fmCon\n\n\n89500\n1406\n7920\n1920\n6\n0\nNA\nRM\nInside\n1Fam\n\n\n79900\n1198\n5586\n1920\n6\n0\nNA\nRM\nInside\n1Fam\n\n\n82375\n1344\n10320\n1915\n3\n0\nNA\nRM\nInside\n2fmCon\n\n\n127500\n1355\n10106\n1940\n5\n0\nNA\nRL\nInside\n2fmCon\n\n\n80000\n1006\n9000\n1959\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n260000\n1518\n19550\n1940\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n99600\n864\n9350\n1975\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n107500\n1347\n7000\n1910\n5\n0\nNA\nRL\nInside\n2fmCon\n\n\n79000\n1096\n9600\n1924\n6\n0\nNA\nRL\nCorner\n1Fam\n\n\n85000\n796\n8777\n1910\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n145900\n2200\n8777\n1900\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n82000\n1152\n6040\n1955\n4\n0\nNA\nRL\nInside\nDuplex\n\n\n82000\n1152\n6012\n1955\n4\n0\nNA\nRL\nCorner\nDuplex\n\n\n118000\n1440\n12108\n1955\n4\n0\nNA\nRL\nInside\nDuplex\n\n\n82500\n1152\n6845\n1955\n4\n0\nNA\nRL\nInside\nDuplex\n\n\n91900\n784\n6931\n1955\n4\n0\nNA\nRL\nInside\n2fmCon\n\n\n120000\n1053\n12180\n1938\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n96000\n1137\n8050\n1947\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n98000\n864\n5604\n1925\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n67000\n864\n8248\n1914\n3\n0\nNA\nRL\nInside\n1Fam\n\n\n135900\n1716\n5687\n1912\n5\n0\nNA\nRL\nInside\n2fmCon\n\n\n119000\n1200\n8155\n1930\n5\n0\nNA\nRM\nInside\n1Fam\n\n\n81000\n630\n1890\n1972\n4\n0\nNA\nRM\nInside\nTwnhs\n\n\n146000\n1100\n7500\n2006\n6\n0\nNA\nRL\nInside\n1Fam\n\n\n64000\n670\n3500\n1945\n3\n0\nNA\nRL\nInside\n1Fam\n\n\n103200\n882\n5500\n1956\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n148000\n1534\n10800\n1895\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n110500\n866\n3880\n1945\n5\n0\nNA\nRM\nInside\n1Fam\n\n\n127000\n1355\n6882\n1914\n6\n0\nNA\nRM\nInside\n1Fam\n\n\n200500\n3086\n18030\n1946\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n150000\n1440\n7711\n1977\n4\n0\nNA\nRL\nInside\nDuplex\n\n\n86000\n605\n9098\n1920\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n123600\n990\n8070\n1994\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n98500\n1195\n8741\n1946\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n79000\n774\n4270\n1931\n3\n0\nNA\nRH\nInside\n1Fam\n\n\n200000\n3395\n10896\n1914\n6\n0\nNA\nRH\nInside\n2fmCon\n\n\n150000\n2592\n10890\n1923\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n115000\n1517\n8500\n1919\n5\n0\nNA\nRM\nCorner\n1Fam\n\n\n150909\n1828\n9060\n1923\n5\nNA\nNA\nRM\nInside\n1Fam\n\n\n119600\n1991\n8250\n1895\n5\n0\nNA\nC (all)\nInside\n2fmCon\n\n\n147000\n1120\n8402\n2007\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n93900\n1092\n1495\n1970\n4\n0\nNA\nRM\nInside\nTwnhsE\n\n\n84500\n630\n1936\n1970\n4\n0\nNA\nRM\nInside\nTwnhs\n\n\n139500\n1142\n7733\n2005\n6\n0\nNA\nRL\nInside\n1Fam\n\n\n132000\n1131\n13072\n2005\n6\n0\nNA\nRL\nInside\n1Fam\n\n\n85500\n869\n5900\n1923\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n135000\n1192\n10800\n1949\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n119000\n1556\n8512\n1960\n5\n0\nNA\nRL\nCorner\nDuplex\n\n\n124000\n1025\n7000\n1962\n5\n0\nNA\nRL\nInside\n2fmCon\n\n\n64500\n1020\n4761\n1918\n3\n0\nNA\nC (all)\nCorner\n1Fam\n\n\n100000\n788\n7446\n1941\n4\n0\nNA\nRL\nCorner\n1Fam\n\n\n80500\n912\n6240\n1947\n4\n0\nNA\nRM\nInside\n1Fam\n\n\n72000\n819\n9000\n1919\n5\n0\nNA\nRM\nInside\n1Fam\n\n\n117250\n914\n8050\n2002\n6\n0\nNA\nRL\nInside\n1Fam\n\n\n81000\n1184\n8410\n1910\n5\n0\nNA\nRL\nFR2\n1Fam\n\n\n83000\n1414\n8248\n1922\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n102000\n1522\n6000\n1926\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n72000\n672\n8534\n1925\n4\n0\nNA\nRM\nInside\n1Fam\n\n\n115000\n1396\n9000\n1951\n5\n0\nNA\nC (all)\nInside\n2fmCon\n\n\n78000\n936\n8520\n1916\n3\n0\nNA\nC (all)\nInside\n1Fam\n\n\n92000\n630\n1533\n1970\n5\n0\nNA\nRM\nInside\nTwnhs\n\n\n90500\n1092\n1936\n1970\n4\n0\nNA\nRM\nInside\nTwnhs\n\n\n\n\n\n\n\n\nCoding sidebar:\n\nIn the above example, we created a function (print_kbl()) from scratch (rather than using a function factory)\nSee functions chapter in Wickham, Çetinkaya-Rundel, and Grolemund (2023) for help.\nSee functionals chapter in Wickham (2019).\n\n\nOption 3 (Most advanced): Line by line kable table. You can make this as complicated and customized as you like. We use kable (and kableExtra) for publication quality tables. This is a simple example of options\n\ndata_all |&gt; filter(is.na(garage_qual)) |&gt; \n  kbl(align = \"r\") |&gt; \n  kable_styling(bootstrap_options = c(\"striped\", \"condensed\")) |&gt; \n  scroll_box(height = \"500px\", width = \"100%\")\n\n\n\n\n\nsale_price\ngr_liv_area\nlot_area\nyear_built\noverall_qual\ngarage_cars\ngarage_qual\nms_zoning\nlot_config\nbldg_type\n\n\n\n\n115000\n864\n10500\n1971\n4\n0\nNA\nRL\nFR2\n1Fam\n\n\n128950\n1225\n9320\n1959\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n84900\n1728\n13260\n1962\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n116500\n858\n7207\n1958\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n76500\n1306\n5350\n1940\n3\n0\nNA\nRL\nInside\n1Fam\n\n\n76500\n2256\n9045\n1910\n5\n0\nNA\nRM\nInside\n2fmCon\n\n\n159900\n1560\n12900\n1912\n6\n0\nNA\nRM\nInside\n1Fam\n\n\n55000\n1092\n5600\n1930\n4\n0\nNA\nRM\nInside\n2fmCon\n\n\n93369\n1884\n6449\n1907\n4\n0\nNA\nC (all)\nInside\n1Fam\n\n\n94000\n1020\n6342\n1875\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n136000\n1832\n10773\n1967\n4\n0\nNA\nRL\nInside\nDuplex\n\n\n100000\n1664\n9825\n1965\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n90000\n960\n6410\n1958\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n100000\n1666\n9839\n1931\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n139000\n1824\n9400\n1971\n6\n0\nNA\nRL\nCorner\nDuplex\n\n\n76000\n1092\n1476\n1970\n4\n0\nNA\nRM\nInside\nTwnhs\n\n\n75500\n630\n1491\n1972\n4\n0\nNA\nRM\nInside\nTwnhsE\n\n\n88250\n1092\n1900\n1970\n4\n0\nNA\nRM\nInside\nTwnhsE\n\n\n136000\n1792\n9000\n1974\n5\n0\nNA\nRL\nFR2\nDuplex\n\n\n142000\n1114\n13072\n2004\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n82500\n708\n5330\n1940\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n129000\n1464\n9900\n1910\n5\n0\nNA\nRM\nCorner\n1Fam\n\n\n94550\n1701\n7627\n1920\n4\n0\nNA\nRM\nCorner\n2fmCon\n\n\n103000\n1447\n10134\n1910\n5\n0\nNA\nRM\nInside\n1Fam\n\n\n37900\n968\n5925\n1910\n3\n0\nNA\nRM\nInside\n1Fam\n\n\n113000\n1452\n4456\n1920\n4\n0\nNA\nRM\nInside\n2fmCon\n\n\n58500\n816\n3300\n1910\n4\n0\nNA\nC (all)\nInside\n1Fam\n\n\n34900\n720\n7879\n1920\n4\n0\nNA\nC (all)\nInside\n1Fam\n\n\n60000\n800\n6120\n1936\n2\n0\nNA\nRM\nInside\n1Fam\n\n\n62500\n2128\n3000\n1922\n5\n0\nNA\nRM\nInside\nDuplex\n\n\n97500\n1864\n5852\n1902\n7\n0\nNA\nRM\nCorner\n2fmCon\n\n\n70000\n892\n5160\n1923\n4\n0\nNA\nRM\nInside\n1Fam\n\n\n179000\n1200\n10800\n1987\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n179000\n1200\n10800\n1987\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n61000\n904\n10020\n1922\n1\n0\nNA\nRL\nInside\n1Fam\n\n\n118000\n698\n9405\n1947\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n99900\n864\n4060\n1922\n5\n0\nNA\nRL\nCorner\n1Fam\n\n\n119900\n1678\n10926\n1959\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n112000\n833\n8780\n1985\n5\n0\nNA\nRL\nCorner\n1Fam\n\n\n141000\n1080\n7500\n2004\n7\n0\nNA\nRL\nInside\n1Fam\n\n\n106250\n1294\n10800\n1900\n4\n0\nNA\nRL\nInside\n2fmCon\n\n\n130000\n1800\n8513\n1961\n5\n0\nNA\nRL\nCorner\nDuplex\n\n\n120000\n1027\n5400\n1920\n7\n0\nNA\nRM\nInside\n1Fam\n\n\n95000\n1080\n5914\n1890\n5\n0\nNA\nRM\nInside\n1Fam\n\n\n65000\n1588\n12205\n1949\n3\n0\nNA\nRM\nInside\n1Fam\n\n\n129400\n1540\n6000\n1905\n5\n0\nNA\nRM\nCorner\n1Fam\n\n\n160000\n1984\n8094\n1910\n6\n1\nNA\nRM\nInside\n2fmCon\n\n\n89500\n1406\n7920\n1920\n6\n0\nNA\nRM\nInside\n1Fam\n\n\n79900\n1198\n5586\n1920\n6\n0\nNA\nRM\nInside\n1Fam\n\n\n82375\n1344\n10320\n1915\n3\n0\nNA\nRM\nInside\n2fmCon\n\n\n127500\n1355\n10106\n1940\n5\n0\nNA\nRL\nInside\n2fmCon\n\n\n80000\n1006\n9000\n1959\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n260000\n1518\n19550\n1940\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n99600\n864\n9350\n1975\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n107500\n1347\n7000\n1910\n5\n0\nNA\nRL\nInside\n2fmCon\n\n\n79000\n1096\n9600\n1924\n6\n0\nNA\nRL\nCorner\n1Fam\n\n\n85000\n796\n8777\n1910\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n145900\n2200\n8777\n1900\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n82000\n1152\n6040\n1955\n4\n0\nNA\nRL\nInside\nDuplex\n\n\n82000\n1152\n6012\n1955\n4\n0\nNA\nRL\nCorner\nDuplex\n\n\n118000\n1440\n12108\n1955\n4\n0\nNA\nRL\nInside\nDuplex\n\n\n82500\n1152\n6845\n1955\n4\n0\nNA\nRL\nInside\nDuplex\n\n\n91900\n784\n6931\n1955\n4\n0\nNA\nRL\nInside\n2fmCon\n\n\n120000\n1053\n12180\n1938\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n96000\n1137\n8050\n1947\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n98000\n864\n5604\n1925\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n67000\n864\n8248\n1914\n3\n0\nNA\nRL\nInside\n1Fam\n\n\n135900\n1716\n5687\n1912\n5\n0\nNA\nRL\nInside\n2fmCon\n\n\n119000\n1200\n8155\n1930\n5\n0\nNA\nRM\nInside\n1Fam\n\n\n81000\n630\n1890\n1972\n4\n0\nNA\nRM\nInside\nTwnhs\n\n\n146000\n1100\n7500\n2006\n6\n0\nNA\nRL\nInside\n1Fam\n\n\n64000\n670\n3500\n1945\n3\n0\nNA\nRL\nInside\n1Fam\n\n\n103200\n882\n5500\n1956\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n148000\n1534\n10800\n1895\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n110500\n866\n3880\n1945\n5\n0\nNA\nRM\nInside\n1Fam\n\n\n127000\n1355\n6882\n1914\n6\n0\nNA\nRM\nInside\n1Fam\n\n\n200500\n3086\n18030\n1946\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n150000\n1440\n7711\n1977\n4\n0\nNA\nRL\nInside\nDuplex\n\n\n86000\n605\n9098\n1920\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n123600\n990\n8070\n1994\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n98500\n1195\n8741\n1946\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n79000\n774\n4270\n1931\n3\n0\nNA\nRH\nInside\n1Fam\n\n\n200000\n3395\n10896\n1914\n6\n0\nNA\nRH\nInside\n2fmCon\n\n\n150000\n2592\n10890\n1923\n5\n0\nNA\nRL\nInside\nDuplex\n\n\n115000\n1517\n8500\n1919\n5\n0\nNA\nRM\nCorner\n1Fam\n\n\n150909\n1828\n9060\n1923\n5\nNA\nNA\nRM\nInside\n1Fam\n\n\n119600\n1991\n8250\n1895\n5\n0\nNA\nC (all)\nInside\n2fmCon\n\n\n147000\n1120\n8402\n2007\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n93900\n1092\n1495\n1970\n4\n0\nNA\nRM\nInside\nTwnhsE\n\n\n84500\n630\n1936\n1970\n4\n0\nNA\nRM\nInside\nTwnhs\n\n\n139500\n1142\n7733\n2005\n6\n0\nNA\nRL\nInside\n1Fam\n\n\n132000\n1131\n13072\n2005\n6\n0\nNA\nRL\nInside\n1Fam\n\n\n85500\n869\n5900\n1923\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n135000\n1192\n10800\n1949\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n119000\n1556\n8512\n1960\n5\n0\nNA\nRL\nCorner\nDuplex\n\n\n124000\n1025\n7000\n1962\n5\n0\nNA\nRL\nInside\n2fmCon\n\n\n64500\n1020\n4761\n1918\n3\n0\nNA\nC (all)\nCorner\n1Fam\n\n\n100000\n788\n7446\n1941\n4\n0\nNA\nRL\nCorner\n1Fam\n\n\n80500\n912\n6240\n1947\n4\n0\nNA\nRM\nInside\n1Fam\n\n\n72000\n819\n9000\n1919\n5\n0\nNA\nRM\nInside\n1Fam\n\n\n117250\n914\n8050\n2002\n6\n0\nNA\nRL\nInside\n1Fam\n\n\n81000\n1184\n8410\n1910\n5\n0\nNA\nRL\nFR2\n1Fam\n\n\n83000\n1414\n8248\n1922\n4\n0\nNA\nRL\nInside\n1Fam\n\n\n102000\n1522\n6000\n1926\n5\n0\nNA\nRL\nInside\n1Fam\n\n\n72000\n672\n8534\n1925\n4\n0\nNA\nRM\nInside\n1Fam\n\n\n115000\n1396\n9000\n1951\n5\n0\nNA\nC (all)\nInside\n2fmCon\n\n\n78000\n936\n8520\n1916\n3\n0\nNA\nC (all)\nInside\n1Fam\n\n\n92000\n630\n1533\n1970\n5\n0\nNA\nRM\nInside\nTwnhs\n\n\n90500\n1092\n1936\n1970\n4\n0\nNA\nRM\nInside\nTwnhs\n\n\n\n\n\n\n\n\nIn this instance, if we consult our data dictionary, we see that NA for garage_qual should be coded as “no garage”. We will correct this in our data set.\nThis is a pretty poor choice on the part of the researchers who created the dataset because it becomes impossible to distinguish between NA that means no garage vs. true NA for the variable. In fact, if you later do really careful EDA on the full data set with all variables, you will see this problem likely exists in this dataset\nAnyway, let’s correct all the NA for garage_qual to “no_garage” using mutate()\n\ndata_all &lt;- data_all |&gt; \n1  mutate(garage_qual = fct_expand(garage_qual, \"no_garage\"),\n2         garage_qual = replace_na(garage_qual, \"no_garage\"))\n\n\n1\n\nFirst add a new level to the factor\n\n2\n\nThen recode NA to that new level\n\n\n\n\nWe will leave the NA for garage_cars as NA because its not clear if that is truly missing or not, based on further EDA not shown here.\n\nWe have one other issue with garage_qual. It is an ordinal variable but we never reviewed the order of its levels. The data dictionary indicates the levels are ordered (best to worst) as:\n\nEx (excellent)\nGd (good)\nTA (typical/average)\nFa (fair)\nPo (poor)\n\nAnd we might assume that no garage is even worse than a poor garage. Lets see what they are.\n\ndata_all$garage_qual |&gt; levels()\n\n[1] \"Ex\"        \"Fa\"        \"Gd\"        \"Po\"        \"TA\"        \"no_garage\"\n\n\nTo fix this, we can use forcats::fct_relevel().\n\n1gq_levels &lt;- c(\"no_garage\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\")\ndata_all &lt;- data_all |&gt; \n2  mutate(garage_qual = fct_relevel(garage_qual, gq_levels))\n\n3data_all$garage_qual |&gt; levels()\n\n\n1\n\nMake a vector that indicates the valid levels in order\n\n2\n\nPass that into fct_relevel(). See ?fct_relevel for other ways to adjust the levels of a factor.\n\n3\n\nConfirm that the levels are now correct\n\n\n\n\n[1] \"no_garage\" \"Po\"        \"Fa\"        \"TA\"        \"Gd\"        \"Ex\"       \n\n\n\n\n\n2.4.6 Explore Min/Max Response for Numeric Variables\nWe should explore mins and maxes for all numeric variables to detect out of valid range numeric responses\n\nCould also do this for ordinal variables that are coded with numbers\n\ne.g., overall_qual (1-10) vs. garage_qual (no_garage, Po, Fa, TA, Gd, Ex)\n\nThis is only a temporary mutation of overall_qual for this check. We don’t assign to new df to an object\nWe can use skim_some() again\n\np0 = min\np100 = max\n\n\n\ndata_all |&gt;\n  mutate(overall_qual = as.numeric(overall_qual)) |&gt; \n  skim_some() |&gt; \n1  filter(skim_type == \"numeric\") |&gt;\n2  select(skim_variable, numeric.p0, numeric.p100)\n\n\n1\n\nSelect only numeric variables since min/max only apply to them\n\n2\n\nSelect relevant stats (min/max)\n\n\n\n\n# A tibble: 6 × 3\n  skim_variable numeric.p0 numeric.p100\n  &lt;chr&gt;              &lt;dbl&gt;        &lt;dbl&gt;\n1 sale_price         12789       745000\n2 gr_liv_area          438         5642\n3 lot_area            1476       215245\n4 year_built          1875         2010\n5 overall_qual           1           10\n6 garage_cars            0            4\n\n\n\n\n\n2.4.7 Explore All Responses for Categorical Variables\nWe should explore all unique responses for nominal variables\nMight also do this for ordinal variables that are coded with labels vs. numbers.\n\ndata_all |&gt; \n  select(where(is.factor)) |&gt;\n  walk(\\(column) print(levels(column)))\n\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"\n[1] \"no_garage\" \"Po\"        \"Fa\"        \"TA\"        \"Gd\"        \"Ex\"       \n[1] \"A (agr)\" \"C (all)\" \"FV\"      \"I (all)\" \"RH\"      \"RL\"      \"RM\"     \n[1] \"Corner\"  \"CulDSac\" \"FR2\"     \"FR3\"     \"Inside\" \n[1] \"1Fam\"   \"2fmCon\" \"Duplex\" \"Twnhs\"  \"TwnhsE\"\n\n\nCoding sidebar:\n\nOn the previous page, we demonstrated the use of an anonymous function (\\(column) print(levels(column))), which is a function we use once that we don’t bother to assign a name (since we won’t reuse it). We often use anonymous functions when using the functions from the purrr package (e.g., map(), walk())\nWe use walk() from the purrr package to apply our anonymous function to all columns of the data frame at once\nJust copy this code for now\nWe will see simpler uses later that will help you understand iteration with purrr functions\nSee the chapter on iteration in R for Data Science (2e) for more info on map() and walk()\n\n\n\n\n2.4.8 Tidy Responses for Categorical Variables\nFeature engineering with nominal and ordinal variables typically involves\n\nConverting to factors (already did this!)\nOften creating dummy features from these factors\n\nThis feature engineering will use response labels for naming new features\n\nTherefore, it is a good idea to have the responses snake-cased and cleaned up a bit so that these new feature names are clean/clear.\n\nHere is an easy way to convert responses for character variables to snake case using a function (tidy_responses()) we share in fun_eda.R (reproduced here).\n\nThis uses regular expressions (regex), which will will learn about in a later unit on text processing.\nYou could expand this cleaning function if you encounter other issues that need to be cleaned in the factor levels.\n\n\ntidy_responses &lt;- function(column){\n  # replace all non-alphanumeric with _\n  column &lt;- fct_relabel(column, \\(column) str_replace_all(column, \"\\\\W\", \"_\"))\n  # replace whitespace with _\n  column &lt;- fct_relabel(column, \\(column) str_replace_all(column, \"\\\\s+\", \"_\"))\n  # replace multiple _ with single _\n  column &lt;- fct_relabel(column, \\(column) str_replace_all(column, \"\\\\_+\", \"_\"))\n  #remove _ at end of string\n  column &lt;- fct_relabel(column, \\(column) str_replace_all(column, \"\\\\_$\", \"\"))\n  # remove _ at start of string\n  column &lt;- fct_relabel(column, \\(column) str_replace_all(column, \"\\\\^_\", \"\"))\n  # convert to lowercase\n  column &lt;- fct_relabel(column, tolower)\n  factor(column)\n}\n\n\nLet’s use the function\n\ndata_all &lt;- data_all |&gt; \n1  mutate(across(where(is.factor), tidy_responses))\n\n\n1\n\nWe use the tidy selection helper function to limit our mutate to only factors. See more details on the tidy selection helpers like all_of() and where()\n\n\n\n\n\nAlas, these response labels were pretty poorly chosen so some didn’t convert well. And some are really hard to understand too.\n\nAvoid this problem and choose good response labels from the start for your own data\nHere, we show you what we got from using tidy_responses()\n\n\ndata_all |&gt; \n  select(where(is.factor)) |&gt;\n  walk(\\(column) print(levels(column)))\n\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"\n[1] \"no_garage\" \"po\"        \"fa\"        \"ta\"        \"gd\"        \"ex\"       \n[1] \"a_agr\" \"c_all\" \"fv\"    \"i_all\" \"rh\"    \"rl\"    \"rm\"   \n[1] \"corner\"  \"culdsac\" \"fr2\"     \"fr3\"     \"inside\" \n[1] \"1fam\"   \"2fmcon\" \"duplex\" \"twnhs\"  \"twnhse\"\n\n\n\nLets clean them up a bit more manually\n\ndata_all &lt;- data_all |&gt; \n  mutate(ms_zoning = fct_recode(ms_zoning,\n                                res_low = \"rl\",\n                                res_med = \"rm\",\n                                res_high = \"rh\",\n                                float = \"fv\",\n                                agri = \"a_agr\",\n                                indus = \"i_all\",\n                                commer = \"c_all\"),\n1         bldg_type = fct_recode(bldg_type,\n                                one_fam = \"1fam\",\n                                two_fam = \"2fmcon\",\n                                town_end = \"twnhse\",\n                                town_inside = \"twnhs\"))\n\n\n1\n\nNote that I did not need to list all levels in the recode. Only the levels I wanted to change.\n\n\n\n\nThe full dataset is now clean!\n\n\n\n2.4.9 Train/Validate/Test Splits\nThe final task we typically do as part of the data preparation process is to split the full dataset into training, validation and test sets.\n\nTest sets are “typically” between 20-30% of your full dataset\n\nThere are costs and benefits to larger test sets\nWe will learn about these costs/benefits in the unit on resampling\nI have already held out the test set\n\nThere are many approaches to validation sets\n\nFor now (until unit 5) we will use a single validation set approach\nWe will use 25% of the remaining data (after holding out the test set) as a validation set for this example\n\nIt is typical to split data on the outcome within strata\n\nFor a categorical outcome, this makes the proportions of the response categories more balanced across the train, validation, and test sets\nFor a numeric outcome, we first break up the distribution into temporary bins (see breaks = 4 below) and then we split within these bins\n\nIMPORTANT: Set a seed so that you can reproduce these splits if you later do more cleaning\n\n\nset.seed(20110522)\nsplits &lt;- data_all |&gt; \n  initial_split(prop = 3/4, strata = \"sale_price\", breaks = 4)\n\n\nWe then extract the training set from the splits and save it\n\nTraining sets are used for “analysis”- hence the name of the function\n\n\nsplits |&gt; \n1  analysis() |&gt;\n  glimpse() |&gt; \n  write_csv(here::here(path_data, \"ames_clean_class_trn.csv\"))\n\n\n1\n\nanalysis() pulls out the training set from our splits of data_all\n\n\n\n\nRows: 1,465\nColumns: 10\n$ sale_price   &lt;dbl&gt; 105000, 126000, 115000, 120000, 99500, 112000, 122000, 12…\n$ gr_liv_area  &lt;dbl&gt; 896, 882, 864, 836, 918, 1902, 900, 1225, 1728, 858, 1306…\n$ lot_area     &lt;dbl&gt; 11622, 8400, 10500, 2280, 7892, 8930, 9819, 9320, 13260, …\n$ year_built   &lt;dbl&gt; 1961, 1970, 1971, 1975, 1979, 1978, 1967, 1959, 1962, 195…\n$ overall_qual &lt;fct&gt; 5, 4, 4, 7, 6, 6, 5, 4, 5, 5, 3, 5, 4, 5, 3, 5, 2, 6, 5, …\n$ garage_cars  &lt;dbl&gt; 1, 2, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 2, 2, 1, …\n$ garage_qual  &lt;fct&gt; ta, ta, no_garage, ta, ta, ta, ta, no_garage, no_garage, …\n$ ms_zoning    &lt;fct&gt; res_high, res_low, res_low, res_low, res_low, res_med, re…\n$ lot_config   &lt;fct&gt; inside, corner, fr2, fr2, inside, inside, inside, inside,…\n$ bldg_type    &lt;fct&gt; one_fam, one_fam, one_fam, town_inside, town_end, duplex,…\n\n\n\nWe will not need the validation set for modeling EDA\n\nIt should NOT be used for anything other than evaluating models to select the best model configuration\nWe do NOT do Modeling EDA or Model Fitting with the validation set\nSave it in this clean form for easy use when you need it\nWe use the validation set to “assess” models that we have fit in training sets - hence the name of the function\n\n\nsplits |&gt; \n1  assessment() |&gt;\n  glimpse() |&gt; \n  write_csv(here::here(path_data, \"ames_clean_class_val.csv\"))\n\n\n1\n\nassessment() pulls out the validation set from our splits of data_all\n\n\n\n\nRows: 490\nColumns: 10\n$ sale_price   &lt;dbl&gt; 215000, 189900, 189000, 171500, 212000, 164000, 394432, 1…\n$ gr_liv_area  &lt;dbl&gt; 1656, 1629, 1804, 1341, 1502, 1752, 1856, 1004, 1092, 106…\n$ lot_area     &lt;dbl&gt; 31770, 13830, 7500, 10176, 6820, 12134, 11394, 11241, 168…\n$ year_built   &lt;dbl&gt; 1960, 1997, 1999, 1990, 1985, 1988, 2010, 1970, 1971, 197…\n$ overall_qual &lt;fct&gt; 6, 5, 7, 7, 8, 8, 9, 6, 5, 6, 7, 9, 8, 8, 7, 8, 6, 5, 5, …\n$ garage_cars  &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 3, 2, 3, 1, 1, 2, …\n$ garage_qual  &lt;fct&gt; ta, ta, ta, ta, ta, ta, ta, ta, ta, ta, ta, ta, ta, ta, t…\n$ ms_zoning    &lt;fct&gt; res_low, res_low, res_low, res_low, res_low, res_low, res…\n$ lot_config   &lt;fct&gt; corner, inside, inside, inside, corner, inside, corner, c…\n$ bldg_type    &lt;fct&gt; one_fam, one_fam, one_fam, one_fam, town_end, one_fam, on…"
  },
  {
    "objectID": "002_exploratory_data_analysis.html#exploratory-data-analysis-for-modeling",
    "href": "002_exploratory_data_analysis.html#exploratory-data-analysis-for-modeling",
    "title": "2  Exploratory Data Analysis",
    "section": "2.5 Exploratory Data Analysis for Modeling",
    "text": "2.5 Exploratory Data Analysis for Modeling\nNow let’s begin our Modeling EDA\nWe prefer to write separate scripts for Cleaning vs. Modeling EDA (but not displayed here)\n\nThis keeps these two processes separate in our minds\nCleaning EDA is done with full dataset but Modeling EDA is only done with a training set - NEVER use validation or test set\nYou will use two separate scripts for the application assignment for this unit\n\n\nLets re-load (and glimpse) our training set to pretend we are at the start of a new script.\n\n data_trn &lt;- read_csv(here::here(path_data, \"ames_clean_class_trn.csv\")) |&gt; \n  glimpse()\n\nRows: 1465 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): garage_qual, ms_zoning, lot_config, bldg_type\ndbl (6): sale_price, gr_liv_area, lot_area, year_built, overall_qual, garage...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nRows: 1,465\nColumns: 10\n$ sale_price   &lt;dbl&gt; 105000, 126000, 115000, 120000, 99500, 112000, 122000, 12…\n$ gr_liv_area  &lt;dbl&gt; 896, 882, 864, 836, 918, 1902, 900, 1225, 1728, 858, 1306…\n$ lot_area     &lt;dbl&gt; 11622, 8400, 10500, 2280, 7892, 8930, 9819, 9320, 13260, …\n$ year_built   &lt;dbl&gt; 1961, 1970, 1971, 1975, 1979, 1978, 1967, 1959, 1962, 195…\n$ overall_qual &lt;dbl&gt; 5, 4, 4, 7, 6, 6, 5, 4, 5, 5, 3, 5, 4, 5, 3, 5, 2, 6, 5, …\n$ garage_cars  &lt;dbl&gt; 1, 2, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 2, 2, 1, …\n$ garage_qual  &lt;chr&gt; \"ta\", \"ta\", \"no_garage\", \"ta\", \"ta\", \"ta\", \"ta\", \"no_gara…\n$ ms_zoning    &lt;chr&gt; \"res_high\", \"res_low\", \"res_low\", \"res_low\", \"res_low\", \"…\n$ lot_config   &lt;chr&gt; \"inside\", \"corner\", \"fr2\", \"fr2\", \"inside\", \"inside\", \"in…\n$ bldg_type    &lt;chr&gt; \"one_fam\", \"one_fam\", \"one_fam\", \"town_inside\", \"town_end…\n\n\n\nWe have some work to do (again)\n\nNotice that overall_qual is back to being classed as numeric (dbl).\n\nNotice that your factors are back to character\n\nThis is because csv files don’t save anything other than the values (labels for factors). They are the cleaned labels though!\n\nYou should class all variables using the same approach as before (often just a copy/paste).\n\n\n data_trn &lt;- \n  read_csv(here::here(path_data, \"ames_clean_class_trn.csv\"), \n1           col_types = cols()) |&gt;\n2  mutate(across(where(is.character), factor)) |&gt;\n3  mutate(overall_qual = factor(overall_qual, levels = 1:10),\n         garage_qual = fct_relevel(garage_qual, c(\"no_garage\", \"po\", \"fa\", \n4                                                  \"ta\", \"gd\", \"ex\"))) |&gt;\n  glimpse()\n\n\n1\n\nuse col_types = cols() to suppress messages about default class assignments\n\n2\n\nuse mutate() with across() to change all character variables to factors\n\n3\n\nuse mutate() with factor() to change numeric variable to factor.\n\n4\n\nuse mutate() with fct_relevel() to explicitly set levels of an ordinal factor. Also notice the warning about the unknown level. Always explore warnings! In this instance, its fine. There were only two observations with ex and neither ended up in the training split. Still best to include this level to note it exists!\n\n\n\n\nRows: 1,465\nColumns: 10\n$ sale_price   &lt;dbl&gt; 105000, 126000, 115000, 120000, 99500, 112000, 122000, 12…\n$ gr_liv_area  &lt;dbl&gt; 896, 882, 864, 836, 918, 1902, 900, 1225, 1728, 858, 1306…\n$ lot_area     &lt;dbl&gt; 11622, 8400, 10500, 2280, 7892, 8930, 9819, 9320, 13260, …\n$ year_built   &lt;dbl&gt; 1961, 1970, 1971, 1975, 1979, 1978, 1967, 1959, 1962, 195…\n$ overall_qual &lt;fct&gt; 5, 4, 4, 7, 6, 6, 5, 4, 5, 5, 3, 5, 4, 5, 3, 5, 2, 6, 5, …\n$ garage_cars  &lt;dbl&gt; 1, 2, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 2, 2, 1, …\n$ garage_qual  &lt;fct&gt; ta, ta, no_garage, ta, ta, ta, ta, no_garage, no_garage, …\n$ ms_zoning    &lt;fct&gt; res_high, res_low, res_low, res_low, res_low, res_med, re…\n$ lot_config   &lt;fct&gt; inside, corner, fr2, fr2, inside, inside, inside, inside,…\n$ bldg_type    &lt;fct&gt; one_fam, one_fam, one_fam, town_inside, town_end, duplex,…\n\n\n\nCoding sidebar: We will likely re-class the Ames dataset many times (for training, validation, test). We could copy/paste these mutates each time but whenever you do something more than twice, I recommend writing a function. We might write this one to re-class the ames variables\n\nclass_ames &lt;- function(df){\n  \n  df |&gt;\n    mutate(across(where(is.character), factor)) |&gt; \n    mutate(overall_qual = factor(overall_qual, levels = 1:10), \n           garage_qual = fct_relevel(garage_qual, c(\"no_garage\", \"po\", \"fa\", \n                                                    \"ta\", \"gd\", \"ex\")))\n}\n\n\nNow we can use this function every time we read in one of the Ames datasets\n\ndata_trn &lt;- \n  read_csv(here::here(path_data, \"ames_clean_class_trn.csv\"), \n           col_types = cols()) |&gt; \n1  class_ames() |&gt;\n  glimpse()\n\n\n1\n\nUsing our new function!\n\n\n\n\nRows: 1,465\nColumns: 10\n$ sale_price   &lt;dbl&gt; 105000, 126000, 115000, 120000, 99500, 112000, 122000, 12…\n$ gr_liv_area  &lt;dbl&gt; 896, 882, 864, 836, 918, 1902, 900, 1225, 1728, 858, 1306…\n$ lot_area     &lt;dbl&gt; 11622, 8400, 10500, 2280, 7892, 8930, 9819, 9320, 13260, …\n$ year_built   &lt;dbl&gt; 1961, 1970, 1971, 1975, 1979, 1978, 1967, 1959, 1962, 195…\n$ overall_qual &lt;fct&gt; 5, 4, 4, 7, 6, 6, 5, 4, 5, 5, 3, 5, 4, 5, 3, 5, 2, 6, 5, …\n$ garage_cars  &lt;dbl&gt; 1, 2, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 2, 2, 1, …\n$ garage_qual  &lt;fct&gt; ta, ta, no_garage, ta, ta, ta, ta, no_garage, no_garage, …\n$ ms_zoning    &lt;fct&gt; res_high, res_low, res_low, res_low, res_low, res_med, re…\n$ lot_config   &lt;fct&gt; inside, corner, fr2, fr2, inside, inside, inside, inside,…\n$ bldg_type    &lt;fct&gt; one_fam, one_fam, one_fam, town_inside, town_end, duplex,…\n\n\n\nThere are 3 basic types of Modeling EDA you should always do\n\nExplore missingness for predictors\nExplore univariate distributions for outcome and predictors\nExplore bivariate relationships between predictors and outcome\n\nAs a result of this exploration, we will:\n\nIdentify promising predictors\nDetermine appropriate feature engineering for those predictors (e.g., transformations)\nIdentify outliers and consider how to handle when model building\nConsider how to handle imputation for missing data (if any)\n\n\n\n2.5.1 Overall Summary of Feature Matrix\nBefore we dig into individual variables and their distributions and relationships with the outcome, it’s nice to start with a big picture of the dataset\n\nWe use another customized version of skim() from the skimr package to provide this\nJust needed to augment it with skewness and kurtosis statistics for numeric variables\nand remove histogram b/c we don’t find that small histogram useful\nincluded in fun_eda.R on github\n\n\nskew_na &lt;- partial(e1071::skewness, na.rm = TRUE)\nkurt_na &lt;- partial(e1071::kurtosis, na.rm = TRUE)\n\nskim_all &lt;- skimr::skim_with(numeric = skimr::sfl(skew = skew_na, \n                                                  kurtosis = kurt_na, \n                                                  hist = NULL))\n\n\nCareful review of this output provides a great orientation to our data\n\ndata_trn |&gt; \n  skim_all()\n\n\n\n\nData summary\n\n\n\n\nName\n\n\ndata_trn\n\n\n\n\nNumber of rows\n\n\n1465\n\n\n\n\nNumber of columns\n\n\n10\n\n\n\n\n_______________________\n\n\n\n\n\n\nColumn type frequency:\n\n\n\n\n\n\nfactor\n\n\n5\n\n\n\n\nnumeric\n\n\n5\n\n\n\n\n________________________\n\n\n\n\n\n\nGroup variables\n\n\nNone\n\n\n\n\n\nVariable type: factor\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nn_unique\n\n\ntop_counts\n\n\n\n\n\n\noverall_qual\n\n\n0\n\n\n1\n\n\n10\n\n\n5: 424, 6: 350, 7: 304, 8: 176\n\n\n\n\ngarage_qual\n\n\n0\n\n\n1\n\n\n5\n\n\nta: 1312, no_: 81, fa: 57, gd: 13\n\n\n\n\nms_zoning\n\n\n0\n\n\n1\n\n\n7\n\n\nres: 1157, res: 217, flo: 66, com: 13\n\n\n\n\nlot_config\n\n\n0\n\n\n1\n\n\n5\n\n\nins: 1095, cor: 248, cul: 81, fr2: 39\n\n\n\n\nbldg_type\n\n\n0\n\n\n1\n\n\n5\n\n\none: 1216, tow: 108, dup: 63, tow: 46\n\n\n\n\n\nVariable type: numeric\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmean\n\n\nsd\n\n\np0\n\n\np25\n\n\np50\n\n\np75\n\n\np100\n\n\nskew\n\n\nkurtosis\n\n\n\n\n\n\nsale_price\n\n\n0\n\n\n1\n\n\n180696.15\n\n\n78836.41\n\n\n12789\n\n\n129500\n\n\n160000\n\n\n213500\n\n\n745000\n\n\n1.64\n\n\n4.60\n\n\n\n\ngr_liv_area\n\n\n0\n\n\n1\n\n\n1506.84\n\n\n511.44\n\n\n438\n\n\n1128\n\n\n1450\n\n\n1759\n\n\n5642\n\n\n1.43\n\n\n5.19\n\n\n\n\nlot_area\n\n\n0\n\n\n1\n\n\n10144.16\n\n\n8177.55\n\n\n1476\n\n\n7500\n\n\n9375\n\n\n11362\n\n\n164660\n\n\n11.20\n\n\n182.91\n\n\n\n\nyear_built\n\n\n0\n\n\n1\n\n\n1971.35\n\n\n29.65\n\n\n1880\n\n\n1953\n\n\n1972\n\n\n2000\n\n\n2010\n\n\n-0.54\n\n\n-0.62\n\n\n\n\ngarage_cars\n\n\n1\n\n\n1\n\n\n1.78\n\n\n0.76\n\n\n0\n\n\n1\n\n\n2\n\n\n2\n\n\n4\n\n\n-0.26\n\n\n0.10\n\n\n\n\n\n\n\n\n\n\n2.5.2 Univariate Distributions\nExploration of univariate distributions are useful to\n\nUnderstand variation and distributional shape\nMay suggest need to consider transformations as part of feature engineering\nCan identify univariate outliers (valid but disconnected from distribution so not detected in cleaning)\n\nWe generally select different visualizations and summary statistics for categorical vs. numeric variables\n\n\n\n2.5.3 Barplots for Categorical Variables (Univariate)\nThe primary visualization for categorical variables is the bar plot\n\nWe use it for both nominal and ordinal variables\nDefine and customize it within a function for repeated use.\n\nWe share this and all the remaining plots used in this unit in fun_plot.R. Source it to use them without having to re-code each time\n\n\nplot_bar &lt;- function(df, x){\n  x_label_size &lt;- if_else(skimr::n_unique(df[[x]]) &lt; 7, 11, 7)\n  \n  df |&gt;\n    ggplot(aes(x = .data[[x]])) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, size = x_label_size, vjust = 0.5, hjust = 1),\n          axis.text.y = element_text(size = 11))\n}\n\n\nCoding sidebar: When defining functions, generally put data as first argument so you can pipe in data using tidy pipelines\nThere are pros and cons to writing functions that accept variable names that are quoted vs. unquoted\n\nIt depends a bit on how you will use them.\n.data[[argument]] is used in functions with quoted arguments\nembracing {{}} is used for unquoted arguments\nFor these plot functions, I use quoted variable names and then pipe those into map() to make multiple plots (see below)\nsee ?vignette(\"programming\") or info on tidy evaluation in Wickham, Çetinkaya-Rundel, and Grolemund (2023) for more details\n\n\nBar plots reveal low frequency responses for nominal and ordinal variables\n\nSee bldg_type\n\n\ndata_trn |&gt; plot_bar(\"bldg_type\")\n\n\n\n\n\nBar plots can display distributional shape for ordinal variables. May suggest the need for transformations if we later treat the ordinal variable as numeric\n\nSee overall_qual. Though it is not very skewed.\n\n\ndata_trn |&gt; plot_bar(\"overall_qual\")\n\n\n\n\n\nCoding sidebar:\nWe can make all of our plots iteratively using map() from the `purrr package.\n\ndata_trn |&gt; \n1  select(where(is.factor)) |&gt;\n2  names() |&gt;\n3  map(\\(name) plot_bar(df = data_trn, x = name)) |&gt;\n4  plot_grid(plotlist = _, ncol = 2)\n\n\n1\n\nSelect only the factor columns\n\n2\n\nGet their names as strings (that is why we use quoted variables in these plot functions\n\n3\n\nUse map() to iterative plot_bar() over every column. (see iteration in Wickham, Çetinkaya-Rundel, and Grolemund (2023))\n\n4\n\nUse plot_grid() from cowplot package to display the list of plots in a grid\n\n\n\n\n\n\n\n\n\n\n2.5.4 Tables for Categorical Variables (Univariate)\nWe tend to prefer visualizations vs. summary statistics for EDA. However, tables can be useful.\nHere is a function that was described in Wickham, Çetinkaya-Rundel, and Grolemund (2023) that we like because\n\nIt includes counts and proportions\nIt includes NA as a category\n\nWe have included it in fun_eda.R for your use.\n\ntab &lt;- function(df, var, sort = FALSE) {\n  df |&gt;  dplyr::count({{ var }}, sort = sort) |&gt; \n    dplyr::mutate(prop = n / sum(n))\n} \n\n\nTables can be used to identify responses that have very low frequency and to think about the need to handle missing values\n\nSee ms_zoning\nMay want to collapse low frequency (or low percentage) categories to reduce the number of features needed to represent the predictor\n\n\ndata_trn |&gt; tab(ms_zoning)\n\n# A tibble: 7 × 3\n  ms_zoning     n     prop\n  &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;\n1 agri          2 0.00137 \n2 commer       13 0.00887 \n3 float        66 0.0451  \n4 indus         1 0.000683\n5 res_high      9 0.00614 \n6 res_low    1157 0.790   \n7 res_med     217 0.148   \n\n\n\n\nWe could also view the table sorted if we prefer\n\n\ndata_trn |&gt; tab(ms_zoning, sort = TRUE)\n\n# A tibble: 7 × 3\n  ms_zoning     n     prop\n  &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;\n1 res_low    1157 0.790   \n2 res_med     217 0.148   \n3 float        66 0.0451  \n4 commer       13 0.00887 \n5 res_high      9 0.00614 \n6 agri          2 0.00137 \n7 indus         1 0.000683\n\n\n\nbut could see all this detail with plot as well\n\ndata_trn |&gt; plot_bar(\"ms_zoning\")\n\n\n\n\n\n\n\n2.5.5 Histograms for Numeric Variables (Univariate)\nHistograms are a useful/common visualization for numeric variables\nLet’s define a histogram function (included in fun_plots.r)\n\nBin size should be explored a bit to find best representation\nSomewhat dependent on n (my default here is based on this training set)\nThis is one of the limitations of histograms\n\n\nplot_hist &lt;- function(df, x, bins = 100){\n  df |&gt;\n    ggplot(aes(x = .data[[x]])) +\n    geom_histogram(bins = bins) +\n    theme(axis.text.x = element_text(size = 11),\n          axis.text.y = element_text(size = 11))\n}\n\n\nLet’s look at sale_price\n\nIt is positively skewed\nMay suggest units (dollars) are not interval in nature (makes sense)\nCould cause problems for some algorithms (e.g., lm) when features are normal\n\n\ndata_trn |&gt; plot_hist(\"sale_price\")\n\n\n\n\n\n\n\n2.5.6 Smoothed Frequency Polygons for Numeric Variables (Univariate)\nFrequency polygons are also commonly used\n\nDefine a frequency polygon function and use it (included in fun_plots.r)\n\n\nplot_freqpoly &lt;- function(df, x, bins = 50){\n  df |&gt;\n    ggplot(aes(x = .data[[x]])) +\n    geom_freqpoly(bins = bins) +\n    theme(axis.text.x = element_text(size = 11),\n          axis.text.y = element_text(size = 11))\n}\n\n\n\nBins may matter again\n\n\ndata_trn |&gt; plot_freqpoly(\"sale_price\")\n\n\n\n\n\n\n\n2.5.7 Simple Boxplots for Numeric Variables (Univariate)\nBoxplots display\n\nMedian as line\n25%ile and 75%ile as hinges\nHighest and lowest points within 1.5 * IQR (interquartile-range: difference between scores at 25% and 75%iles)\nOutliers outside of 1.5 * IQR\n\nDefine a boxplot function and use it (included in fun_plots.r)\n\nplot_boxplot &lt;- function(df, x){\n  x_label_size &lt;- if_else(skimr::n_unique(df[[x]]) &lt; 7, 11, 7)\n  \n  df |&gt;\n    ggplot(aes(x = .data[[x]])) +\n    geom_boxplot() +\n    theme(axis.text.y = element_blank(),\n          axis.ticks.y = element_blank(),\n          axis.text.x = element_text(angle = 90, size = x_label_size, vjust = 0.5, hjust = 1))\n}\n\n\nHere is the plot for sale_price\n\ndata_trn |&gt; plot_boxplot(\"sale_price\")\n\n\n\n\n\n\n\n2.5.8 Combined Boxplot and Violin Plots for Numeric Variables (Univariate)\nThe combination of a boxplot and violin plot is particularly useful\n\nThis is our favorite\nGet all the benefits of the boxplot\nCan clearly see shape of distribution given the violin plot overlay\nCan also clearly see the tails\n\nDefine a combined plot (included in fun_plots.r)\n\nplot_box_violin &lt;- function(df, x){\n  x_label_size &lt;- if_else(skimr::n_unique(df[[x]]) &lt; 7, 11, 7)\n  \n  df |&gt;\n    ggplot(aes(x = .data[[x]])) +\n    geom_violin(aes(y = 0), fill = \"green\", color = NA) +\n    geom_boxplot(width = .1, fill = NA, lwd = 1.1, fatten = 1.1) +\n    theme(axis.text.y = element_blank(),\n          axis.ticks.y = element_blank(),\n          axis.title.y = element_blank(),\n          axis.text.x = element_text(angle = 90, size = x_label_size, vjust = 0.5, hjust = 1))\n}\n\n\nHere is the plot for sale_price\n\nIn this instance, the skew is NOT due to only a few outliers\n\n\ndata_trn |&gt; plot_box_violin(\"sale_price\")\n\n\n\n\n\nCoding sidebar:\n\nYou can make figures for all numeric variables at once using select() and map() as before\n\n\ndata_trn |&gt; \n1  select(where(is.numeric)) |&gt;\n  names() |&gt; \n  map(\\(name) plot_box_violin(df = data_trn, x = name)) |&gt; \n  plot_grid(plotlist = _, ncol = 2)\n\n\n1\n\nNow select numeric rather than factor but otherwise same as previous example\n\n\n\n\n\n\n\n\n\n\n2.5.9 Summary Statistics for Numeric Variables (Univariate)\nskim_all() provided all the summary statistics you likely needed for numeric variables\n\nmean & median (p50)\nsd & IQR (see difference between p25 and p75)\nskew & kurtosis\n\nYou can get skim of only numeric variables if you like\n\ndata_trn |&gt; \n  skim_all() |&gt; \n  filter(skim_type == \"numeric\")\n\n\n\n\nData summary\n\n\n\n\nName\n\n\ndata_trn\n\n\n\n\nNumber of rows\n\n\n1465\n\n\n\n\nNumber of columns\n\n\n10\n\n\n\n\n_______________________\n\n\n\n\n\n\nColumn type frequency:\n\n\n\n\n\n\nnumeric\n\n\n5\n\n\n\n\n________________________\n\n\n\n\n\n\nGroup variables\n\n\nNone\n\n\n\n\n\nVariable type: numeric\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmean\n\n\nsd\n\n\np0\n\n\np25\n\n\np50\n\n\np75\n\n\np100\n\n\nskew\n\n\nkurtosis\n\n\n\n\n\n\nsale_price\n\n\n0\n\n\n1\n\n\n180696.15\n\n\n78836.41\n\n\n12789\n\n\n129500\n\n\n160000\n\n\n213500\n\n\n745000\n\n\n1.64\n\n\n4.60\n\n\n\n\ngr_liv_area\n\n\n0\n\n\n1\n\n\n1506.84\n\n\n511.44\n\n\n438\n\n\n1128\n\n\n1450\n\n\n1759\n\n\n5642\n\n\n1.43\n\n\n5.19\n\n\n\n\nlot_area\n\n\n0\n\n\n1\n\n\n10144.16\n\n\n8177.55\n\n\n1476\n\n\n7500\n\n\n9375\n\n\n11362\n\n\n164660\n\n\n11.20\n\n\n182.91\n\n\n\n\nyear_built\n\n\n0\n\n\n1\n\n\n1971.35\n\n\n29.65\n\n\n1880\n\n\n1953\n\n\n1972\n\n\n2000\n\n\n2010\n\n\n-0.54\n\n\n-0.62\n\n\n\n\ngarage_cars\n\n\n1\n\n\n1\n\n\n1.78\n\n\n0.76\n\n\n0\n\n\n1\n\n\n2\n\n\n2\n\n\n4\n\n\n-0.26\n\n\n0.10\n\n\n\n\n\n\n\n\n\n\n2.5.10 Bivariate Relationships with Outcome\nBivariate relationships with the outcome are useful to detect\n\nWhich predictors display some relationship with the outcome\nWhat feature engineering (transformations) might maximize that relationship\nAre there any bivariate (model) outliers\n\nAgain, we prefer visualizations but summary statistics are also available\n\n\n\n2.5.11 Scatterplots for Numeric Variables (Bivariate)\nScatterplots are the preferred visualization when both variables are numeric\nDefine a scatterplot function (included in fun_plots.r)\n\nadd a simple line\nadd a LOWESS line (Locally Weighted Scatterplot Smoothing)\nThese lines are useful for considering shape of relationship\n\n\nplot_scatter &lt;- function(df, x, y){\n  df |&gt;\n    ggplot(aes(x = .data[[x]], y = .data[[y]])) +\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = y ~ x, col = \"red\") +\n    geom_smooth(method = \"loess\", formula = y ~ x, col = \"green\") +\n    theme(axis.text.x = element_text(size = 11),\n          axis.text.y = element_text(size = 11))\n}\n\n\nLet’s consider relationship between gr_liv_area and sale_price\n\nCare most about influential points (both model outlier and leverage)\nCan be typically spotted in bivariate plots (but could do more sophisticated assessments)\nWe might:\n\nretain as is\ndrop\nbring to fence\n\n\nIf bivariate outliers are detected, you should return to cleaning mode to verify that they aren’t result of scoring/coding errors. If they are:\n\nFix in full dataset\nUse same train/test split after fixing\n\n\ndata_trn |&gt; plot_scatter(\"gr_liv_area\", \"sale_price\")\n\n\n\n\n\nHere is another example where the relationship might be non-linear\n\ndata_trn |&gt; plot_scatter(\"year_built\", \"sale_price\")\n\n\n\n\n\nA transformation of sale_price might help the relationship with \\(year\\_built\\) but might hurt gr_liv_area\nMaybe need to transform both sale_price and gr_liv_area as both were skewed\nThis might require some more EDA but here is a start\n\nQuick and temporary Log (base e) of sale_price\nThis doesn’t seem promising by itself\n\n\ndata_trn |&gt; \n  mutate(sale_price = log(sale_price)) |&gt; \n  plot_scatter(\"gr_liv_area\", \"sale_price\")\n\n\n\ndata_trn |&gt; \n  mutate(sale_price = log(sale_price)) |&gt;\n  plot_scatter(\"year_built\", \"sale_price\")\n\n\n\n\n\nCan make scatterplots for ordinal variables as well\n\nBut other (perhaps better) options also exist for this combination of variable classes.\nUse as.numeric() to allow for lm and LOWESS lines on otherwise categorical variable\n\n\ndata_trn |&gt; \n  mutate(overall_qual = as.numeric(overall_qual)) |&gt; \n  plot_scatter(\"overall_qual\", \"sale_price\")\n\n\n\n\n\nCoding sidebar: Use jitter() with x to help with overplotting\n\ndata_trn |&gt; \n  mutate(overall_qual = jitter(as.numeric(overall_qual))) |&gt; \n  plot_scatter(\"overall_qual\", \"sale_price\")\n\n\n\n\n\n\n\n2.5.12 Correlations & Correlation Plots for Numeric Variables (Bivariate)\nCorrelations are useful summary statistics for numeric variables\nSome statistical algorithms are sensitive to high correlations among features (multi-collinearity)\nAt best, highly correlated features add unnecessary flexibility and can lead to overfitting\n\nWe can visualize correlations among predictors/features using corrplot.mixed() from corrplot package\n\nBest for numeric variables\nCan include ordinal or two level nominal variables if transformed to numeric\nCan include nominal variables with &gt; 2 levels if first transformed appropriately (e.g., dummy features, not demonstrated yet)\nWorks best with relatively small set of variables\n\n\n\ndata_trn |&gt; \n  mutate(overall_qual = as.numeric(overall_qual),\n         garage_qual = as.numeric(garage_qual)) |&gt; \n  select(where(is.numeric)) |&gt; \n  cor(use = \"pairwise.complete.obs\") |&gt; \n1  corrplot::corrplot.mixed()\n\n\n1\n\nNote use of namespace (corrplot::corrplot.mixed()) to call this function from corrplot package\n\n\n\n\n\n\n\n\n\n\n2.5.13 Grouped Box + Violin Plots for Categorical and Numeric (Bivariate)\nA grouped version of the combined box and violin plot is our preferred visualization for relationship between categorical and numeric variables (included in fun_plots.r)\n\nOften best when feature is categorical and outcome is numeric but can reverse\nCan use with both nominal and ordinal categorical variable\nWickham, Çetinkaya-Rundel, and Grolemund (2023) also describes use of grouped frequency polygons for this combination of variable classes\n\n\nplot_grouped_box_violin &lt;- function(df, x, y){\n  x_label_size &lt;- if_else(skimr::n_unique(df[[x]]) &lt; 7, 11, 7)\n  \n  df |&gt;\n    ggplot(aes(x = .data[[x]], y = .data[[y]])) +\n    geom_violin(fill = \"green\", color = NA) +\n    geom_boxplot(width = .1, fill = NA, lwd = 1.1, fatten = 1.1) +\n    theme(axis.text.x = element_text(angle = 90, size = x_label_size, \n                                     vjust = 0.5, hjust = 1),\n          axis.text.y = element_text(size = 11))\n}\n\n\nHere is the relationship between overall_qual and sale_price\n\nTend to prefer this over the scatterplot (with as.numeric()) for ordinal variables\nIncreasing spread of sale_price at higher levels of overall_qual is clearer in this plot\n\n\ndata_trn |&gt; plot_grouped_box_violin(\"overall_qual\", \"sale_price\")\n\n\n\n\n\nHere is a grouped box + violin with a nominal variable\n\nMore variation and skew in sale_price for one family homes (additional features, moderators?)\nPosition of townhouse (interior vs. exterior) seems to matter (don’t collapse?)\n\n\ndata_trn |&gt; plot_grouped_box_violin(\"bldg_type\", \"sale_price\")\n\n\n\n\n\nWhen we have a categorical predictor and a numeric outcome, we often want to see both the relationship between the variables AND the variability on the categorical variable alone.\nWe like this combined plot enough when doing EDA to provide a specific function (included in fun_plots.r)!\nIt is our go to for understanding the potential effect of a categorical predictor\n\nplot_categorical &lt;- function(df, x, y, ordered = FALSE){\n  if (ordered) {\n    df &lt;- df |&gt;\n      mutate(!!x := fct_reorder(.data[[x]], .data[[y]]))\n  }\n  \n  x_label_size &lt;- if_else(skimr::n_unique(df[[x]]) &lt; 7, 11, 7)\n  \n  p_bar &lt;- df |&gt;\n    ggplot(aes(x = .data[[x]])) +\n    geom_bar()  +\n    theme(axis.text.x = element_text(angle = 90, size = x_label_size, \n                                     vjust = 0.5, hjust = 1),\n          axis.text.y = element_text(size = 11))\n  \n  p_box &lt;- df |&gt;\n    ggplot(aes(x = .data[[x]], y = .data[[y]])) +\n    geom_violin(fill = \"green\", color = NA) +\n    geom_boxplot(width = .1, fill = NA, lwd = 1.1, fatten = 1.1) +\n    theme(axis.text.x = element_text(angle = 90, size = x_label_size, \n                                     vjust = 0.5, hjust = 1),\n          axis.text.y = element_text(size = 11))\n  \n  return(list(p_bar, p_box))\n}\n\n\nsale_price by bldg_type\n\ndata_trn |&gt; plot_categorical(\"bldg_type\", \"sale_price\") |&gt; \n  plot_grid(plotlist = _, ncol = 1)\n\n\n\n\n\n\n\n2.5.14 Stacked Barplots for Categorical (Bivariate)\nStacked Barplots:\n\nCan be useful with both nominal and ordinal variables\nCan create with either raw counts or percentages.\n\nDisplays different perspective (particularly with uneven distributions across levels)\nDepends on your question\n\nOften, you will place the outcome on the x-axis and the feature is coded by fill\n\n\nplot_grouped_barplot_count &lt;- function(df, x, y){\n  x_label_size &lt;- if_else(skimr::n_unique(df[[x]]) &lt; 7, 11, 7)\n  \n  df |&gt;\n    ggplot(aes(x = .data[[y]], fill = .data[[x]])) +\n    geom_bar(position = \"stack\") +\n    theme(axis.text.x = element_text(angle = 90, size = x_label_size, \n                                     vjust = 0.5, hjust = 1),\n          axis.text.y = element_text(size = 11))\n}\n\nplot_grouped_barplot_percent &lt;- function(df, x, y){\n  x_label_size &lt;- if_else(skimr::n_unique(df[[x]]) &lt; 7, 11, 7)\n  \n  df |&gt;\n    ggplot(aes(x = .data[[y]], fill = .data[[x]])) +\n    geom_bar(position = \"fill\") +\n    labs(y = \"Proportion\") +\n    theme(axis.text.x = element_text(angle = 90, size = x_label_size, \n                                     vjust = 0.5, hjust = 1),\n          axis.text.y = element_text(size = 11))\n}\n\n\nFor example, if we wanted to learn about how bldg_type varies by lot_config, see these plots\n\ndata_trn |&gt; plot_grouped_barplot_count(\"lot_config\", \"bldg_type\")\n\n\n\n\n\ndata_trn |&gt; plot_grouped_barplot_percent(\"lot_config\", \"bldg_type\")\n\n\n\n\n\nMay want to plot both ways\n\ndata_trn |&gt; plot_grouped_barplot_percent(\"lot_config\", \"bldg_type\")\n\n\n\n\n\ndata_trn |&gt; plot_grouped_barplot_percent(\"bldg_type\", \"lot_config\")\n\n\n\n\n\n\n\n2.5.15 Tile Plot for Ordinal Categorical (Bivariate)\nTile plots may be useful if both categorical variables are ordinal\n\nplot_tile &lt;- function(df, x, y){\n  df |&gt;\n    count(.data[[x]], .data[[y]]) |&gt;\n    ggplot(aes(x = .data[[x]], y = .data[[y]])) +\n    geom_tile(mapping = aes(fill = n))\n}\n\n\n\ndata_trn |&gt; plot_tile(\"overall_qual\", \"garage_qual\")\n\n\n\n\n\nYou might also consider a scatterplot with jitter in this instance\n\ndata_trn |&gt; \n  mutate(overall_qual = jitter(as.numeric(overall_qual)),\n         garage_qual = as.numeric(garage_qual)) |&gt; \n  plot_scatter(\"overall_qual\", \"garage_qual\")\n\n\n\n\n\n\n\n2.5.16 Two-way Tables for Categorical Variables (Bivariate)\nTwo-way tables are sometimes a useful summary statistic for two categorical variables. We can use a 2-variable form of the tab function, tab2(), from my function scripts for this\nFor example, the relationship between bldg_type and lot_config\n\ndata_trn |&gt; tab2(bldg_type, lot_config)\n\n   bldg_type corner culdsac fr2 fr3 inside\n      duplex     13       0   3   0     47\n     one_fam    221      73  29   1    892\n    town_end      8       5   3   0     92\n town_inside      0       3   3   0     40\n     two_fam      6       0   1   1     24"
  },
  {
    "objectID": "002_exploratory_data_analysis.html#working-with-recipes",
    "href": "002_exploratory_data_analysis.html#working-with-recipes",
    "title": "2  Exploratory Data Analysis",
    "section": "2.6 Working with Recipes",
    "text": "2.6 Working with Recipes\nRecipes are used for feature engineering in tidymodels using the recipes package\n\nUsed for transforming raw predictors into features used in our models\nDescribes all steps to make feature matrix. For example:\n\nTransforming factors into “dummy” features if needed\nLinear and non-linear transformations (e.g., log, box-cox)\nPolynomials and interactions (i.e., x1 * x1 or x1 * x2)\nMissing value imputations\n\nProper use of recipes is an important tool to prevent data leakage between train and either validation or test.\nRecipes use only information from the training set in all feature engineering\nConsider example of standardizing x1 for a feature in train vs. validation and test. Must use mean and sd from TRAIN to standardize x1 in train, validate, and test. VERY IMPORTANT.\n\n\nWe use recipes in a two step process - prep() and bake()\n\n“Prepping” a recipe involves calculating any statistics needed for the transformations that will be applied to engineer features (e.g., mean and standard deviation to normalize a numeric variable).\n\nPrepping is done with the prep() function.\nPrepping is always done only with training data. A “prepped” recipe does not derive any statistics from validation or test sets.\n\n“Baking” is the process of calculating the features\n\nBaking is done with the bake() function.\nWe used our prepped recipe when we bake.\nWhereas we only prep a recipe with training data, we can use a prepped recipe to bake features from any dataset (training, validation, or test).\n\n\n\nWe will work with recipes extensively when model building starting in unit 3\nFor now, we will only use the recipe to indicate roles as a gentle introduction.\nWe will expand on this recipe in unit 3\nRecipe syntax is very similar to generic tidyverse syntax (created by same group)\n\nActually a subset of tidyverse functions\nLess flexible/powerful but focused on our needs and easier to learn\nYou will eventually know both\n\n\nRecipes are used in Modeling scripts (which is a third type of script after cleaning and modeling EDA scripts)\n\nLets reload training again to pretend we are starting a new script\n\n\n data_trn &lt;- read_csv(file.path(path_data, \"ames_clean_class_trn.csv\"), \n                      col_types = cols()) |&gt; \n1  class_ames() |&gt;\n  glimpse()\n\n\n1\n\nRemember our function for classing!\n\n\n\n\nRows: 1,465\nColumns: 10\n$ sale_price   &lt;dbl&gt; 105000, 126000, 115000, 120000, 99500, 112000, 122000, 12…\n$ gr_liv_area  &lt;dbl&gt; 896, 882, 864, 836, 918, 1902, 900, 1225, 1728, 858, 1306…\n$ lot_area     &lt;dbl&gt; 11622, 8400, 10500, 2280, 7892, 8930, 9819, 9320, 13260, …\n$ year_built   &lt;dbl&gt; 1961, 1970, 1971, 1975, 1979, 1978, 1967, 1959, 1962, 195…\n$ overall_qual &lt;fct&gt; 5, 4, 4, 7, 6, 6, 5, 4, 5, 5, 3, 5, 4, 5, 3, 5, 2, 6, 5, …\n$ garage_cars  &lt;dbl&gt; 1, 2, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 2, 2, 1, …\n$ garage_qual  &lt;fct&gt; ta, ta, no_garage, ta, ta, ta, ta, no_garage, no_garage, …\n$ ms_zoning    &lt;fct&gt; res_high, res_low, res_low, res_low, res_low, res_med, re…\n$ lot_config   &lt;fct&gt; inside, corner, fr2, fr2, inside, inside, inside, inside,…\n$ bldg_type    &lt;fct&gt; one_fam, one_fam, one_fam, town_inside, town_end, duplex,…\n\n\n\nRecipes can be used to indicate the outcome and predictors that will be used in the model\n\nCan use . to indicate all predictors\n\nCurrently, our preferred method for larger data sets\nWe can exclude some predictors later by changing their role, removing them with a later recipe step (\\(step\\_rm()\\)), or specifying a more precise formula when we fit the model\nSee Roles in Recipes for more info\n\nCan use specific names of predictors along with \\(+\\)\n\nThis is our preferred method when we have a smaller set of predictors (We will show you both approaches)\ne.g., sale_price ~ lot_area + year_built + overall_qual\n\nDo NOT indicate interactions here\n\nAll predictors are combined with +\nInteractions are specified by a later explicit feature engineering step\n\n\n\nrec &lt;- recipe(sale_price ~ ., data = data_trn)\n\nrec\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 9\n\nsummary(rec)\n\n# A tibble: 10 × 4\n   variable     type      role      source  \n   &lt;chr&gt;        &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 gr_liv_area  &lt;chr [2]&gt; predictor original\n 2 lot_area     &lt;chr [2]&gt; predictor original\n 3 year_built   &lt;chr [2]&gt; predictor original\n 4 overall_qual &lt;chr [3]&gt; predictor original\n 5 garage_cars  &lt;chr [2]&gt; predictor original\n 6 garage_qual  &lt;chr [3]&gt; predictor original\n 7 ms_zoning    &lt;chr [3]&gt; predictor original\n 8 lot_config   &lt;chr [3]&gt; predictor original\n 9 bldg_type    &lt;chr [3]&gt; predictor original\n10 sale_price   &lt;chr [2]&gt; outcome   original\n\n\n\n\n2.6.1 Prepping and Baking a Recipe\nLet’s make a feature matrix from the training set\nThere are two discrete (and important) steps\n\nprep()\nbake()\n\nFirst we prep the recipe using the training data\n\n1rec_prep &lt;- rec |&gt;\n2  prep(training = data_trn)\n\n\n1\n\nWe start by prepping our raw/original recipe (rec)\n\n2\n\nWe use the prep() function on on the training data. Recipes are ALWAYS prepped using training data. This makes sure that are recipes will always only use information from the training set when making features for any subsequent dataset.\n\n\n\n\n\nSecond, we bake the training data using this prepped recipe to get a feature matrix from it.\n\nfeat_trn &lt;- rec_prep |&gt; \n  bake(new_data = data_trn)\n\n\nFinally, we should generally at least glimpse and/or skim (and typically do some more EDA) on our features to make sure our recipe is doing what we expect.\n\nglimpse\n\n\nfeat_trn |&gt; glimpse()\n\nRows: 1,465\nColumns: 10\n$ gr_liv_area  &lt;dbl&gt; 896, 882, 864, 836, 918, 1902, 900, 1225, 1728, 858, 1306…\n$ lot_area     &lt;dbl&gt; 11622, 8400, 10500, 2280, 7892, 8930, 9819, 9320, 13260, …\n$ year_built   &lt;dbl&gt; 1961, 1970, 1971, 1975, 1979, 1978, 1967, 1959, 1962, 195…\n$ overall_qual &lt;fct&gt; 5, 4, 4, 7, 6, 6, 5, 4, 5, 5, 3, 5, 4, 5, 3, 5, 2, 6, 5, …\n$ garage_cars  &lt;dbl&gt; 1, 2, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 2, 2, 1, …\n$ garage_qual  &lt;fct&gt; ta, ta, no_garage, ta, ta, ta, ta, no_garage, no_garage, …\n$ ms_zoning    &lt;fct&gt; res_high, res_low, res_low, res_low, res_low, res_med, re…\n$ lot_config   &lt;fct&gt; inside, corner, fr2, fr2, inside, inside, inside, inside,…\n$ bldg_type    &lt;fct&gt; one_fam, one_fam, one_fam, town_inside, town_end, duplex,…\n$ sale_price   &lt;dbl&gt; 105000, 126000, 115000, 120000, 99500, 112000, 122000, 12…\n\n\n\n\nskim\n\n\nfeat_trn |&gt; skim_all()\n\n\n\n\nData summary\n\n\n\n\nName\n\n\nfeat_trn\n\n\n\n\nNumber of rows\n\n\n1465\n\n\n\n\nNumber of columns\n\n\n10\n\n\n\n\n_______________________\n\n\n\n\n\n\nColumn type frequency:\n\n\n\n\n\n\nfactor\n\n\n5\n\n\n\n\nnumeric\n\n\n5\n\n\n\n\n________________________\n\n\n\n\n\n\nGroup variables\n\n\nNone\n\n\n\n\n\nVariable type: factor\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nn_unique\n\n\ntop_counts\n\n\n\n\n\n\noverall_qual\n\n\n0\n\n\n1\n\n\n10\n\n\n5: 424, 6: 350, 7: 304, 8: 176\n\n\n\n\ngarage_qual\n\n\n0\n\n\n1\n\n\n5\n\n\nta: 1312, no_: 81, fa: 57, gd: 13\n\n\n\n\nms_zoning\n\n\n0\n\n\n1\n\n\n7\n\n\nres: 1157, res: 217, flo: 66, com: 13\n\n\n\n\nlot_config\n\n\n0\n\n\n1\n\n\n5\n\n\nins: 1095, cor: 248, cul: 81, fr2: 39\n\n\n\n\nbldg_type\n\n\n0\n\n\n1\n\n\n5\n\n\none: 1216, tow: 108, dup: 63, tow: 46\n\n\n\n\n\nVariable type: numeric\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmean\n\n\nsd\n\n\np0\n\n\np25\n\n\np50\n\n\np75\n\n\np100\n\n\nskew\n\n\nkurtosis\n\n\n\n\n\n\ngr_liv_area\n\n\n0\n\n\n1\n\n\n1506.84\n\n\n511.44\n\n\n438\n\n\n1128\n\n\n1450\n\n\n1759\n\n\n5642\n\n\n1.43\n\n\n5.19\n\n\n\n\nlot_area\n\n\n0\n\n\n1\n\n\n10144.16\n\n\n8177.55\n\n\n1476\n\n\n7500\n\n\n9375\n\n\n11362\n\n\n164660\n\n\n11.20\n\n\n182.91\n\n\n\n\nyear_built\n\n\n0\n\n\n1\n\n\n1971.35\n\n\n29.65\n\n\n1880\n\n\n1953\n\n\n1972\n\n\n2000\n\n\n2010\n\n\n-0.54\n\n\n-0.62\n\n\n\n\ngarage_cars\n\n\n1\n\n\n1\n\n\n1.78\n\n\n0.76\n\n\n0\n\n\n1\n\n\n2\n\n\n2\n\n\n4\n\n\n-0.26\n\n\n0.10\n\n\n\n\nsale_price\n\n\n0\n\n\n1\n\n\n180696.15\n\n\n78836.41\n\n\n12789\n\n\n129500\n\n\n160000\n\n\n213500\n\n\n745000\n\n\n1.64\n\n\n4.60\n\n\n\n\n\n\n\n\nWe can now use our features from training to train models, but that will take place in the next unit!\nWe could also use the prepped recipe to bake validation or test data to evaluate trained models. That too will happen in the next unit!"
  },
  {
    "objectID": "002_exploratory_data_analysis.html#discussion-topics",
    "href": "002_exploratory_data_analysis.html#discussion-topics",
    "title": "2  Exploratory Data Analysis",
    "section": "2.7 Discussion Topics",
    "text": "2.7 Discussion Topics\n\nHouse keeping\n\nUnit 2 solutions\nCourse evals for extra credit (to quiz score)!\nUnit 3 homework\n\ntest set predictions\nfree lunch!\n\nQuestions to all three of us\nAn attempt at a reprex is generally expected now for code help\n\nQuiz review\nStudent Questions\n\ngreat questions!\nwrite them down as you read and watch lectures\nnot all questions will fit (slack as an alternative for follow-up)\n\n\n\n\n\n\nWickham, Hadley. 2019. Advanced r. 2nd ed. https://adv-r.hadley.nz/.\n\n\nWickham, Hadley, Çetinkaya-Rundel Mine, and Garrett Grolemund. 2023. R for Data Science: Visualize, Model, Transform, and Import Data. 2nd ed. https://r4ds.hadley.nz/."
  },
  {
    "objectID": "003_regression.html#distance-and-scaling-in-knn",
    "href": "003_regression.html#distance-and-scaling-in-knn",
    "title": "3  Introduction to Regression Models",
    "section": "3.7 Distance and Scaling in KNN",
    "text": "3.7 Distance and Scaling in KNN\n\n3.7.1 Defining “Nearest”\nTo make a prediction for some new observation, we need to identify the observations from the training set that are nearest to it\n\nNeed a distance measure to define “nearest”\nIMPORTANT: We care only about:\n\nDistance between a validation observation and all the training observations\nNeed to find the \\(k\\) observations in training that are nearest to the validation observation (i.e., its neighbors)\nDistance is defined based on these observations’ features, not their outcomes\n\nThere are a number of different distance measures available (e.g., Euclidean, Manhattan, Chebyshev, Cosine, Minkowski)\n\nEuclidean is most commonly used in KNN\n\n\n\nEuclidean distance between any two points is an n-dimensional extension of the Pythagorean formula (which applies explicitly with 2 features/2 dimensional space).\n\\(C^2 = A^2 + B^2\\)\n\\(C = \\sqrt{A^2 + B^2}\\)\n…where C is the distance between two points\n\nThe Euclidean distance between 2 points (p and q) in two dimensions (2 predictors, x1 = A, x2 = B)\n\\(Distance = \\sqrt{A^2 + B^2}\\)\n\\(Distance = \\sqrt{(q1 - p1)^2 + (q2 - p2)^2}\\)\n\\(Distance = \\sqrt{(2 - 1)^2 + (5 - 2)^2}\\)\n\\(Distance = 3.2\\)\n\n\n\n\n\n\nOne dimensional (one feature) is simply the subtraction of scores on that feature (x1) between p and q\n\\(Distance = \\sqrt{(q1 - p1)^2}\\)\n\\(Distance = \\sqrt{(2 - 1)^2}\\)\n\\(Distance = 1\\)\n\n\n\n\n\nN-dimensional generalization for n features:\n\\(Distance = \\sqrt{(q1 - p1)^2 + (q2 - p2)^2 + ... + (qn - pn)^2}\\)\n\nManhattan distance is also referred to as city block distance\n\nTravel down the “A” street for 1 unit\nTravel down the “B” street for 3 units\nTotal distance = 4 units\n\nFor two features/dimensions\n\\(Distance = |A + B|\\)\n\n\n\n\n\n\nkknn() uses Minkowski distance (see Wikipedia or less mathematical description)\n\nIt is a more complex parameterized distance formula\n\nThis parameter is called p, referred to as distance in kknn()\n\nEuclidean and Manhattan distances are special cases where p = 2 and 1, respectively\nThe default p in kknn() = 2 (Euclidean distance)\n\nThis default (like all defaults) can be changed when you define the algorithm using nearest_neighbor()\n\n\n\n\n3.7.2 Scaling X\nDistance is dependent on scales of all the features. We need to put all features on the same scale\n\nScale all features to SD = 1 (using step_scale(all_numeric_predictors()))\nRange correct [0, 1] all features (using step_range(all_numeric_predictors()))\n\n\n\n\n3.7.3 Categorical Predictors\nKNN requires numeric features (for distance calculation).\n\nFor categorical predictors, you will need to use dummy coding or other feature engineering that results in numeric features.\ne.g., step_dummy(all_nominal_predictors())"
  },
  {
    "objectID": "003_regression.html#knn-with-ames-housing-prices",
    "href": "003_regression.html#knn-with-ames-housing-prices",
    "title": "3  Introduction to Regression Models",
    "section": "3.8 KNN with Ames Housing Prices",
    "text": "3.8 KNN with Ames Housing Prices\nLet’s use KNN with Ames\n\nTrain a model using only numeric predictors and overall_qual as numeric\nUse the default k = 5 algorithm\nSet SD = 1 for all features\n\n\nrec <- \n  recipe(sale_price ~ gr_liv_area + lot_area + year_built + garage_cars + overall_qual, \n         data = data_trn) |> \n  step_impute_median(garage_cars) |> \n  step_mutate(overall_qual = as.numeric(overall_qual)) |> \n  step_scale(all_numeric_predictors()) # <1>\n\n\nRemember to take advantage of these selectors for easier code! See ?has_role for more details\n\n\n\nprep, bake\n\n\nrec_prep <- rec |> \n  prep(data_trn)\n\nfeat_trn <- rec_prep |>\n  bake(data_trn)\n\nfeat_val <- rec_prep |> \n  bake(data_val)\n\n\n\nSkim training features. Note all SD = 1\n\n\nfeat_trn |> skim_all()\n\n\nData summary\n\n\nName\nfeat_trn\n\n\nNumber of rows\n1465\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n2.95\n1.00\n0.86\n2.21\n2.84e+00\n3.44\n11.03\n1.43\n5.19\n\n\nlot_area\n0\n1\n1.24\n1.00\n0.18\n0.92\n1.15e+00\n1.39\n20.14\n11.20\n182.91\n\n\nyear_built\n0\n1\n66.48\n1.00\n63.40\n65.86\n6.65e+01\n67.45\n67.79\n-0.54\n-0.62\n\n\ngarage_cars\n0\n1\n2.33\n1.00\n0.00\n1.31\n2.62e+00\n2.62\n5.23\n-0.26\n0.10\n\n\noverall_qual\n0\n1\n4.30\n1.00\n0.71\n3.54\n4.24e+00\n4.95\n7.07\n0.20\n-0.03\n\n\nsale_price\n0\n1\n180696.15\n78836.41\n12789.00\n129500.00\n1.60e+05\n213500.00\n745000.00\n1.64\n4.60\n\n\n\n\n\n\n\nSkim validation features. Note SD. Why not exactly 1?\n\n\nfeat_val |> skim_all()\n\n\nData summary\n\n\nName\nfeat_val\n\n\nNumber of rows\n490\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nskew\nkurtosis\n\n\n\n\ngr_liv_area\n0\n1\n2.92\n0.95\n0.94\n2.24\n2.81\n3.38\n7.05\n0.92\n1.16\n\n\nlot_area\n0\n1\n1.28\n1.27\n0.21\n0.92\n1.17\n1.44\n26.32\n15.64\n301.66\n\n\nyear_built\n0\n1\n66.47\n1.04\n63.23\n65.90\n66.61\n67.45\n67.79\n-0.66\n-0.41\n\n\ngarage_cars\n0\n1\n2.27\n0.99\n0.00\n1.31\n2.62\n2.62\n5.23\n-0.24\n0.22\n\n\noverall_qual\n0\n1\n4.28\n0.98\n0.71\n3.54\n4.24\n4.95\n7.07\n0.00\n0.35\n\n\nsale_price\n0\n1\n178512.82\n75493.59\n35311.00\n129125.00\n160000.00\n213000.00\n556581.00\n1.42\n2.97\n\n\n\n\n\n\n\nFit 5NN\n\n\nfit_5nn_5num <- \n  nearest_neighbor() |>   \n  set_engine(\"kknn\") |>   \n  set_mode(\"regression\") |> \n  fit(sale_price ~ ., data = feat_trn)\n\n\n\nerror_val <- bind_rows(error_val, \n                        tibble(model = \"5 numeric predictor 5nn\", \n                               rmse_val = rmse_vec(feat_val$sale_price, \n                                                   predict(fit_5nn_5num, feat_val)$.pred)))\n\nerror_val\n\n# A tibble: 8 × 2\n  model                                  rmse_val\n  <chr>                                     <dbl>\n1 simple linear model                      51375.\n2 4 feature linear model                   39903.\n3 4 feature linear model with YJ           41660.\n4 6 feature linear model w/ms_zoning       39846.\n5 7 feature linear model                   34080.\n6 8 feature linear model w/interaction     32720.\n7 10 feature linear model w/interactions   32708.\n8 5 numeric predictor 5nn                  32837.\n\n\n\nNot bad!\n\n\nKNN also mostly solved the linearity problem\n\nWe might be able to improve the linear models with better transformations of X and Y\nHowever, this wasn’t needed for KNN!\n\n\nplot_truth(truth = feat_val$sale_price, \n           estimate = predict(fit_5nn_5num, feat_val)$.pred)\n\n\n\n\n\nBut 5NN may be overfit. k = 5 is pretty low\nAgain with k = 20\n\nfit_20nn_5num <- \n  nearest_neighbor(neighbors = 20) |>   \n  set_engine(\"kknn\") |>   \n  set_mode(\"regression\") |> \n  fit(sale_price ~ ., data = feat_trn)\n\n\n\n\n# A tibble: 9 × 2\n  model                                  rmse_val\n  <chr>                                     <dbl>\n1 simple linear model                      51375.\n2 4 feature linear model                   39903.\n3 4 feature linear model with YJ           41660.\n4 6 feature linear model w/ms_zoning       39846.\n5 7 feature linear model                   34080.\n6 8 feature linear model w/interaction     32720.\n7 10 feature linear model w/interactions   32708.\n8 5 numeric predictor 5nn                  32837.\n9 5 numeric predictor 20nn                 30535.\n\n\n\nThat helped some\n\n\nOne more time with k = 50 to see where we are in the bias-variance function\n\nfit_50nn_5num <- \n  nearest_neighbor(neighbors = 50) |>   \n  set_engine(\"kknn\") |>   \n  set_mode(\"regression\") |> \n  fit(sale_price ~ ., data = feat_trn)\n\n\n\n\n# A tibble: 10 × 2\n   model                                  rmse_val\n   <chr>                                     <dbl>\n 1 simple linear model                      51375.\n 2 4 feature linear model                   39903.\n 3 4 feature linear model with YJ           41660.\n 4 6 feature linear model w/ms_zoning       39846.\n 5 7 feature linear model                   34080.\n 6 8 feature linear model w/interaction     32720.\n 7 10 feature linear model w/interactions   32708.\n 8 5 numeric predictor 5nn                  32837.\n 9 5 numeric predictor 20nn                 30535.\n10 5 numeric predictor 50nn                 31055.\n\n\n\nToo high, now we have bias……\nWe will learn a more rigorous method for selecting the optimal value for \\(k\\) (i.e., tuning this hyperparameter) in unit 5\n\n\nTo better understand bias-variance trade-off, let’s look at error across these three values of \\(k\\) in train and validation for Ames\nTraining\n\nRemember that training error would be 0 for k = 1\nTraining error is increasing as \\(k\\) increases b/c it KNN is overfitting less (so its not fitting the noise in train as well)\n\n\nrmse_vec(feat_trn$sale_price, \n         predict(fit_5nn_5num, feat_trn)$.pred)\n\n[1] 19012.94\n\nrmse_vec(feat_trn$sale_price, \n         predict(fit_20nn_5num, feat_trn)$.pred)\n\n[1] 27662.2\n\nrmse_vec(feat_trn$sale_price, \n         predict(fit_50nn_5num, feat_trn)$.pred)\n\n[1] 31069.12\n\n\n\nValidation\n\nValidation error is first going down as \\(k\\) increases (and it would have been very high for k = 1)\nBias is likely increasing a bit\nBut this is compensated by big decreases in overfitting variance\nThe trade-off is good for k = 20 relative to 5 and 1\nAt some point, as \\(k\\) increases the increase in bias outweighed the decrease in variance and validation error increased too.\n\n\nrmse_vec(feat_val$sale_price, \n         predict(fit_5nn_5num, feat_val)$.pred)\n\n[1] 32837.37\n\nrmse_vec(feat_val$sale_price, \n         predict(fit_20nn_5num, feat_val)$.pred)\n\n[1] 30535.04\n\nrmse_vec(feat_val$sale_price, \n         predict(fit_50nn_5num, feat_val)$.pred)\n\n[1] 31054.6\n\n\n\nLet’s do one final example and add one of our nominal variables into the model: ms_zoning\n\nNeed to collapse levels and then dummy\n\n\nrec <- \n  recipe(sale_price ~ gr_liv_area + lot_area + year_built + garage_cars + \n           overall_qual + ms_zoning, data = data_trn) |> \n  step_impute_median(garage_cars) |> \n  step_mutate(overall_qual = as.numeric(overall_qual)) |> \n  step_mutate(ms_zoning = fct_collapse(ms_zoning,\n                                 \"residential\" = c(\"res_high\", \"res_med\", \"res_low\"),\n                                 \"commercial\" = c(\"agri\", \"commer\", \"indus\"),\n                                 \"floating\" = \"float\")) |>\n  step_dummy(ms_zoning) |> \n  step_scale(all_numeric_predictors())\n\n\n\nprep, bake\n\n\nrec_prep <- rec |> \n  prep(data_trn)\n\nfeat_trn <- rec_prep |> \n  bake(data_trn)\n\nfeat_val <- rec_prep |> \n  bake(data_val)\n\n\n\nFit\n\n\nfit_20nn_5num_mszone <- \n  nearest_neighbor(neighbors = 20) |>   \n  set_engine(\"kknn\") |>   \n  set_mode(\"regression\") |> \n  fit(sale_price ~ ., data = feat_trn)\n\n\n\nevaluate\n\n\n\n# A tibble: 11 × 2\n   model                                   rmse_val\n   <chr>                                      <dbl>\n 1 simple linear model                       51375.\n 2 4 feature linear model                    39903.\n 3 4 feature linear model with YJ            41660.\n 4 6 feature linear model w/ms_zoning        39846.\n 5 7 feature linear model                    34080.\n 6 8 feature linear model w/interaction      32720.\n 7 10 feature linear model w/interactions    32708.\n 8 5 numeric predictor 5nn                   32837.\n 9 5 numeric predictor 20nn                  30535.\n10 5 numeric predictor 50nn                  31055.\n11 5 numeric predictor 20nn with ms_zoning   30172.\n\n\n\nNow it helps.\n\nMight have to do with interactions with other predictors that we didn’t model in the linear model\nKNN automatically accommodates interactions. Why?\nThis model is a bit more complex and might benefit further from higher \\(k\\)\n\n\nAs a teaser, here is another performance metric for this model - \\(R^2\\). Not too shabby! Remember, there is certainly some irreducible error in sale_price that will put a ceiling on \\(R^2\\) and a floor on RMSE\n\nrsq_vec(feat_val$sale_price, \n        predict(fit_20nn_5num_mszone, feat_val)$.pred)\n\n[1] 0.8404044\n\n\nOverall, we now have a model that predicts housing prices with about 30K of RMSE and accounting for 84% of the variance. I am sure you can improve on this!"
  }
]