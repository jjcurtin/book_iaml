---
editor_options: 
  chunk_output_type: console
---

# IAML Unit 2: Dicussion

## Housekeeping

- Unit 2 solutions
- Course evals for extra credit (to quiz score)!
- Unit 3 homework
  - test set predictions
  - free lunch!
- Questions to all three of us
- An attempt at a reprex is generally expected now for code help

--------------------------------------------------------------------------------

## Quiz review and student questions

- Quiz review

- Student Questions
  - great questions!
  - write them down as you read and watch lectures
  - not all questions will fit (slack as an alternative for follow-up)
  
--------------------------------------------------------------------------------  
  
## Possible topics

1. Review
    - Goal is to develop model that closely approximates DGP
    - Goal is to evaluate (estimate) how close our model is to the DGP (how much error) with as little error as possible
    - Bias, overfitting/variance for any estimate (model and performance of model)
    - candidate model configurations
    - fit, select, evaluate
    - training, validation, test


2. Review: 2.2.1 Stages of Data Analysis and Model Development

3. Best practices (discuss quickly)
    - csv for data sharing, viewing, git (though be careful with data in github or other public repo!)
    - variable values saved as text when nominal and ordinal (self-documenting)
    - Create data dictionary - Documentation is critical!!
    - snake_case for variables and self-documenting names (systematic names too)

4. Review: 2.3.1 Data Leakage Issues
    - Review section in webbook
    - Cleaning EDA is done with full dataset (but univariate).  Very limited (variable names, values, find errors)
    - Modeling EDA is only done with a training set (or even "eyeball" sample) - NEVER use validate or test set
    - Never estimate anything with full data set (e.g., missing values, standardize, etc)
    - Use recipes, prep (all estimation) with held in data than bake the appropriate set
    - Put test aside
    - You work with validation but never explore with validation (will still catch leakage with test but will be mislead to be overly optimistic and spoil test)
    
5. Functions sidenote - fun_modeling.R on [github](https://github.com/jjcurtin/lab_support)

6. Review: 2.4.2 Prepping and Baking a Recipe
     - Review section in web book
     - prep always with held in data, bake with held in & out data.

7. EDA for modeling

    - limitless, just scratched the surface
    - Differs some based on dimenstionality of dataset
    - Learning about DGP
      - understand univariate distributions, frequencies
      - bivariate relationships
      - interactions (3 or more variables)
      - patterns in data


8.  Extra topics, time permitting

8.1. Missing data
  
    - Exclude vs. Impute in training data.  Outcomes?
    - How to impute
    - Missing in validate or test (can't exclude?). Exclude cases with missing outcomes.

8.2. Outliers
    - Drop or fix errors!
    - Goal is always to estimate DGP
    - Exclude
    - Retain
    - Bring to fence
    - Don't exclude/change outcome in validate/test

8.3. Issues with high dimensionality

    - Hard to do predictor level EDA
    - Common choices (normality transformations)
    - observed vs. predicted plots
    - Methods for automated variable selection (glmnet)
    
8.4. Distributional Shape

    - Measurement issues (interval scale)
    - Implications for relationships with other variables
    - Solutions?
  
8.5. Linearity vs. More Complex Relationships

    - Transformations
    - Choice of statistical algorithm
    - Do you need a linear model?

8.6. Interactions

    - Domain expertise
    - Visual options for interactions
    - But what do do with high dimensional data?
    - Explanatory vs. prediction goals (algorithms that accommodate interactions)

8.7. How to handle all of these decisions in the machine learning framework

    - Goal is to develop a model that most closely approximates the DGP
    - How does validation and test help this?
    - Preregistration?
      - Pre-reg for performance metric, resampling method   
      - Use of resampling for other decisions
      - Use of resampling to find correct model to test explanatory goals
  
  
8.8. Model Assumptions

    - Why do we make assumptions?
      - Inference
      - Flexibility wrt DGP
 
