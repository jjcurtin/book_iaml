---
editor_options: 
  chunk_output_type: console
---

# Autoencoder for Dimensionality Reduction

```{r}
library(tidyverse)
library(tidymodels)
options(conflicts.policy = "depends.ok")
library(keras, exclude = "get_weights")
```


```{r}
path_data <- "./data"
data_trn <- read_csv(here::here(path_data, "mnist_train.csv.gz"),
                     col_types = cols()) |> 
  mutate(y = factor(y, levels = 0:9, labels = 0:9))
data_trn |> dim()

data_val <- data_trn()

data_test <- read_csv(here::here(path_data, "mnist_test.csv"),
                      col_types = cols()) |> 
    mutate(y = factor(y, levels = 0:9, labels = 0:9))
data_test |> dim()
```




```{r}
# # Determine the number of rows in the dataset
n <- nrow(iris)

# Create a random sample of row indices for the training set (80% of the data)
trainIndex <- sample(seq_len(n), size = 0.8 * n)

# Split the data into training and validation sets
trainData <- iris[trainIndex, ]
validationData <- iris[-trainIndex, ]
```












## Notes from other resources

from Matt

https://github.com/MCooperBorkenhagen/tutorials/blob/main/keras_hidden_layer.Rmd


useful examples with code from web
https://statslab.eighty20.co.za/posts/autoencoders_keras_r/

https://nbisweden.github.io/workshop-neural-nets-and-deep-learning/session_rAutoencoders/lab_autoencoder_hapmap.html

https://www.reddit.com/r/learnmachinelearning/comments/1dkt5i8/build_your_first_autoencoder_in_keras/


https://blog.keras.io/building-autoencoders-in-keras.html

https://reintech.io/blog/mastering-autoencoders-with-r#google_vignette


https://medium.com/@hassaanidrees7/autoencoders-vs-pca-dimensionality-reduction-for-complex-data-e07d4612b711


https://medium.com/data-science/autoencoders-vs-pca-when-to-use-which-73de063f5d7


https://www.linkedin.com/pulse/autoencoders-pca-bridging-gap-machine-learning-sehrish-iqbal-93gff/
