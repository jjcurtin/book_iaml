{
  "hash": "d2ca19ca411d8d54aa464d0b06619959",
  "result": {
    "engine": "knitr",
    "markdown": "---\noutput: html_document\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n# Novel Levels in Held-Out Set(s) { .unnumbered}\nWhen you have nominal/ordinal predictors that have levels that are infrequent, you will occasionally find that an infrequent level appears in your held out set (i.e., validation or test) but not in your training set.  This can cause problems when you try to make predictions for these new values.  Specifically, the feature values for this level will be set to NA and therefore, you will get predictions of NA for these observations. \n\nIn this appendix, we demonstrate this problem and our preferred solution given our workflow of classing all nominal/ordinal predictors as factors in our dataframes.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) \nlibrary(tidymodels) \ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true\")\n```\n:::\n\n\n\n\nMake simple data sets with an outcome (`y`) and one nominal predictor (`x`).  Note that `x` will have a novel value (`foo`) in the test set that wasnt present in the training set.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 6\ndata_trn <- tibble(y = rnorm(n), \n                   x = rep (c(\"a\", \"b\", \"c\"), n/3)) |>\n  mutate(x = factor(x, levels = c(\"a\", \"b\", \"c\"))) |> \n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n        y x    \n    <dbl> <fct>\n1  1.16   a    \n2 -1.01   b    \n3  0.929  c    \n4 -0.494  a    \n5  0.0734 b    \n6 -0.580  c    \n```\n\n\n:::\n\n```{.r .cell-code}\ndata_test <- tibble(y = c(rnorm(n), rnorm(1)),\n                    x = c(rep (c(\"a\", \"b\", \"c\"), n/3), \"foo\")) |> \n  mutate(x = factor(x, levels = c(\"a\", \"b\", \"c\", \"foo\"))) |> \n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 2\n         y x    \n     <dbl> <fct>\n1  0.836   a    \n2  0.412   b    \n3 -0.0199  c    \n4 -0.968   a    \n5  0.00296 b    \n6 -0.864   c    \n7 -0.306   foo  \n```\n\n\n:::\n:::\n\n\n\n\nMake a recipe\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <- recipe(y ~ x, data = data_trn) %>% \n  step_dummy(x)\n```\n:::\n\n\n\n\nPrep the recipe with training data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_prep <- rec |> \n  prep(data_trn)\n```\n:::\n\n\n\n\nFeatures for training set.  No problems \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfeat_trn <- rec_prep |> \n  bake(NULL)\n\nfeat_trn |> skim_all()\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |         |\n|:------------------------|:--------|\n|Name                     |feat_trn |\n|Number of rows           |6        |\n|Number of columns        |3        |\n|_______________________  |         |\n|Column type frequency:   |         |\n|numeric                  |3        |\n|________________________ |         |\n|Group variables          |None     |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate| mean|   sd|    p0|   p25|   p50|  p75| p100| skew| kurtosis|\n|:-------------|---------:|-------------:|----:|----:|-----:|-----:|-----:|----:|----:|----:|--------:|\n|y             |         0|             1| 0.01| 0.88| -1.01| -0.56| -0.21| 0.71| 1.16| 0.22|    -1.93|\n|x_b           |         0|             1| 0.33| 0.52|  0.00|  0.00|  0.00| 0.75| 1.00| 0.54|    -1.96|\n|x_c           |         0|             1| 0.33| 0.52|  0.00|  0.00|  0.00| 0.75| 1.00| 0.54|    -1.96|\n\n\n:::\n:::\n\n\n\n\nFeatures for test set.  \n\n- Now we see the problem indicated by the warning about new level in test.\n- We see that one observation is missing for `x` in test.  If we looked closer, we would see this is the observation for `foo`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfeat_test <- rec_prep |> \n  bake(data_test)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: ! There are new levels in `x`: foo.\nℹ Consider using step_novel() (`?recipes::step_novel()`) \\ before\n  `step_dummy()` to handle unseen values.\n```\n\n\n:::\n\n```{.r .cell-code}\nfeat_test |> skim_all()\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |          |\n|:------------------------|:---------|\n|Name                     |feat_test |\n|Number of rows           |7         |\n|Number of columns        |3         |\n|_______________________  |          |\n|Column type frequency:   |          |\n|numeric                  |3         |\n|________________________ |          |\n|Group variables          |None      |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|  mean|   sd|    p0|   p25|   p50|  p75| p100| skew| kurtosis|\n|:-------------|---------:|-------------:|-----:|----:|-----:|-----:|-----:|----:|----:|----:|--------:|\n|y             |         0|          1.00| -0.13| 0.65| -0.97| -0.59| -0.02| 0.21| 0.84| 0.04|    -1.60|\n|x_b           |         1|          0.86|  0.33| 0.52|  0.00|  0.00|  0.00| 0.75| 1.00| 0.54|    -1.96|\n|x_c           |         1|          0.86|  0.33| 0.52|  0.00|  0.00|  0.00| 0.75| 1.00| 0.54|    -1.96|\n\n\n:::\n:::\n\n\n\n\nWe handle this problem of potential new levels in held-out data by inserting `step_novel()` prior to `step_dummy()` in our recipe.\nThis assigns all potential novel (unseen in training) levels to a new category called `new` by default\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_novel <- recipe(y ~ x, data = data_trn) |>  \n  step_novel(x) |> \n  step_dummy(x)\n```\n:::\n\n\n\n\nWhen we now prep this recipe using training data that does not contain `foo` (our novel level we will find in test), everything is fine\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_novel_prep <- rec_novel |> \n  prep(data_trn)\n```\n:::\n\n\n\n\nWhen we bake features for training data, we see what `step_novel()` did.  It added a new level and therefore a new feature to code the contrast of that level with the reference level.  However, given that this new level was not present in our training data, all observations are assigned a zero for this new feature.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfeat_trn_novel <- rec_novel_prep |> \n  bake(NULL)\n\nfeat_trn_novel |> bind_cols(data_trn |> select(x)) |> print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n        y   x_b   x_c x_new x    \n    <dbl> <dbl> <dbl> <dbl> <fct>\n1  1.16       0     0     0 a    \n2 -1.01       1     0     0 b    \n3  0.929      0     1     0 c    \n4 -0.494      0     0     0 a    \n5  0.0734     1     0     0 b    \n6 -0.580      0     1     0 c    \n```\n\n\n:::\n:::\n\n\n\n\nBut now when we bake the test data, this new feature is set to 1 for observations associated with this new level `foo`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfeat_test_novel <- rec_novel_prep |> \n  bake(data_test)\n\nfeat_test_novel |> bind_cols(data_test |> select(x)) |> print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 5\n         y   x_b   x_c x_new x    \n     <dbl> <dbl> <dbl> <dbl> <fct>\n1  0.836       0     0     0 a    \n2  0.412       1     0     0 b    \n3 -0.0199      0     1     0 c    \n4 -0.968       0     0     0 a    \n5  0.00296     1     0     0 b    \n6 -0.864       0     1     0 c    \n7 -0.306       0     0     1 foo  \n```\n\n\n:::\n:::\n\n\n\n\nAll looks normal when we fit this model to our training features\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_novel <-\n  linear_reg() %>% \n  set_engine(\"lm\") %>% \n  fit(y ~ ., data = feat_trn_novel)\n```\n:::\n\n\n\n\nHowever, if we look at the parameter estimates, we see that the algorithm was unable to estimate a parameter for `x_foo` because it was a constant in train.  Of course, this makes sense because there were no observations of `foo` in training so the model coouldnt learn how that new level differed from the reference level.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_novel %>% tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n  term        estimate std.error statistic p.value\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    0.335     0.719     0.466   0.673\n2 x_b           -0.806     1.02     -0.792   0.486\n3 x_c           -0.161     1.02     -0.158   0.885\n4 x_new         NA        NA        NA      NA    \n```\n\n\n:::\n:::\n\n\n\n\n\nThis model will now generate a warning (*\"prediction from a rank-deficient fit has doubtful cases\"*) when you use this model to make predictions for values it didnt see in the training set.\n\n- The consequence is that the model will predict a `y` value associated with the reference level (coded 0 for all  other dummy features) for all `foo` observations.  This is probably the best we can do for these new (previously unseen) values for x.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(fit_novel, feat_test_novel) |>  \n  bind_cols(feat_test_novel)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\", : prediction from rank-deficient fit; consider predict(.,\nrankdeficient=\"NA\")\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 5\n   .pred        y   x_b   x_c x_new\n   <dbl>    <dbl> <dbl> <dbl> <dbl>\n1  0.335  0.836       0     0     0\n2 -0.471  0.412       1     0     0\n3  0.174 -0.0199      0     1     0\n4  0.335 -0.968       0     0     0\n5 -0.471  0.00296     1     0     0\n6  0.174 -0.864       0     1     0\n7  0.335 -0.306       0     0     1\n```\n\n\n:::\n:::\n\n\n\n\nYou do not need to use `step_novel()` always.  Just put it into a recipe if you find that there are novel levels in your held-out data (and re-prep the recipe after you add that step of course~)",
    "supporting": [
      "app_dummy_coding_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}