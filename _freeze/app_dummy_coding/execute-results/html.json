{
  "hash": "cf39d0c6cac362fe34b341e81639e3d5",
  "result": {
    "engine": "knitr",
    "markdown": "---\noutput: html_document\neditor_options: \n  chunk_output_type: console\n---\n\n\n# Novel Levels in Held-Out Set(s)\nWhen you have nominal/ordinal predictors that have levels that are infrequent, you will occasionally find that an infrequent level appears in your held out set (i.e., validation or test) but not in your training set.  This can cause problems when you try to make predictions for these new values.  Specifically, the feature values for this level will be set to NA and therefore, you will get predictions of NA for these observations. \n\nIn this appendix, we demonstrate this problem and our preferred solution given our workflow of classing all nominal/ordinal predictors as factors in our dataframes.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) \nlibrary(tidymodels) \ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true\")\n```\n:::\n\n\nMake simple data sets with an outcome (`y`) and one nominal predictor (`x`).  Note that `x` will have a novel value (`foo`) in the test set that wasnt present in the training set.\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 6\ndata_trn <- tibble(y = rnorm(n), \n                   x = rep (c(\"a\", \"b\", \"c\"), n/3)) |>\n  mutate(x = factor(x, levels = c(\"a\", \"b\", \"c\"))) |> \n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n       y x    \n   <dbl> <fct>\n1  1.03  a    \n2 -0.478 b    \n3  0.772 c    \n4  0.948 a    \n5  0.214 b    \n6  0.333 c    \n```\n\n\n:::\n\n```{.r .cell-code}\ndata_test <- tibble(y = c(rnorm(n), rnorm(1)),\n                    x = c(rep (c(\"a\", \"b\", \"c\"), n/3), \"foo\")) |> \n  mutate(x = factor(x, levels = c(\"a\", \"b\", \"c\", \"foo\"))) |> \n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 2\n        y x    \n    <dbl> <fct>\n1 -0.0664 a    \n2 -0.520  b    \n3 -0.994  c    \n4 -0.980  a    \n5 -0.191  b    \n6  0.125  c    \n7  0.783  foo  \n```\n\n\n:::\n:::\n\n\nMake a recipe\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <- recipe(y ~ x, data = data_trn) %>% \n  step_dummy(x)\n```\n:::\n\n\nPrep the recipe with training data\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_prep <- rec |> \n  prep(data_trn)\n```\n:::\n\n\nFeatures for training set.  No problems \n\n::: {.cell}\n\n```{.r .cell-code}\nfeat_trn <- rec_prep |> \n  bake(data_trn)\n\nfeat_trn |> skim_all()\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |         |\n|:------------------------|:--------|\n|Name                     |feat_trn |\n|Number of rows           |6        |\n|Number of columns        |3        |\n|_______________________  |         |\n|Column type frequency:   |         |\n|numeric                  |3        |\n|________________________ |         |\n|Group variables          |None     |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate| mean|   sd|    p0|  p25|  p50|  p75| p100|  skew| kurtosis|\n|:-------------|---------:|-------------:|----:|----:|-----:|----:|----:|----:|----:|-----:|--------:|\n|y             |         0|             1| 0.47| 0.57| -0.48| 0.24| 0.55| 0.90| 1.03| -0.51|    -1.45|\n|x_b           |         0|             1| 0.33| 0.52|  0.00| 0.00| 0.00| 0.75| 1.00|  0.54|    -1.96|\n|x_c           |         0|             1| 0.33| 0.52|  0.00| 0.00| 0.00| 0.75| 1.00|  0.54|    -1.96|\n\n\n:::\n:::\n\n\nFeatures for test set.  \n\n- Now we see the problem indicated by the warning about new level in test.\n- We see that one observation is missing for `x` in test.  If we looked closer, we would see this is the observation for `foo`\n\n::: {.cell}\n\n```{.r .cell-code}\nfeat_test <- rec_prep |> \n  bake(data_test)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: ! There are new levels in a factor: `foo`.\n```\n\n\n:::\n\n```{.r .cell-code}\nfeat_test |> skim_all()\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |          |\n|:------------------------|:---------|\n|Name                     |feat_test |\n|Number of rows           |7         |\n|Number of columns        |3         |\n|_______________________  |          |\n|Column type frequency:   |          |\n|numeric                  |3         |\n|________________________ |          |\n|Group variables          |None      |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|  mean|   sd|    p0|   p25|   p50|  p75| p100| skew| kurtosis|\n|:-------------|---------:|-------------:|-----:|----:|-----:|-----:|-----:|----:|----:|----:|--------:|\n|y             |         0|          1.00| -0.26| 0.63| -0.99| -0.75| -0.19| 0.03| 0.78| 0.25|    -1.42|\n|x_b           |         1|          0.86|  0.33| 0.52|  0.00|  0.00|  0.00| 0.75| 1.00| 0.54|    -1.96|\n|x_c           |         1|          0.86|  0.33| 0.52|  0.00|  0.00|  0.00| 0.75| 1.00| 0.54|    -1.96|\n\n\n:::\n:::\n\n\nWe solve this problem but just making sure this level was listed when we created the factor in training (e.g., use this mutate earlier when classing `x` in `data_trn`: `mutate(x = factor(x, levels = c(\"a\", \"b\", \"c\", \"foo\")))`.  \n\nOr we can add the level after the fact, when we discover the problem (as below).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_trn1 <- data_trn |> \n  mutate(x = factor(x, levels = c(\"a\", \"b\", \"c\", \"foo\")))\n```\n:::\n\n\nNow prep recipe with this updated training set that includes `foo` level\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_prep1 <- rec |> \n  prep(data_trn1)\n```\n:::\n\n\nFeatures for training as before\n\n- We now have a feature for this new level\n- It is set to 0 for all observations (because there are no observations with a value of `foo` in training set)\n\n::: {.cell}\n\n```{.r .cell-code}\nfeat_trn1 <- rec_prep1 |> \n  bake(data_trn1)\n\nfeat_trn1 |> skim_all()\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |          |\n|:------------------------|:---------|\n|Name                     |feat_trn1 |\n|Number of rows           |6         |\n|Number of columns        |4         |\n|_______________________  |          |\n|Column type frequency:   |          |\n|numeric                  |4         |\n|________________________ |          |\n|Group variables          |None      |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate| mean|   sd|    p0|  p25|  p50|  p75| p100|  skew| kurtosis|\n|:-------------|---------:|-------------:|----:|----:|-----:|----:|----:|----:|----:|-----:|--------:|\n|y             |         0|             1| 0.47| 0.57| -0.48| 0.24| 0.55| 0.90| 1.03| -0.51|    -1.45|\n|x_b           |         0|             1| 0.33| 0.52|  0.00| 0.00| 0.00| 0.75| 1.00|  0.54|    -1.96|\n|x_c           |         0|             1| 0.33| 0.52|  0.00| 0.00| 0.00| 0.75| 1.00|  0.54|    -1.96|\n|x_foo         |         0|             1| 0.00| 0.00|  0.00| 0.00| 0.00| 0.00| 0.00|   NaN|      NaN|\n\n\n:::\n:::\n\n\nNow there is no problem when we find this value for an observation in the test set.\n\n::: {.cell}\n\n```{.r .cell-code}\nfeat_test1 <- rec_prep1 |> \n  bake(data_test)\n\nfeat_test1 |> skim_all()\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |           |\n|:------------------------|:----------|\n|Name                     |feat_test1 |\n|Number of rows           |7          |\n|Number of columns        |4          |\n|_______________________  |           |\n|Column type frequency:   |           |\n|numeric                  |4          |\n|________________________ |           |\n|Group variables          |None       |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|  mean|   sd|    p0|   p25|   p50|  p75| p100| skew| kurtosis|\n|:-------------|---------:|-------------:|-----:|----:|-----:|-----:|-----:|----:|----:|----:|--------:|\n|y             |         0|             1| -0.26| 0.63| -0.99| -0.75| -0.19| 0.03| 0.78| 0.25|    -1.42|\n|x_b           |         0|             1|  0.29| 0.49|  0.00|  0.00|  0.00| 0.50| 1.00| 0.75|    -1.60|\n|x_c           |         0|             1|  0.29| 0.49|  0.00|  0.00|  0.00| 0.50| 1.00| 0.75|    -1.60|\n|x_foo         |         0|             1|  0.14| 0.38|  0.00|  0.00|  0.00| 0.00| 1.00| 1.62|     0.80|\n\n\n:::\n:::\n\n\nAll is good.  BUT, there are still some complexities when we fit this model in train and predict into test.  In training, the `x_foo` feature is a constant (all 0) so this will present some issues for some statistical algorithms.  Lets see what happens when we fit a linear model and use it to  predict into test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <-\n  linear_reg() %>% \n  set_engine(\"lm\") %>% \n  fit(y ~ ., data = feat_trn1)\n```\n:::\n\n\nIf we look at the parameter estimates, we see that the algorithm was unable to estimate a parameter for `x_foo` because it was a constant in train\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 %>% tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n  term        estimate std.error statistic p.value\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    0.989     0.238      4.16  0.0253\n2 x_b           -1.12      0.336     -3.33  0.0446\n3 x_c           -0.436     0.336     -1.30  0.285 \n4 x_foo         NA        NA         NA    NA     \n```\n\n\n:::\n:::\n\n\nThis will generate a warning (*\"prediction from a rank-deficient fit has doubtful cases\"*) when you use this model to make predictions for values it didnt see in the training set.\n\n- The consequence is that the model will predict a `y` value associated with the reference level (coded 0 for all  other dummy features) for all `foo` observations.  This is probably the best we can do for these new (previously unseen) values for x.\n- also note that the column name for predictions, which is usually called `.pred`, is now called `.pred_res`.  You will need to accomodate this in your code as well.  Just rename it.\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(fit1, feat_test1) |>  \n  bind_cols(feat_test1)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\", : prediction from rank-deficient fit; consider predict(.,\nrankdeficient=\"NA\")\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 5\n   .pred       y   x_b   x_c x_foo\n   <dbl>   <dbl> <dbl> <dbl> <dbl>\n1  0.989 -0.0664     0     0     0\n2 -0.132 -0.520      1     0     0\n3  0.553 -0.994      0     1     0\n4  0.989 -0.980      0     0     0\n5 -0.132 -0.191      1     0     0\n6  0.553  0.125      0     1     0\n7  0.989  0.783      0     0     1\n```\n\n\n:::\n:::\n\n\nThis is our preferred solution when new/previously unseen values exist in held out data.  A comparable solution is offered as a recipe step.  See `step_novel()`\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}