{
  "hash": "fb1706a4d76b6c43b20644924c6a0194",
  "result": {
    "engine": "knitr",
    "markdown": "---\noutput: html_document\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n# Map across resamples { .unnumbered}\n\nWe can use map (and foreach) to fit and evaluate models over resamples/splits manually\n\n- This can be done to replace `fit_resamples()` and `tune_grid()`\n- Useful if we need to fit models outside of full tidymodels framework (e.g., when using keras for neural networks)\n- Useful for nested resampling, which is not supported by `fit_resamples()` and `tune_grid()`\n\n## Set up\n\nLets start by....\n\n- loading libraries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(foreach)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'foreach'\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n```\n\n\n:::\n:::\n\n\n\n\n- creating a simple data set\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123456)\nn_obs <- 300\nn_boots <- 50\nd <- tibble(x1 = rnorm(n_obs), x2 = rnorm(n_obs), y = 2*x1 + 3*x2 + rnorm(n_obs))\n```\n:::\n\n\n\n\n- getting bootstrap resamples of d.  It has two columns and n_boots rows.  Each row is a bootstrap sample of the data.  The columns are:\n\n  - `splits` - contains a bootstrap sample of the data that includes held-in raw data and OOB held-out raw data subsamples\n  - `id` - name of the resample\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples <- bootstraps(d, times = n_boots)\n\nresamples\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Bootstrap sampling \n# A tibble: 50 × 2\n   splits            id         \n   <list>            <chr>      \n 1 <split [300/115]> Bootstrap01\n 2 <split [300/108]> Bootstrap02\n 3 <split [300/108]> Bootstrap03\n 4 <split [300/107]> Bootstrap04\n 5 <split [300/112]> Bootstrap05\n 6 <split [300/102]> Bootstrap06\n 7 <split [300/112]> Bootstrap07\n 8 <split [300/114]> Bootstrap08\n 9 <split [300/115]> Bootstrap09\n10 <split [300/117]> Bootstrap10\n# ℹ 40 more rows\n```\n\n\n:::\n:::\n\n\n\n\n- setting up a simple recipe for feature engineering all our models (just use raw x and y)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <- recipe(y ~ ., data = d)\n```\n:::\n\n\n\n\n## Using map() to replace fit_resamples() - step x step\n\nIn this first example, we will combine `map()` with the use of list columns to save all the intermediate products that are produced when fitting and evaluating a single model configuration for a logistic regression across resamples.\n\nTo do this, we will need a function to fit logistic regression to held-in training data.  We can use the typical tidymodels code here.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_lm <- function(held_in) {\n  linear_reg() |> \n    set_engine(\"lm\") |> \n    fit(y ~ ., data = held_in)\n}\n```\n:::\n\n\n\n\nThen we use `map()` and list columns to save the individual steps for evaluating the model in each resample.  The following steps are done for EACH resample using `map()` or `map2()`\n\n- prep the recipe with held-in data\n- bake the recipe using `new_data = NULL` to get held-in features\n- bake the recipe using `new_data = assessment(split)` to get held-out features\n- fit the model using the held-in features\n- get predictions using the model with the held-out features\n- calculate the accuracy of the model\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_ex1 <- resamples |> \n  mutate(prep_recs = map(splits, \n                         \\(split) prep(rec, training = analysis(split))),\n         held_ins = map2(resamples$splits, prep_recs, \n                         \\(split, prep_rec) bake(prep_rec, new_data = NULL)),\n         held_outs = map2(resamples$splits, prep_recs, \n                          \\(split, prep_rec) bake(prep_rec, \n                                                  new_data = assessment(split))),\n         models = map(held_ins, \n                      \\(held_in) fit_lm(held_in)),\n         predictions = map2(models, held_outs, \n                            \\(model, held_out) predict(model, held_out)$.pred),\n         errors = map2_dbl(predictions, held_outs, \n                           \\(pred, held_out) rmse_vec(held_out$y, pred)))\n```\n:::\n\n\n\n\nThe pipline above creates a tibble with columns for each of the intermediate products and the rmse/error of the model in each resample.  All but the last columns are list columns that can hold objects of any time (e.g., prepped recipes, data frames, model objects).  The final column is a double column that holds the rmse of the model in each resample.  That is why we used `map_dbl()` to create the error column.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_ex1 |> glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 50\nColumns: 8\n$ splits      <list> [<boot_split[300 x 115 x 300 x 3]>], [<boot_split[300 x 1…\n$ id          <chr> \"Bootstrap01\", \"Bootstrap02\", \"Bootstrap03\", \"Bootstrap04\"…\n$ prep_recs   <list> [x1, x2, y, double, numeric, double, numeric, double, num…\n$ held_ins    <list> [<tbl_df[300 x 3]>], [<tbl_df[300 x 3]>], [<tbl_df[300 x …\n$ held_outs   <list> [<tbl_df[115 x 3]>], [<tbl_df[108 x 3]>], [<tbl_df[108 x …\n$ models      <list> [NULL, ~NULL, ~NULL, regression, FALSE, stats, formula, f…\n$ predictions <list> <1.38587470, 2.84334628, -2.07435584, 1.24941793, -0.0569…\n$ errors      <dbl> 0.9826968, 0.9380291, 1.0127994, 0.9929520, 0.9849202, 0.9…\n```\n\n\n:::\n:::\n\n\n\n\nWe can now look at rmses across the 50 bootstraps.  For example, we can make a histogram using ggplot from the errors column in the fits tibble\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_ex1 |> \n  ggplot(aes(errors)) +\n  geom_histogram(binwidth = 0.05)\n```\n\n::: {.cell-output-display}\n![](app_resampling_with_map_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\nAnd we can summarize the min, max, mean, median and stdev of the error column in the fits tibble\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_ex1 |> \n  summarize(n = n(),\n            min = min(errors), \n            max = max(errors), \n            mean = mean(errors), \n            median = median(errors),\n            std_dev = sd(errors))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n      n   min   max  mean median std_dev\n  <int> <dbl> <dbl> <dbl>  <dbl>   <dbl>\n1    50 0.876  1.12 0.997  0.989  0.0557\n```\n\n\n:::\n:::\n\n\n\n\nEasy peasy!  But remember, it is easier still using `fit_reamples()`.  We demo this only to make clear what `fit_resamples()` is doing and to give you an alternative workflow in case you can't use `fit_resamples()`.  It is also a demonstration of the use of `map()` and list columns, which has many uses.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_tidy_ex1 <-\n  linear_reg() |> \n    set_engine(\"lm\") |> \n    fit_resamples(preprocessor = rec, \n                  resamples = resamples, \n                  metrics = metric_set(rmse))\n\nresamples_tidy_ex1 |> \n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.997    50 0.00788 Preprocessor1_Model1\n```\n\n\n:::\n\n```{.r .cell-code}\nresamples_tidy_ex1 |> \n  collect_metrics(summarize = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 × 5\n   id          .metric .estimator .estimate .config             \n   <chr>       <chr>   <chr>          <dbl> <chr>               \n 1 Bootstrap01 rmse    standard       0.983 Preprocessor1_Model1\n 2 Bootstrap02 rmse    standard       0.938 Preprocessor1_Model1\n 3 Bootstrap03 rmse    standard       1.01  Preprocessor1_Model1\n 4 Bootstrap04 rmse    standard       0.993 Preprocessor1_Model1\n 5 Bootstrap05 rmse    standard       0.985 Preprocessor1_Model1\n 6 Bootstrap06 rmse    standard       0.947 Preprocessor1_Model1\n 7 Bootstrap07 rmse    standard       1.00  Preprocessor1_Model1\n 8 Bootstrap08 rmse    standard       1.06  Preprocessor1_Model1\n 9 Bootstrap09 rmse    standard       1.05  Preprocessor1_Model1\n10 Bootstrap10 rmse    standard       0.981 Preprocessor1_Model1\n# ℹ 40 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Using map() to replace fit_resamples() - one function\n\nIf we wanted to generate the held-out error using resampling but didnt need/want the intermediate products, we could wrap all the steps in one function and just map that single function.  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_and_eval <- function(split, rec) {\n  # prep the recipe with held-in data\n  prep_rec <- prep(rec, training = analysis(split))\n  \n  # bake the recipe using new_data = NULL to pull out the held-in features\n  held_in <- bake(prep_rec, new_data = NULL)\n  \n  # bake the recipe using new_data = assessment(split) to get held-out features\n  held_out <- bake(prep_rec, new_data = assessment(split))\n  \n  # fit the model using the held-in features\n  model <- \n    linear_reg() |> \n    set_engine(\"lm\") |> \n    fit(y ~ ., data = held_in)\n  \n  # get predictions using the model with the held-out features\n  pred <- predict(model, held_out)$.pred\n  \n  # calculate the accuracy of the model\n  rmse_vec(held_out$y, pred)\n}\n```\n:::\n\n\n\n\nNow map this function over the splits to get a vector of rmse.  Same results, but not saving intermediate steps by using one function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_ex2 <- resamples |> \n  mutate(errors = map_dbl(splits, \\(split) fit_and_eval(split, rec)))\n```\n:::\n\n\n\n\nHere is what the resamples_ex2 tibble now looks like and summary stats on the resampled rmse\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_ex2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Bootstrap sampling \n# A tibble: 50 × 3\n   splits            id          errors\n   <list>            <chr>        <dbl>\n 1 <split [300/115]> Bootstrap01  0.983\n 2 <split [300/108]> Bootstrap02  0.938\n 3 <split [300/108]> Bootstrap03  1.01 \n 4 <split [300/107]> Bootstrap04  0.993\n 5 <split [300/112]> Bootstrap05  0.985\n 6 <split [300/102]> Bootstrap06  0.947\n 7 <split [300/112]> Bootstrap07  1.00 \n 8 <split [300/114]> Bootstrap08  1.06 \n 9 <split [300/115]> Bootstrap09  1.05 \n10 <split [300/117]> Bootstrap10  0.981\n# ℹ 40 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nresamples_ex2 |> \n  summarize(n = n(),\n            min = min(errors), \n            max = max(errors), \n            mean = mean(errors), \n            median = median(errors),\n            std_dev = sd(errors))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n      n   min   max  mean median std_dev\n  <int> <dbl> <dbl> <dbl>  <dbl>   <dbl>\n1    50 0.876  1.12 0.997  0.989  0.0557\n```\n\n\n:::\n:::\n\n\n\n\n\n## Using two map()s to replace tune_grid()\n\nNow we can make this a bit more complicated by adding a grid of hyperparameters to tune.  Lets keep it simple and tune only k in a knn model.  To tune k, we would normally use `tune_grid()` but we can do it again with two loops using `map()`.  We use an outer `map()` to loop over the resamples and an inner `map()` to loop over the values of lambda.   \n\nWe need a single function to repeatedly fit and eval over a grid of parameters\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neval_grid <- function(split, rec, grid_k) {\n \n  # get held-in and held-out features for split \n  prep_rec <- prep(rec, training = analysis(split))\n  held_in <- bake(prep_rec, new_data = NULL)\n  held_out <- bake(prep_rec, new_data = assessment(split))\n\n  # function fit fit and eval model for a specific lambda and resample\n  fit_eval_k <- function(k, held_in, held_out) {\n    model <- \n      nearest_neighbor(neighbors = k) |>   \n        set_engine(\"kknn\") |>   \n        set_mode(\"regression\") |>  \n        fit(y ~ ., data = held_in)\n    \n    pred <- predict(model, held_out)$.pred\n    \n    tibble(k = k, \n           rmse = rmse_vec(held_out$y, pred))\n  }\n  \n  # loop through grid_k and fit/eval model for each k \n  # this is the inner loop\n  # use list_rbind() to bind the separate rows for each tibble into one larger tibble\n  grid_k |> \n    map(\\(k) fit_eval_k(k, held_in, held_out)) |> \n    list_rbind()\n}\n```\n:::\n\n\n\n\nNow map this function over the splits. This is the outer loop.  `fit_eval_hyper()` will return a tibble with rows for each value of k.  We will save one tibble for each split in a list column called `errors`. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_k = c(2, 4, 8, 16)\nresamples_ex3 <- resamples |> \n  mutate(rmses = map(splits, \n              \\(split) eval_grid(split, rec, grid_k)))\n```\n:::\n\n\n\n\nThe rmses column contains the rmse for each value of k for each split/resample in a tibble.  Each tibble has 4 rows (one for each k) and 2 columns (k and rmse).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_ex3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Bootstrap sampling \n# A tibble: 50 × 3\n   splits            id          rmses           \n   <list>            <chr>       <list>          \n 1 <split [300/115]> Bootstrap01 <tibble [4 × 2]>\n 2 <split [300/108]> Bootstrap02 <tibble [4 × 2]>\n 3 <split [300/108]> Bootstrap03 <tibble [4 × 2]>\n 4 <split [300/107]> Bootstrap04 <tibble [4 × 2]>\n 5 <split [300/112]> Bootstrap05 <tibble [4 × 2]>\n 6 <split [300/102]> Bootstrap06 <tibble [4 × 2]>\n 7 <split [300/112]> Bootstrap07 <tibble [4 × 2]>\n 8 <split [300/114]> Bootstrap08 <tibble [4 × 2]>\n 9 <split [300/115]> Bootstrap09 <tibble [4 × 2]>\n10 <split [300/117]> Bootstrap10 <tibble [4 × 2]>\n# ℹ 40 more rows\n```\n\n\n:::\n:::\n\n\n\n\nWe can `unnest()` the rmses column to get a tibble with one row for each lambda value in each resample.  No need to see the original splits column so we will select it out.  For example.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_ex3 |> \n  unnest(rmses) |> \n  select(-splits) |>\n  print(n = 30)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 200 × 3\n   id              k  rmse\n   <chr>       <dbl> <dbl>\n 1 Bootstrap01     2  1.54\n 2 Bootstrap01     4  1.49\n 3 Bootstrap01     8  1.46\n 4 Bootstrap01    16  1.58\n 5 Bootstrap02     2  1.38\n 6 Bootstrap02     4  1.27\n 7 Bootstrap02     8  1.25\n 8 Bootstrap02    16  1.29\n 9 Bootstrap03     2  1.50\n10 Bootstrap03     4  1.47\n11 Bootstrap03     8  1.48\n12 Bootstrap03    16  1.52\n13 Bootstrap04     2  1.44\n14 Bootstrap04     4  1.39\n15 Bootstrap04     8  1.32\n16 Bootstrap04    16  1.36\n17 Bootstrap05     2  1.60\n18 Bootstrap05     4  1.47\n19 Bootstrap05     8  1.41\n20 Bootstrap05    16  1.44\n21 Bootstrap06     2  1.33\n22 Bootstrap06     4  1.32\n23 Bootstrap06     8  1.42\n24 Bootstrap06    16  1.53\n25 Bootstrap07     2  1.35\n26 Bootstrap07     4  1.33\n27 Bootstrap07     8  1.34\n28 Bootstrap07    16  1.35\n29 Bootstrap08     2  1.39\n30 Bootstrap08     4  1.32\n# ℹ 170 more rows\n```\n\n\n:::\n:::\n\n\n\n\nWe can pipe this unnested tibble into a `group_by()` and `summarize()` to get the median (or mean) across resamples and then arrange to find the best k \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_ex3 |> \n  unnest(rmses) |> \n  select(-splits) |>\n  group_by(k) |> \n  summarize(n = n(),\n            mean_rmse = mean(rmse)) |> \n  arrange(mean_rmse)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n      k     n mean_rmse\n  <dbl> <int>     <dbl>\n1     8    50      1.34\n2    16    50      1.37\n3     4    50      1.39\n4     2    50      1.48\n```\n\n\n:::\n:::\n\n\n\n\nThe code above makes it clear that using resampling to tune a grid of hyperparameters is just a matter of looping over the resamples in an outer loop and looping over a  grid of hyperparameters in an inner loop. \n\nBut of course, this can be done more easily with `tune_grid()`.  Here is the tidymodels version with `tune_grid()`.  Its clearly more concise code but the looping is not transparent.  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_tidy_ex3 <- \n  nearest_neighbor(neighbors = tune()) |>   \n    set_engine(\"kknn\") |>   \n    set_mode(\"regression\") |>  \n    tune_grid(preprocessor = rec, \n              resamples = resamples, \n              grid = tibble(neighbors = grid_k), \n              metrics = metric_set(rmse))\n\nresamples_tidy_ex3 |> \n  collect_metrics() |> \n  arrange(mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 7\n  neighbors .metric .estimator  mean     n std_err .config             \n      <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1         8 rmse    standard    1.34    50  0.0178 Preprocessor1_Model3\n2        16 rmse    standard    1.37    50  0.0219 Preprocessor1_Model4\n3         4 rmse    standard    1.39    50  0.0160 Preprocessor1_Model2\n4         2 rmse    standard    1.48    50  0.0161 Preprocessor1_Model1\n```\n\n\n:::\n\n```{.r .cell-code}\nresamples_tidy_ex3 |> \n  collect_metrics(summarize = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 200 × 6\n   id          neighbors .metric .estimator .estimate .config             \n   <chr>           <dbl> <chr>   <chr>          <dbl> <chr>               \n 1 Bootstrap01         2 rmse    standard        1.54 Preprocessor1_Model1\n 2 Bootstrap02         2 rmse    standard        1.38 Preprocessor1_Model1\n 3 Bootstrap03         2 rmse    standard        1.50 Preprocessor1_Model1\n 4 Bootstrap04         2 rmse    standard        1.44 Preprocessor1_Model1\n 5 Bootstrap05         2 rmse    standard        1.60 Preprocessor1_Model1\n 6 Bootstrap06         2 rmse    standard        1.33 Preprocessor1_Model1\n 7 Bootstrap07         2 rmse    standard        1.35 Preprocessor1_Model1\n 8 Bootstrap08         2 rmse    standard        1.39 Preprocessor1_Model1\n 9 Bootstrap09         2 rmse    standard        1.43 Preprocessor1_Model1\n10 Bootstrap10         2 rmse    standard        1.54 Preprocessor1_Model1\n# ℹ 190 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Using map() and foreach() to do nested cv\n\nNow lets do the most complicated version of this.   Nested resampling involves looping over outer splits where the held out data are test sets used to evaluate best model configurations for each outer split and the inner loop makes validation sets that are used to select the best model configuration for each outer fold.  However, if we are tuning a grid of hyperparameters, there is even a further nested loop inside the inner resampling loop to get performance metrics for each value of the hyperparameter in the validation sets.\n\nrsample supports creating a nested resamplinng object.  You can specify different resampling for the inner and outer loops.  k-fold for the outer loop and bootstraps for the inner loop is a common choice.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_nested <- d |> \n  nested_cv(outside = vfold_cv(v = 5), inside = bootstraps(times = 10))\n```\n:::\n\n\n\n\nLets take a look at it.  It has five rows for each of the five outer splits.  The inner_resamples column contains a list column with 10 rows for each of the 10 inner splits.  The inner splits are the bootstrap samples.  The outer splits are the k-folds.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_nested\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Nested resampling:\n#  outer: 5-fold cross-validation\n#  inner: Bootstrap sampling\n# A tibble: 5 × 3\n  splits           id    inner_resamples\n  <list>           <chr> <list>         \n1 <split [240/60]> Fold1 <boot [10 × 2]>\n2 <split [240/60]> Fold2 <boot [10 × 2]>\n3 <split [240/60]> Fold3 <boot [10 × 2]>\n4 <split [240/60]> Fold4 <boot [10 × 2]>\n5 <split [240/60]> Fold5 <boot [10 × 2]>\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\neval_grid <- function(bootstrap_split, rec, grid_k) {\n \n  # get held-in and held-out features for split \n  prep_rec <- prep(rec, training = analysis(bootstrap_split))\n  held_in <- bake(prep_rec, new_data = NULL)\n  held_out <- bake(prep_rec, new_data = assessment(bootstrap_split))\n\n  # function fit fit and eval model for a specific lambda and resample\n  fit_eval_k <- function(k, held_in, held_out) {\n    model <- \n      nearest_neighbor(neighbors = k) |>   \n        set_engine(\"kknn\") |>   \n        set_mode(\"regression\") |>  \n        fit(y ~ ., data = held_in)\n    \n    pred <- predict(model, held_out)$.pred\n    \n    tibble(k = k, \n           rmse = rmse_vec(held_out$y, pred))\n  }\n  \n  # loop through grid_k and fit/eval model for each k \n  # this is the inner loop\n  # use list_rbind() to bind the separate rows for each tibble into one larger tibble\n  grid_k |> \n    map(\\(k) fit_eval_k(k, held_in, held_out)) |> \n    list_rbind()\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_bootstraps <- function(bootstraps, rec, grid_k) {\n \n  bootstraps$splits |>  \n    map(\\(bootstrap_split) eval_grid(bootstrap_split, rec, grid_k)) |> \n    list_rbind()\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresamples_nested_ex4 <- resamples_nested |> \n  mutate(inner_rmses = map(inner_resamples, \n                          \\(inner_resample) bind_bootstraps(inner_resample, \n                                                            rec, \n                                                            grid_k)))\n```\n:::\n\n\n\n\nGet best k for each outer fold\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_best_k <- function(rmses) {\n  rmses |>  \n    group_by(k) |> \n    summarize(mean_rmse = mean(rmse)) |> \n    arrange(mean_rmse) |> \n    slice(1) |> \n    pull(k)\n}\n\nresamples_nested_ex4 <- resamples_nested_ex4 |> \n  mutate(best_k = map_dbl(inner_rmses, \\(rmses) get_best_k(rmses)))\n```\n:::\n",
    "supporting": [
      "app_resampling_with_map_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}