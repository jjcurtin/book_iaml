---
title: 'Unit 4 (Classification): Cleaning EDA'
author: "Gaylen Fronk"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---

## Assignment overview

To begin, download the following from the course web book (Unit 4):

* Three RMarkdown (.Rmd) files: hw_unit_4_eda_cleaning.Rmd, hw_unit_4_fit_knn, & hw_unit_4_fit_rda.Rmd)

* titanic_raw.csv (data to be used for this script to create training & validation)

* titanic_test_cln.csv (already-cleaned held-out test data with outcome labels removed)

* fun_modeling.R (for custom course functions)

* titanic_data_dictionary.png

The data for this week's assignment (across all scripts) will be the Titanic dataset, which contains survival outcomes and passenger characteristics for the Titanic's passengers. You can find information about the dataset in the data dictionary (available for download from the course website). This is a popular dataset that has been used for machine learning competitions and is noted for being a fun and easy introduction into data science. There is tons of information on how others have worked with this dataset online, and you are encouraged to incorporate knowledge that others have gained if you want! However, only code from the class web book will be needed for full credit on this assignment.

In this script, you will step through cleaning EDA on the full dataset. To keep this assignment to a manageable length, we have included all the code here for cleaning. This script starts with reading in the raw .csv file that you downloaded & finishes with writing out cleaned training and validation files. We have already held out a separate test set for final model evaluation. You will need to run the code in this script to clean the raw data before moving onto modeling EDA. Note that you WILL need to adjust file paths for this script to work for you; those spots in the script are clearly marked. **Do not start working on the fit_knn or fit_rda scripts until you have completed this cleaning script and generated the cleaned training and validation files**

Your assignment is due Wednesday, February 15th at 5:00 PM.

## Setup

Load packages 
```{r load_packages}
library(tidymodels) # for modeling
library(tidyverse) # for general data wrangling
library(kableExtra) # for displaying formatted tables w/ kbl()
library(janitor)  # for clean_names(), tabyl()
library(skimr) # for skim()
```

Create file path object. **NOTE:** change this path to be where YOUR unit 4 homework files are saved.
```{r set_path}
path_hw_unit_4 <- "C:/Users/skittleson/Documents/GitHub/iaml/bookdown/homework"
```

Source functions script. **NOTE:** change the path to where YOU have saved this file.
```{r source_custom_functions}
source("C:/Users/skittleson/iaml/fun_modeling.R")
```

## Cleaning EDA on full dataset

### Read in data & glimpse
Read in titanic_raw.csv from your data path using read_csv() and then glimpse() it.

**Tip:** read_csv() has an argument called "col_types". This argument can be used to specify column types for variables that might be read in wrong. If you set the argument equal to "cols()" (which indicates that R should still figure out column types on its own), it avoids the printout from the read-in function. Sometimes it's nice to get that printout, but if you're going to immediately glimpse() or otherwise view the data, it can be annoying!
```{r read_data}
data_all <- read_csv(file.path(path_hw_unit_4, "titanic_raw.csv"),
                     col_types = cols(),
                     na = c("?", "NA")) %>% 
  glimpse()
```

### Read data dictionary

Look at the data dictionary available for download from the course website to understand the different variables. Reference this as needed while you perform cleaning checks below and modeling EDA/feature engineering in future scripts.

### Perform basic cleaning

**Tidy variable names:** Note from our glimpse() above that all variable names are already lower case/snake case, but I'm going to make some small changes to make the names clearer. Specifically, I'm changing sibsp to n_sib_spouse to remind me that this is a count variable of that passenger's siblings and spouses on-board, and I'm changing parch to n_parent_child to remind me that this is a count variable of that passenger's parents and children on-board.
```{r tidy_names}
data_all <- data_all %>% 
  rename(n_sib_spouse = sibsp, n_parent_child = parch)
```

**Change variable classes as needed:** I see that pclass should be character (because it represents passenger class; it's ordinal not numeric) and that our outcome variable, survived, should be character (we'll make it a factor later). 
```{r change_classes}
glimpse(data_all)

data_all <- data_all %>% 
  mutate(pclass = as.character(pclass),
         survived = as.character(survived))
```

**Skim the data:** Note the high percentages of missingness for cabin and age There is also one missing observation for embarked and fare. There are also very high numbers of unique values for name, ticket, and cabin.
```{r skim_data}
data_all %>% skim_some()
```

**Address missingness related to errors:** Here we would review missing data and address any missingness due to errors/coding. However, there is nothing in the data dictionary to suggest that missing values are due to errors.

**Explore out-of-range responses for numeric variables:** Here, no responses seem out of the ordinary - it's reasonable for age to range from a fraction (a baby; this IS explicitly noted in the data dictionary), for someone to have 8 siblings or 9 children on-board (in fact, those values line up and probably refer to the same family!), and for fares to range up over $500.
```{r explore_numeric}
data_all %>% 
  select(where(is.numeric)) %>% 
  skim_some()
```

**Explore all responses for categorical variables:** We see that there are three passenger classes: 1st, 2nd, and 3rd.,  binary values for  biological sex (male and female), and three embarcation ports: S (Southampton), C (Cherbourg), and Q (Queenstown). These all line up with the data dictionary.
```{r explore_categorical}
data_all %>% 
  select(survived, pclass, sex, embarked) %>% 
  walk2(.x = names(.),
        .y = .,
        .f = print_responses)
```

For some variables in this dataset with hundreds of unique values, the output from print_responses() will be meaningless, so we'll explore those in different ways. Let's instead take a look at a handful of the values to get a sense of the types of responses. 

We see that the name variable includes last names, a title, and first/middle names. The cabin variable includes a letter and a number, and sometimes it includes more than one cabin. It appears that those multiple cabins are for groups who have more than one cabin on the same ticket, as indicated by the first three rows where the ticket number and cabins are the same. 
```{r}
data_all %>% 
  select(name, cabin, ticket) %>% 
  head()
```

**Tidy response labels for categorical variables:** We're going to keep name, cabin, and ticket as they are because the formatting is somewhat useful/meaningful (e.g., capital letters and punctuation help the names look like names). The only responses that need to be changed are for the embarked variable. We can just use the simpler str_to_lower() function to change that (rather than tidy_responses).
```{r tidy_cat_responses}
data_all <- data_all %>% 
  mutate(embarked = str_to_lower(embarked))
```

## Split data into training, validation, and test

Now that we have completed data cleaning, we will split our data into train and test sets and save out the cleaned files. We have already held out a separate test set, so this split will create our training and validation sets.

We'll set a seed so that the same split can be redone if needed (like if we find more errors during modeling EDA/feature engineering & need to come back to this script).
```{r}
set.seed(11151994)
```

**Divide data using splitting function:** Assign 25% of the data to be your validation set. Stratify this split on the outcome variable (survived)
```{r split_data}
splits <- initial_split(data_all, prop = 0.75, strata = "survived")
data_trn <- splits %>% analysis()
data_val <- splits %>% assessment()
```

Write out two .csv files (titanic_train.csv, titanic_val.csv)
```{r write_data}
write_csv(data_trn, file.path(path_hw_unit_4, "titanic_train_cln.csv"))
write_csv(data_val, file.path(path_hw_unit_4, "titanic_val_cln.csv"))
```

## Next steps

Complete some modeling EDA on your cleaned training data so that you're able to do good feature engineering & model fitting, then head to the two model fitting homework scripts (hw_unit_4_fit_knn.Rmd, hw_unit_4_fit_rda.Rmd). Good luck!
