---
title: "Homework Unit 9: Model Comparisons and Other Explanatory Goals"
author: "Your name here"
date: "`r lubridate::today()`"
format: 
  html: 
    embed-resources: true
    toc: true 
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---


## Introduction

To begin, download the following from the course web book (Unit 9):

* `hw_unit_9_explanatory.qmd` (notebook for this assignment)

* `admissions_full.csv` (data for this assignment)

The data for this week's assignment have information about admissions to a masters program. 

The data will be cleaned using code included for you below, and you don't need to do any modeling EDA to keep the assignment from getting too long. *However, you should still always be checking your data as you progress through the assignment!* We have described the specific steps you'll take to implement the recipes.

In this assignment, you will practice comparing models to determine the importance of a focal variable. In particular, you will be determining whether GRE score matters for gaining admission to graduate school. You will then use the Bayesian approach to evaluate the effect of that focal variable. 

To reduce run time we are not going to do any hyperparameter tuning and will only be using 20 splits (2 repeats of 10 fold cv), *but remember in real world applications you would be fitting many more models*. Remember that setting up parallel processing will also dramatically reduce your run times.   

Let's get started!

-----


##  Setup

Set up your notebook in this section. You will want to set your path and initiate parallel processing here!

```{r}

```



## Read in your data

Read in the `admissions_full.csv` data file using this code to clean and glimpse it.
```{r}
data_all <- read_csv(here(path_hw_unit_9, "admissions.csv"),
                     col_types = cols()) %>% 
  clean_names(case = "snake") %>% 
  rename(statement_quality = sop, letter_quality = lor,
         research_experience = research, id = serial_no) %>% 
  mutate(across(where(is.character), tidy_responses)) %>% 
  mutate(across(where(is.character), as_factor)) %>% 
  glimpse()
```

## Set up splits

### Divide data into train and test

Hold out 25% of the data as a test set for evaluation. Stratify on admitted. 
```{r}
set.seed(12345)

```

### Make cross-validation splits

Split `data_trn` into repeated k-fold cross-validation splits using 2 repeats, 10 folds, and stratifying on admitted. You do not need to set a new seed. Save your splits as an object named `splits`
```{r}


```

## Build recipes

Follow the instructions below to build two recipes from your training data: one for a "full" model (contains all predictors), and one for a compact model (contains all predictors except the focal variable, GRE score).

### Recipe 1: Full model

Follow these steps in your recipe. **Use your own judgment about the correct order of steps!** These are an UNORDERED list of the things you should include. 

* Regress the outcome on all variables

* Create dummy coded features for categorical predictors

* Handle missing data for both categorical and numeric predictors where needed

* If needed, include a step to handle novel levels of categorical features

* Remove near-zero variance features

* Remove the id variable

```{r}
rec_full <- 
```

### Recipe 2: Compact model

Because your recipe for the compact model will only differ from your recipe for the full model by one step (removing a variable), you can start with `rec_full`. Then add a step (after a pipe) that will remove the focal variable, GRE score.

```{r}
rec_compact <- rec_full
```

## Fit models

### Fit the full model

Use `rec_full` and `splits` to fit GLMs across folds. Use accuracy as your metric. Save your model fits as `fits_full`. 
```{r}

```

Print the mean accuracy across the 20 held-out folds.
```{r}

```

### Fit the compact model

Use `rec_compact` and `splits` to fit GLMs across folds. Use accuracy as your metric. Save your model fits as `fits_compact`. 
```{r}

```

Print the mean accuracy across the 20 held-out folds.
```{r}

```


## Model comparison with the Bayesian approach
You will now compare your models using the Bayesian parameter estimation

### Gather performance estimates

First, make a dataframe containing the 20 performance estimates from held out folds for your full and compact model
```{r}


```


### Posterior probabilities

Next, derive the posterior probabilites for the accuracy of each of these two models
```{r}


```

### Graph positerior probabilities

Display your posterior probabilities using both a density plot and a histogram. Choose plots that would be the most useful to display your results to a collaborator.
```{r}


```

### Determine if the full model is more accurate

Calculate the probability that the full model is more accurate than the compact model. 

```{r}


```

Type out a summary of what you find that includes:

* Your interpretation of what the mean increase in accuracy and 95% HDI values represent

* Your conclusion if the full model is meaningfully better than your compact model and why   

*Type your summary here*



## Feature importance

You will now look at feature importance in your full model using Shapely Values.

### Prep data
Get your data ready for use with the `iml` package. Do the following:

* Create a feature matrix of your full model 

* Pull out your raw features and outcome to be utilized in calculating feature importance

* Define a predictor function so we can make predictions from our model using the `iml` package
```{r}



```

### Calculate Shapely Values for a single participant

First, we will look at shapely values for a single participant. For this example, lets look at the last participant in our data set. Do the following:

* Print the raw feature values for the last participant. (Be sure to do this in a way that will print your output in your knit document)

* Generate Shapely Values for this participant and output the raw results

* Use ggplot to plot the Shapely Values for this participant

```{r}


```

Provide a brief interpretation of what the top shapely value means.    

*Type your response here*


### Calculate mean absolute Shapely Values across all participants

Now we will look at feature importance across all participants. Include the following steps (and make sure each step prints to your knit document):

* Calculate Shapely Values for each observation and glimpse() the resulting tibble

* Plot the mean absolute Shapely Values across all participants

```{r}


```

Write a brief description of your top take-aways from this plot.    

*Type your response here.*


## Interactions

Lastly, you will explore interactions among all features in your full model. 

*Generate a plot (using ggplot) of the total variance across all the (two-way) interactions a feature can have with other features 

* Generate a plot displaying we all specific two-way interactions individually for our target GRE score feature

```{r}



```


Provide a brief summary of what you notice about the plots.

*Type your response here*



