---
editor_options: 
  chunk_output_type: console
---

# Discussion

## Announcements

- Application exam available (due )
- Readings due by next Tuesday
- 

## Sets and iteration

- train/val(dev)/test vs kfold/bootstrap with test vs nested cv
- choosing sample sizes for train, val, test
- Random vs non-random splits into train/val/test.  what needs to be true?  what is less important?
- overfit val?  Use test more than once?  Do vs. don't and risks

- **Review 12 Takeaways**

## Error analysis

- why
- start with baseline/basic system first- why?
- eyeball and black box dev sets
- size of eyeball sample?
- risk of using all dev as eyeball sample
- error analysis for regression?

- **review 19 takeaways**

## Bias/Variance

- identify by differences in train/val error
  - 1/11
	- 15/16
	- 15/30
	- 1/2
	
- role of optimal error rate (and human error rate?)
- avoidable bias and variance using train/val/ and optimal error
- how to fix avoidable bias (25)
- how to fix variance (27)


## Learning Curves

- How and why
- how to calculate with small samples?  issues with large samples?
- review figs on next slides

--------------------------------------------------------------------------------

![examples 1](figs/learning_curve_1.png)

--------------------------------------------------------------------------------

![examples 2](figs/learning_curve_2.png)

--------------------------------------------------------------------------------

![examples 3](figs/learning_curve_3.png)


## Pipeline vs End-to-End

- when have we seen each?
- costs and benefits vs. possible?