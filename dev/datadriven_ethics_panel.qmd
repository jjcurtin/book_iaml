# Question 1 - Reporting
For research on computational models in mental health, what do you think the reporting requirements should look like with respect to bias? Are these different for clinical vs basic science research? Should there be guidelines for reporting in publications? Should funders ask for particular analyses up front?

- Characteristics for training data  (but what about intersectional)
- Subgroup analyses for performance metrics 
   - auROC; sensitivity, specificity
   - PPV and NPV critical in case outcome distributions differ by subgroups
   - predictions (pos/neg) by groups
- Feature importance in subgroups
- Requirements for publications rather than (or in addition to) funders.  Important to have it in the papers, not just on clinical trials.gov or grant reports
- intersections - cases with high leverage on features overall
- Challenge for space in papers.  Fairness analyses are complicated and lengthy if done well.

# Question 2 - Mitigation
For research on computational models in mental health, what do you think the mitigation requirements should look like with respect to bias? Are these different for clinical vs basic science research?

- better representation in training data
- but features come from domain expertise and that is based on literature with poor representation
- Modified loss functions or resampling to combat bias
- inclusion of subgroup charateristics in models - id and control, thresholding (but probabiliies)
- outcome that is modeled
- support for representation - costly, difficult

# Question 3 - Materials
Is there missing training, education, or informational resources that would help researchers to better understand and address bias? Is this best presented as continuing education courses? Formal publications? Playbooks/checklists/whitepapers? Side-events with training and discussion at conferences?

- Python tools - aif360, fairlearn, aequitas
- R - fairness, fairadapt, fairmodels
- Need both papers and online CE courses.  Not fan of workshops at confernece because of reach and bias of who can attend


# Question 4 - Tools
Are there tools or assets that would better support researchers in achieving these goals?
Datasets that have better representation that what is currently available
Analytical tools for assessing fairness and bias
Reporting standard forms to simplify how to decide what to include in publications

- Python tools - aif360, fairlearn, aequitas
- R - fairness, fairadapt, fairmodels
- Need reporting guidelines

And here are the other related questions:
How do you think the field of mental health research is doing with respect to algorithmic bias? How does it intersect with your work/research?
How do you think the roles of researchers, clinicians, publishers, funders, and other institutions intersect with issues of algorithmic bias? Are there different focuses or areas of responsibility?
Are there other interesting trends you would notice in terms of how research addresses algorithmic bias? Are there particular publications you would recommend?
Are there any important topics or missing perspectives from this discussion that have not been addressed?



- bias as term
- what subgroups?

park e al 2021 post partum depression






